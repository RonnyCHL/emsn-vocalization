{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# EMSN 2.0 - Vocalization Training v2 (Pro+ Optimized)\n## Geoptimaliseerd voor Colab Pro+ (A100 GPU, 83GB RAM, 24h runtime)\n\n### Snelheidsoptimalisaties:\n- **TF32** - A100 tensor cores, ~2-3x sneller dan FP32\n- **AMP** - Automatic Mixed Precision (FP16 compute + FP32 accumulate)\n- **torch.compile()** - PyTorch 2.0 graph compilation, ~20-30% sneller\n- **cuDNN benchmark** - Automatische kernel auto-tuning\n- **Batch size 128** - Optimaal voor A100 40GB VRAM\n- **8 workers + prefetch** - Maximale data pipeline throughput\n- **20 concurrent downloads** - Snellere Xeno-canto downloads\n- **Persistent workers** - Worker processen hergebruikt tussen batches\n\n### Precisie-optimalisaties:\n- **Deep Residual CNN** - 4 residual blocks + SE attention (5.2M params)\n- **SpecAugment** - Frequency & time masking (Park et al. 2019)\n- **Mixup augmentatie** - Spectogram interpolatie (Zhang et al. 2018)\n- **Label smoothing** - Voorkomt overconfident predictions\n- **Focal Loss** - Beter voor zeldzame klassen (alarm)\n- **75 recordings/type** - 50% meer data dan standaard\n- **4x augmentatie** - Meer variatie per sample\n- **80 epochs, patience 15** - Meer trainingstijd\n- **Temperature scaling** - Gekalibreerde confidence scores\n- **Train/Val/Test split** - 70/15/15 voor eerlijke evaluatie\n- **HiDrive auto-upload** - Modellen direct naar Strato cloud (993 GB vrij)\n\n### Gebruik:\n1. Runtime > Change runtime type > **GPU** (A100 aanbevolen)\n2. High-RAM: **Aan**\n3. Plak je HiDrive SSH key in cel 3\n4. **Run All** - modellen worden automatisch ge-upload naar HiDrive\n5. Na afloop: download naar Pi met het commando in cel 12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cel 1: GPU & Systeem Check (Geoptimaliseerd voor Colab Pro+)\n!nvidia-smi\n\nimport torch\nimport gc\nimport psutil\n\ntorch.cuda.empty_cache()\ngc.collect()\n\nprint(f\"\\nPyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\n\nram_gb = psutil.virtual_memory().total / 1e9\nprint(f\"RAM: {ram_gb:.1f} GB\")\nif ram_gb < 20:\n    print(\"\\u26a0\\ufe0f Low RAM! Enable High-RAM in Runtime settings\")\nelse:\n    print(\"\\u2705 High RAM beschikbaar\")\n\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_mem = torch.cuda.get_device_properties(0).total_mem / 1e9 if hasattr(torch.cuda.get_device_properties(0), 'total_mem') else torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f\"GPU: {gpu_name}\")\n    print(f\"GPU Memory: {gpu_mem:.1f} GB\")\n\n    if 'A100' in gpu_name:\n        GPU_TYPE = 'A100'\n        BATCH_SIZE = 128\n        # A100 TF32: ~2-3x sneller dan FP32, verwaarloosbaar precisieverlies\n        # TF32 gebruikt 10-bit mantissa (vs FP32 23-bit), meer dan genoeg voor CNN training\n        torch.backends.cuda.matmul.allow_tf32 = True\n        torch.backends.cudnn.allow_tf32 = True\n        torch.backends.cudnn.benchmark = True\n        torch.backends.cudnn.deterministic = False\n        print(f\"\\n\\U0001f680 A100 Pro+ mode: TF32=ON, Benchmark=ON, Batch={BATCH_SIZE}\")\n    elif 'V100' in gpu_name:\n        GPU_TYPE = 'V100'\n        BATCH_SIZE = 64\n        torch.backends.cudnn.benchmark = True\n        torch.backends.cudnn.deterministic = False\n        print(f\"\\n\\U0001f680 V100 mode: Benchmark=ON, Batch={BATCH_SIZE}\")\n    elif 'L4' in gpu_name:\n        GPU_TYPE = 'L4'\n        BATCH_SIZE = 64\n        torch.backends.cuda.matmul.allow_tf32 = True\n        torch.backends.cudnn.allow_tf32 = True\n        torch.backends.cudnn.benchmark = True\n        torch.backends.cudnn.deterministic = False\n        print(f\"\\n\\U0001f680 L4 mode: TF32=ON, Batch={BATCH_SIZE}\")\n    else:\n        GPU_TYPE = 'T4'\n        BATCH_SIZE = 32\n        torch.backends.cudnn.benchmark = True\n        torch.backends.cudnn.deterministic = False\n        print(f\"\\nT4 mode: Batch={BATCH_SIZE}\")\n\n    # torch.compile() beschikbaar? (PyTorch 2.0+)\n    USE_TORCH_COMPILE = hasattr(torch, 'compile') and torch.__version__ >= '2.0'\n    if USE_TORCH_COMPILE:\n        print(f\"\\u2705 torch.compile() beschikbaar (PyTorch {torch.__version__})\")\n    else:\n        print(f\"\\u26a0\\ufe0f torch.compile() niet beschikbaar\")\nelse:\n    GPU_TYPE = 'CPU'\n    BATCH_SIZE = 16\n    USE_TORCH_COMPILE = False\n    print(\"\\u26a0\\ufe0f Geen GPU!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cel 2: Dependencies + rclone installeren\n!pip install librosa scikit-learn scikit-image matplotlib tqdm requests scipy -q\n\n# rclone voor HiDrive sync\n!curl -s https://rclone.org/install.sh | bash -s beta 2>/dev/null || echo \"rclone al geinstalleerd\"\n!rclone version | head -1\n\nprint(\"\\u2705 Dependencies + rclone ge\\u00efnstalleerd\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cel 3: HiDrive SFTP verbinding + Opslag configuratie\n#\n# Stap 1: Plak je HiDrive SSH private key hieronder (id_ed25519_hidrive)\n# Stap 2: Draai deze cel - rclone wordt geconfigureerd en verbinding getest\n#\nimport os\nimport time\nimport json\nfrom pathlib import Path\nfrom datetime import datetime\n\n# === HIDRIVE SSH KEY ===\n# Plak hier de inhoud van ~/.ssh/id_ed25519_hidrive\nHIDRIVE_SSH_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\nPLAK_HIER_JE_KEY\n-----END OPENSSH PRIVATE KEY-----\"\"\"\n\n# SSH key opslaan\nssh_dir = Path('/root/.ssh')\nssh_dir.mkdir(exist_ok=True)\nkey_path = ssh_dir / 'id_ed25519_hidrive'\nkey_path.write_text(HIDRIVE_SSH_KEY.strip() + '\\n')\nkey_path.chmod(0o600)\n\n# known_hosts toevoegen (voorkomt host key prompt)\n!ssh-keyscan sftp.hidrive.strato.com >> /root/.ssh/known_hosts 2>/dev/null\n\n# rclone configureren voor HiDrive SFTP\nrclone_config = \"\"\"[hidrive]\ntype = sftp\nhost = sftp.hidrive.strato.com\nuser = ronnyclouddisk\nkey_file = /root/.ssh/id_ed25519_hidrive\nshell_type = unix\n\"\"\"\nrclone_dir = Path('/root/.config/rclone')\nrclone_dir.mkdir(parents=True, exist_ok=True)\n(rclone_dir / 'rclone.conf').write_text(rclone_config)\n\n# HiDrive paden\nHIDRIVE_BASE = '/users/ronnyclouddisk/emsn-backups/vocalization-models'\nHIDRIVE_MODELS = f'{HIDRIVE_BASE}/v2'\nHIDRIVE_RESULTS = f'{HIDRIVE_BASE}/results'\n\n# Lokale paden\nDRIVE_BASE = '/content/EMSN-Vocalization'\nMODELS_DIR = f'{DRIVE_BASE}/models'\nAUDIO_DIR = f'{DRIVE_BASE}/audio'\nOWN_DATA_DIR = f'{DRIVE_BASE}/own_data'\n\nos.makedirs(MODELS_DIR, exist_ok=True)\nos.makedirs(AUDIO_DIR, exist_ok=True)\nos.makedirs(OWN_DATA_DIR, exist_ok=True)\n\n# Test verbinding en maak mappen aan\n!rclone mkdir hidrive:{HIDRIVE_MODELS}\n!rclone mkdir hidrive:{HIDRIVE_RESULTS}\n\n# Check ruimte\nprint(\"HiDrive verbinding testen...\")\nresult = !rclone about hidrive: 2>&1\nfor line in result:\n    print(f\"  {line}\")\n\n# Check bestaande modellen op HiDrive\nexisting = !rclone ls hidrive:{HIDRIVE_MODELS} 2>/dev/null | wc -l\nprint(f\"\\nBestaande v2 modellen op HiDrive: {existing[0].strip()}\")\n\n# === V2 CONFIGURATIE (Geoptimaliseerd voor Colab Pro+) ===\nVERSION = '2025_v2'\n\n# --- Training parameters ---\nEPOCHS = 80                    # Was 60 - meer epochs, A100 is snel genoeg\nLEARNING_RATE = 0.001\nMIN_LR = 0.00001\nPATIENCE = 15                  # Was 12 - meer geduld met meer epochs\nWEIGHT_DECAY = 0.01\nLABEL_SMOOTHING = 0.1          # NIEUW: voorkomt overconfident predictions\n\n# --- Data parameters (Pro+: meer data, meer workers) ---\nMAX_RECORDINGS_PER_TYPE = 75   # Was 50 - meer data = betere generalisatie\nMAX_SEGMENTS_PER_RECORDING = 5\nNUM_WORKERS = 8                # Was 4 - Colab Pro+ heeft 12 CPU cores\nMAX_CONCURRENT_DOWNLOADS = 20  # Was 10 - snellere downloads\n\n# --- Augmentation (Pro+: meer augmentatie) ---\nUSE_AUGMENTATION = True\nAUGMENTATION_FACTOR = 4        # Was 3 - meer variatie per sample\nUSE_MIXUP = True               # NIEUW: mixup augmentatie op spectrogrammen\nMIXUP_ALPHA = 0.3              # Beta distributie parameter\n\n# --- SpecAugment parameters ---\nFREQ_MASK_PARAM = 15\nTIME_MASK_PARAM = 20\nNUM_FREQ_MASKS = 2\nNUM_TIME_MASKS = 2\n\n# --- Focal Loss ---\nFOCAL_ALPHA = 0.25\nFOCAL_GAMMA = 2.0\n\n# Xeno-canto API key\nXC_API_KEY = '14258afd1c8a8e055387d012f2620e20f59ef3a2'\n\n# Upload functie voor gebruik na elke soort\ndef upload_model_to_hidrive(model_path):\n    \"\"\"Upload model naar HiDrive direct na training.\"\"\"\n    model_path = Path(model_path)\n    if model_path.exists():\n        os.system(f'rclone copy \"{model_path}\" hidrive:{HIDRIVE_MODELS}/ --progress')\n        return True\n    return False\n\ndef upload_results_to_hidrive():\n    \"\"\"Upload resultaten CSV en confusion JSON naar HiDrive.\"\"\"\n    for f in ['results_v2.csv', 'confusions_v2.json', 'results_v2.png', 'checkpoint_v2.csv']:\n        src = Path(f'{DRIVE_BASE}/{f}')\n        if src.exists():\n            os.system(f'rclone copy \"{src}\" hidrive:{HIDRIVE_RESULTS}/')\n\nprint(f\"\\n\\U0001f4ca EMSN VOCALIZATION TRAINING v2 (Pro+ Optimized)\")\nprint(f\"{'='*60}\")\nprint(f\"   GPU: {GPU_TYPE} | Batch: {BATCH_SIZE}\")\nprint(f\"   Epochs: {EPOCHS} | Patience: {PATIENCE}\")\nprint(f\"   Recordings/type: {MAX_RECORDINGS_PER_TYPE}\")\nprint(f\"   Augmentation: {AUGMENTATION_FACTOR}x + SpecAugment + Mixup\")\nprint(f\"   Label smoothing: {LABEL_SMOOTHING}\")\nprint(f\"   Loss: Focal (gamma={FOCAL_GAMMA})\")\nprint(f\"   Architecture: Deep Residual CNN + SE\")\nprint(f\"   Workers: {NUM_WORKERS} | Downloads: {MAX_CONCURRENT_DOWNLOADS}\")\nprint(f\"   torch.compile: {USE_TORCH_COMPILE}\")\nprint(f\"   Opslag: HiDrive SFTP (auto-upload)\")\nprint(f\"   Version: {VERSION}\")\nprint(f\"{'='*60}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cel 4: Eigen data uploaden (optioneel)\n",
    "#\n",
    "# Upload eigen gelabelde audio bestanden vanuit BirdNET-Pi.\n",
    "# Structuur: own_data/{soortnaam}/{song|call|alarm}/*.mp3\n",
    "#\n",
    "# Voorbeeld:\n",
    "#   own_data/vink/song/Vink-95-2026-01-15-birdnet-08:30:00.mp3\n",
    "#   own_data/vink/call/Vink-88-2026-01-15-birdnet-09:15:00.mp3\n",
    "#\n",
    "# Tip: Exporteer geverifieerde detecties uit BirdNET-Pi en label ze.\n",
    "\n",
    "from google.colab import files as colab_files\n",
    "import zipfile\n",
    "\n",
    "UPLOAD_OWN_DATA = False  # Zet op True om eigen data te uploaden\n",
    "\n",
    "if UPLOAD_OWN_DATA:\n",
    "    print(\"\\U0001f4e4 Upload een ZIP met eigen gelabelde audio...\")\n",
    "    print(\"Verwachte structuur: {soortnaam}/{song|call|alarm}/*.mp3\")\n",
    "    print()\n",
    "    uploaded = colab_files.upload()\n",
    "\n",
    "    for filename, data in uploaded.items():\n",
    "        if filename.endswith('.zip'):\n",
    "            zip_path = f'/content/{filename}'\n",
    "            with open(zip_path, 'wb') as f:\n",
    "                f.write(data)\n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                z.extractall(OWN_DATA_DIR)\n",
    "            print(f\"\\u2705 {filename} uitgepakt naar {OWN_DATA_DIR}\")\n",
    "\n",
    "    # Toon wat er ge-upload is\n",
    "    own_data_path = Path(OWN_DATA_DIR)\n",
    "    for species_dir in sorted(own_data_path.iterdir()):\n",
    "        if species_dir.is_dir():\n",
    "            for voc_dir in sorted(species_dir.iterdir()):\n",
    "                if voc_dir.is_dir():\n",
    "                    count = len(list(voc_dir.glob('*.mp3')))\n",
    "                    if count > 0:\n",
    "                        print(f\"  {species_dir.name}/{voc_dir.name}: {count} bestanden\")\n",
    "else:\n",
    "    print(\"\\u2139\\ufe0f Eigen data overgeslagen (UPLOAD_OWN_DATA = False)\")\n",
    "    print(\"Zet UPLOAD_OWN_DATA = True om BirdNET-Pi audio toe te voegen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cel 5: Alle 217 soorten\n",
    "\n",
    "ALL_SPECIES = [\n",
    "    # A\n",
    "    (\"Aalscholver\", \"Phalacrocorax carbo\", \"aalscholver\"),\n",
    "    (\"Appelvink\", \"Coccothraustes coccothraustes\", \"appelvink\"),\n",
    "    # B\n",
    "    (\"Baardman\", \"Panurus biarmicus\", \"baardman\"),\n",
    "    (\"Barmsijs\", \"Acanthis flammea\", \"barmsijs\"),\n",
    "    (\"Beflijster\", \"Turdus torquatus\", \"beflijster\"),\n",
    "    (\"Bergeend\", \"Tadorna tadorna\", \"bergeend\"),\n",
    "    (\"Bijeneter\", \"Merops apiaster\", \"bijeneter\"),\n",
    "    (\"Blauwborst\", \"Luscinia svecica\", \"blauwborst\"),\n",
    "    (\"Blauwe Kiekendief\", \"Circus cyaneus\", \"blauwe_kiekendief\"),\n",
    "    (\"Blauwe Reiger\", \"Ardea cinerea\", \"blauwe_reiger\"),\n",
    "    (\"Boerenzwaluw\", \"Hirundo rustica\", \"boerenzwaluw\"),\n",
    "    (\"Bokje\", \"Lymnocryptes minimus\", \"bokje\"),\n",
    "    (\"Bontbekplevier\", \"Charadrius hiaticula\", \"bontbekplevier\"),\n",
    "    (\"Bonte Kraai\", \"Corvus cornix\", \"bonte_kraai\"),\n",
    "    (\"Bonte Strandloper\", \"Calidris alpina\", \"bonte_strandloper\"),\n",
    "    (\"Bonte Vliegenvanger\", \"Ficedula hypoleuca\", \"bonte_vliegenvanger\"),\n",
    "    (\"Boomklever\", \"Sitta europaea\", \"boomklever\"),\n",
    "    (\"Boomkruiper\", \"Certhia brachydactyla\", \"boomkruiper\"),\n",
    "    (\"Boomleeuwerik\", \"Lullula arborea\", \"boomleeuwerik\"),\n",
    "    (\"Boompieper\", \"Anthus trivialis\", \"boompieper\"),\n",
    "    (\"Boomvalk\", \"Falco subbuteo\", \"boomvalk\"),\n",
    "    (\"Bosrietzanger\", \"Acrocephalus palustris\", \"bosrietzanger\"),\n",
    "    (\"Bosruiter\", \"Tringa glareola\", \"bosruiter\"),\n",
    "    (\"Bosuil\", \"Strix aluco\", \"bosuil\"),\n",
    "    (\"Braamsluiper\", \"Curruca curruca\", \"braamsluiper\"),\n",
    "    (\"Brandgans\", \"Branta leucopsis\", \"brandgans\"),\n",
    "    (\"Brilduiker\", \"Bucephala clangula\", \"brilduiker\"),\n",
    "    (\"Bruine Kiekendief\", \"Circus aeruginosus\", \"bruine_kiekendief\"),\n",
    "    (\"Buidelmees\", \"Remiz pendulinus\", \"buidelmees\"),\n",
    "    (\"Buizerd\", \"Buteo buteo\", \"buizerd\"),\n",
    "    # C\n",
    "    (\"Canadese Gans\", \"Branta canadensis\", \"canadese_gans\"),\n",
    "    (\"Cetti's Zanger\", \"Cettia cetti\", \"cettis_zanger\"),\n",
    "    (\"Citroenkanarie\", \"Crithagra citrinelloides\", \"citroenkanarie\"),\n",
    "    # D\n",
    "    (\"Dodaars\", \"Tachybaptus ruficollis\", \"dodaars\"),\n",
    "    (\"Draaihals\", \"Jynx torquilla\", \"draaihals\"),\n",
    "    (\"Drieteenstrandloper\", \"Calidris alba\", \"drieteenstrandloper\"),\n",
    "    (\"Dwergstern\", \"Sternula albifrons\", \"dwergstern\"),\n",
    "    # E\n",
    "    (\"Eider\", \"Somateria mollissima\", \"eider\"),\n",
    "    (\"Ekster\", \"Pica pica\", \"ekster\"),\n",
    "    (\"Europese Kanarie\", \"Serinus serinus\", \"europese_kanarie\"),\n",
    "    # F\n",
    "    (\"Fazant\", \"Phasianus colchicus\", \"fazant\"),\n",
    "    (\"Fitis\", \"Phylloscopus trochilus\", \"fitis\"),\n",
    "    (\"Flamingo\", \"Phoenicopterus roseus\", \"flamingo\"),\n",
    "    (\"Fluiter\", \"Phylloscopus sibilatrix\", \"fluiter\"),\n",
    "    (\"Fuut\", \"Podiceps cristatus\", \"fuut\"),\n",
    "    # G\n",
    "    (\"Gaai\", \"Garrulus glandarius\", \"gaai\"),\n",
    "    (\"Geelgors\", \"Emberiza citrinella\", \"geelgors\"),\n",
    "    (\"Gekraagde Roodstaart\", \"Phoenicurus phoenicurus\", \"gekraagde_roodstaart\"),\n",
    "    (\"Gele Kwikstaart\", \"Motacilla flava\", \"gele_kwikstaart\"),\n",
    "    (\"Gierzwaluw\", \"Apus apus\", \"gierzwaluw\"),\n",
    "    (\"Glanskop\", \"Poecile palustris\", \"glanskop\"),\n",
    "    (\"Goudhaan\", \"Regulus regulus\", \"goudhaan\"),\n",
    "    (\"Goudplevier\", \"Pluvialis apricaria\", \"goudplevier\"),\n",
    "    (\"Goudvink\", \"Pyrrhula pyrrhula\", \"goudvink\"),\n",
    "    (\"Grasmus\", \"Curruca communis\", \"grasmus\"),\n",
    "    (\"Graspieper\", \"Anthus pratensis\", \"graspieper\"),\n",
    "    (\"Graszanger\", \"Cisticola juncidis\", \"graszanger\"),\n",
    "    (\"Grauwe Gans\", \"Anser anser\", \"grauwe_gans\"),\n",
    "    (\"Grauwe Kiekendief\", \"Circus pygargus\", \"grauwe_kiekendief\"),\n",
    "    (\"Grauwe Klauwier\", \"Lanius collurio\", \"grauwe_klauwier\"),\n",
    "    (\"Grauwe Vliegenvanger\", \"Muscicapa striata\", \"grauwe_vliegenvanger\"),\n",
    "    (\"Groene Specht\", \"Picus viridis\", \"groene_specht\"),\n",
    "    (\"Groenling\", \"Chloris chloris\", \"groenling\"),\n",
    "    (\"Groenpootruiter\", \"Tringa nebularia\", \"groenpootruiter\"),\n",
    "    (\"Grote Bonte Specht\", \"Dendrocopos major\", \"grote_bonte_specht\"),\n",
    "    (\"Grote Canadese Gans\", \"Branta canadensis\", \"grote_canadese_gans\"),\n",
    "    (\"Grote Gele Kwikstaart\", \"Motacilla cinerea\", \"grote_gele_kwikstaart\"),\n",
    "    (\"Grote Karekiet\", \"Acrocephalus arundinaceus\", \"grote_karekiet\"),\n",
    "    (\"Grote Lijster\", \"Turdus viscivorus\", \"grote_lijster\"),\n",
    "    (\"Grote Mantelmeeuw\", \"Larus marinus\", \"grote_mantelmeeuw\"),\n",
    "    (\"Grote Zaagbek\", \"Mergus merganser\", \"grote_zaagbek\"),\n",
    "    (\"Grote Zilverreiger\", \"Ardea alba\", \"grote_zilverreiger\"),\n",
    "    (\"Grutto\", \"Limosa limosa\", \"grutto\"),\n",
    "    # H\n",
    "    (\"Haakbek\", \"Pinicola enucleator\", \"haakbek\"),\n",
    "    (\"Havik\", \"Accipiter gentilis\", \"havik\"),\n",
    "    (\"Heggenmus\", \"Prunella modularis\", \"heggenmus\"),\n",
    "    (\"Holenduif\", \"Columba oenas\", \"holenduif\"),\n",
    "    (\"Hop\", \"Upupa epops\", \"hop\"),\n",
    "    (\"Houtduif\", \"Columba palumbus\", \"houtduif\"),\n",
    "    (\"Houtsnip\", \"Scolopax rusticola\", \"houtsnip\"),\n",
    "    (\"Huismus\", \"Passer domesticus\", \"huismus\"),\n",
    "    (\"Huiszwaluw\", \"Delichon urbicum\", \"huiszwaluw\"),\n",
    "    # I\n",
    "    (\"IJsvogel\", \"Alcedo atthis\", \"ijsvogel\"),\n",
    "    # K\n",
    "    (\"Kanoetstrandloper\", \"Calidris canutus\", \"kanoetstrandloper\"),\n",
    "    (\"Kauw\", \"Coloeus monedula\", \"kauw\"),\n",
    "    (\"Keep\", \"Fringilla montifringilla\", \"keep\"),\n",
    "    (\"Kerkuil\", \"Tyto alba\", \"kerkuil\"),\n",
    "    (\"Kievit\", \"Vanellus vanellus\", \"kievit\"),\n",
    "    (\"Klapekster\", \"Lanius excubitor\", \"klapekster\"),\n",
    "    (\"Kleine Bonte Specht\", \"Dryobates minor\", \"kleine_bonte_specht\"),\n",
    "    (\"Kleine Karekiet\", \"Acrocephalus scirpaceus\", \"kleine_karekiet\"),\n",
    "    (\"Kleine Mantelmeeuw\", \"Larus fuscus\", \"kleine_mantelmeeuw\"),\n",
    "    (\"Kleine Rietgans\", \"Anser brachyrhynchus\", \"kleine_rietgans\"),\n",
    "    (\"Kleine Strandloper\", \"Calidris minuta\", \"kleine_strandloper\"),\n",
    "    (\"Kleine Zilverreiger\", \"Egretta garzetta\", \"kleine_zilverreiger\"),\n",
    "    (\"Kleine Zwaan\", \"Cygnus columbianus\", \"kleine_zwaan\"),\n",
    "    (\"Kluut\", \"Recurvirostra avosetta\", \"kluut\"),\n",
    "    (\"Kneu\", \"Linaria cannabina\", \"kneu\"),\n",
    "    (\"Knobbelzwaan\", \"Cygnus olor\", \"knobbelzwaan\"),\n",
    "    (\"Koekoek\", \"Cuculus canorus\", \"koekoek\"),\n",
    "    (\"Kokmeeuw\", \"Chroicocephalus ridibundus\", \"kokmeeuw\"),\n",
    "    (\"Kolgans\", \"Anser albifrons\", \"kolgans\"),\n",
    "    (\"Koolmees\", \"Parus major\", \"koolmees\"),\n",
    "    (\"Koperwiek\", \"Turdus iliacus\", \"koperwiek\"),\n",
    "    (\"Kraanvogel\", \"Grus grus\", \"kraanvogel\"),\n",
    "    (\"Krakeend\", \"Mareca strepera\", \"krakeend\"),\n",
    "    (\"Kramsvogel\", \"Turdus pilaris\", \"kramsvogel\"),\n",
    "    (\"Kruisbek\", \"Loxia curvirostra\", \"kruisbek\"),\n",
    "    (\"Kuifeend\", \"Aythya fuligula\", \"kuifeend\"),\n",
    "    (\"Kuifmees\", \"Lophophanes cristatus\", \"kuifmees\"),\n",
    "    (\"Kwak\", \"Nycticorax nycticorax\", \"kwak\"),\n",
    "    (\"Kwartel\", \"Coturnix coturnix\", \"kwartel\"),\n",
    "    (\"Kwartelkoning\", \"Crex crex\", \"kwartelkoning\"),\n",
    "    # M\n",
    "    (\"Mandarijneend\", \"Aix galericulata\", \"mandarijneend\"),\n",
    "    (\"Matkop\", \"Poecile montanus\", \"matkop\"),\n",
    "    (\"Meerkoet\", \"Fulica atra\", \"meerkoet\"),\n",
    "    (\"Merel\", \"Turdus merula\", \"merel\"),\n",
    "    (\"Middelste Zaagbek\", \"Mergus serrator\", \"middelste_zaagbek\"),\n",
    "    # N\n",
    "    (\"Nachtegaal\", \"Luscinia megarhynchos\", \"nachtegaal\"),\n",
    "    (\"Nachtzwaluw\", \"Caprimulgus europaeus\", \"nachtzwaluw\"),\n",
    "    (\"Nijlgans\", \"Alopochen aegyptiaca\", \"nijlgans\"),\n",
    "    (\"Nonnetje\", \"Mergellus albellus\", \"nonnetje\"),\n",
    "    # O\n",
    "    (\"Oehoe\", \"Bubo bubo\", \"oehoe\"),\n",
    "    (\"Oeverloper\", \"Actitis hypoleucos\", \"oeverloper\"),\n",
    "    (\"Oeverzwaluw\", \"Riparia riparia\", \"oeverzwaluw\"),\n",
    "    (\"Ooievaar\", \"Ciconia ciconia\", \"ooievaar\"),\n",
    "    # P\n",
    "    (\"Paapje\", \"Saxicola rubetra\", \"paapje\"),\n",
    "    (\"Patrijs\", \"Perdix perdix\", \"patrijs\"),\n",
    "    (\"Pestvogel\", \"Bombycilla garrulus\", \"pestvogel\"),\n",
    "    (\"Pijlstaart\", \"Anas acuta\", \"pijlstaart\"),\n",
    "    (\"Pimpelmees\", \"Cyanistes caeruleus\", \"pimpelmees\"),\n",
    "    (\"Porseleinhoen\", \"Porzana porzana\", \"porseleinhoen\"),\n",
    "    (\"Putter\", \"Carduelis carduelis\", \"putter\"),\n",
    "    # R\n",
    "    (\"Raaf\", \"Corvus corax\", \"raaf\"),\n",
    "    (\"Ransuil\", \"Asio otus\", \"ransuil\"),\n",
    "    (\"Regenwulp\", \"Numenius phaeopus\", \"regenwulp\"),\n",
    "    (\"Rietgors\", \"Emberiza schoeniclus\", \"rietgors\"),\n",
    "    (\"Rietzanger\", \"Acrocephalus schoenobaenus\", \"rietzanger\"),\n",
    "    (\"Rode Wouw\", \"Milvus milvus\", \"rode_wouw\"),\n",
    "    (\"Roek\", \"Corvus frugilegus\", \"roek\"),\n",
    "    (\"Roerdomp\", \"Botaurus stellaris\", \"roerdomp\"),\n",
    "    (\"Roodborst\", \"Erithacus rubecula\", \"roodborst\"),\n",
    "    (\"Roodborsttapuit\", \"Saxicola rubicola\", \"roodborsttapuit\"),\n",
    "    (\"Roodhalsfuut\", \"Podiceps grisegena\", \"roodhalsfuut\"),\n",
    "    (\"Rosse Grutto\", \"Limosa lapponica\", \"rosse_grutto\"),\n",
    "    (\"Rotsduif\", \"Columba livia\", \"rotsduif\"),\n",
    "    # S\n",
    "    (\"Scharrelaar\", \"Coracias garrulus\", \"scharrelaar\"),\n",
    "    (\"Scholekster\", \"Haematopus ostralegus\", \"scholekster\"),\n",
    "    (\"Sijs\", \"Spinus spinus\", \"sijs\"),\n",
    "    (\"Slechtvalk\", \"Falco peregrinus\", \"slechtvalk\"),\n",
    "    (\"Slobeend\", \"Spatula clypeata\", \"slobeend\"),\n",
    "    (\"Smelleken\", \"Falco columbarius\", \"smelleken\"),\n",
    "    (\"Smient\", \"Mareca penelope\", \"smient\"),\n",
    "    (\"Snor\", \"Locustella luscinioides\", \"snor\"),\n",
    "    (\"Sperwer\", \"Accipiter nisus\", \"sperwer\"),\n",
    "    (\"Spotvogel\", \"Hippolais icterina\", \"spotvogel\"),\n",
    "    (\"Spreeuw\", \"Sturnus vulgaris\", \"spreeuw\"),\n",
    "    (\"Sprinkhaanzanger\", \"Locustella naevia\", \"sprinkhaanzanger\"),\n",
    "    (\"Staartmees\", \"Aegithalos caudatus\", \"staartmees\"),\n",
    "    (\"Stadsduif\", \"Columba livia domestica\", \"stadsduif\"),\n",
    "    (\"Steenloper\", \"Arenaria interpres\", \"steenloper\"),\n",
    "    (\"Steenuil\", \"Athene noctua\", \"steenuil\"),\n",
    "    (\"Stormmeeuw\", \"Larus canus\", \"stormmeeuw\"),\n",
    "    # T\n",
    "    (\"Tafeleend\", \"Aythya ferina\", \"tafeleend\"),\n",
    "    (\"Taigaboomkruiper\", \"Certhia familiaris\", \"taigaboomkruiper\"),\n",
    "    (\"Tapuit\", \"Oenanthe oenanthe\", \"tapuit\"),\n",
    "    (\"Tjiftjaf\", \"Phylloscopus collybita\", \"tjiftjaf\"),\n",
    "    (\"Toendrarietgans\", \"Anser serrirostris\", \"toendrarietgans\"),\n",
    "    (\"Torenvalk\", \"Falco tinnunculus\", \"torenvalk\"),\n",
    "    (\"Tuinfluiter\", \"Sylvia borin\", \"tuinfluiter\"),\n",
    "    (\"Tureluur\", \"Tringa totanus\", \"tureluur\"),\n",
    "    (\"Turkse Tortel\", \"Streptopelia decaocto\", \"turkse_tortel\"),\n",
    "    # V\n",
    "    (\"Veldleeuwerik\", \"Alauda arvensis\", \"veldleeuwerik\"),\n",
    "    (\"Velduil\", \"Asio flammeus\", \"velduil\"),\n",
    "    (\"Vink\", \"Fringilla coelebs\", \"vink\"),\n",
    "    (\"Visdief\", \"Sterna hirundo\", \"visdief\"),\n",
    "    (\"Vuurgoudhaan\", \"Regulus ignicapilla\", \"vuurgoudhaan\"),\n",
    "    # W\n",
    "    (\"Waterhoen\", \"Gallinula chloropus\", \"waterhoen\"),\n",
    "    (\"Waterral\", \"Rallus aquaticus\", \"waterral\"),\n",
    "    (\"Watersnip\", \"Gallinago gallinago\", \"watersnip\"),\n",
    "    (\"Wielewaal\", \"Oriolus oriolus\", \"wielewaal\"),\n",
    "    (\"Wilde Eend\", \"Anas platyrhynchos\", \"wilde_eend\"),\n",
    "    (\"Wilde Zwaan\", \"Cygnus cygnus\", \"wilde_zwaan\"),\n",
    "    (\"Winterkoning\", \"Troglodytes troglodytes\", \"winterkoning\"),\n",
    "    (\"Wintertaling\", \"Anas crecca\", \"wintertaling\"),\n",
    "    (\"Witgat\", \"Tringa ochropus\", \"witgat\"),\n",
    "    (\"Witte Kwikstaart\", \"Motacilla alba\", \"witte_kwikstaart\"),\n",
    "    (\"Wulp\", \"Numenius arquata\", \"wulp\"),\n",
    "    # Z\n",
    "    (\"Zanglijster\", \"Turdus philomelos\", \"zanglijster\"),\n",
    "    (\"Zilvermeeuw\", \"Larus argentatus\", \"zilvermeeuw\"),\n",
    "    (\"Zomertortel\", \"Streptopelia turtur\", \"zomertortel\"),\n",
    "    (\"Zwarte Kraai\", \"Corvus corone\", \"zwarte_kraai\"),\n",
    "    (\"Zwarte Mees\", \"Periparus ater\", \"zwarte_mees\"),\n",
    "    (\"Zwarte Roodstaart\", \"Phoenicurus ochruros\", \"zwarte_roodstaart\"),\n",
    "    (\"Zwarte Ruiter\", \"Tringa erythropus\", \"zwarte_ruiter\"),\n",
    "    (\"Zwarte Specht\", \"Dryocopus martius\", \"zwarte_specht\"),\n",
    "    (\"Zwartkop\", \"Sylvia atricapilla\", \"zwartkop\"),\n",
    "]\n",
    "\n",
    "print(f\"Te trainen: {len(ALL_SPECIES)} soorten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cel 6: Xeno-canto API + Download functies\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "def search_xeno_canto(scientific_name, voc_type='song', max_results=100):\n",
    "    \"\"\"Zoek opnames op Xeno-canto API v3.\"\"\"\n",
    "    parts = scientific_name.split()\n",
    "    if len(parts) < 2:\n",
    "        return []\n",
    "\n",
    "    genus, species = parts[0].lower(), parts[1].lower()\n",
    "\n",
    "    if ' ' in voc_type:\n",
    "        type_query = f'type:\"{voc_type}\"'\n",
    "    else:\n",
    "        type_query = f'type:{voc_type}'\n",
    "\n",
    "    # Kwaliteit A = beste opnames\n",
    "    query = f'gen:{genus} sp:{species} {type_query} q:A'\n",
    "    url = f'https://xeno-canto.org/api/3/recordings?query={query}&key={XC_API_KEY}'\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get('recordings', [])[:max_results]\n",
    "        return []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def download_single(args):\n",
    "    recording, output_dir = args\n",
    "    xc_id = recording['id']\n",
    "    file_url = recording.get('file', '')\n",
    "\n",
    "    if not file_url:\n",
    "        return None\n",
    "\n",
    "    if file_url.startswith('//'):\n",
    "        file_url = 'https:' + file_url\n",
    "    elif not file_url.startswith('http'):\n",
    "        file_url = 'https://xeno-canto.org' + file_url\n",
    "\n",
    "    output_path = output_dir / f\"XC{xc_id}.mp3\"\n",
    "\n",
    "    if output_path.exists():\n",
    "        return output_path\n",
    "\n",
    "    try:\n",
    "        response = requests.get(file_url, timeout=60)\n",
    "        if response.status_code == 200:\n",
    "            with open(output_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return output_path\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def download_recordings_parallel(recordings, output_dir, max_workers=10):\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    downloaded = []\n",
    "    args_list = [(rec, output_dir) for rec in recordings]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(download_single, args): args[0]['id']\n",
    "            for args in args_list\n",
    "        }\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                downloaded.append(result)\n",
    "\n",
    "    return downloaded\n",
    "\n",
    "\n",
    "print(\"\\u2705 Download functies geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cel 7: Spectrogram generatie + SpecAugment + Audio Augmentation + Mixup\nimport librosa\nimport numpy as np\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\n\nSAMPLE_RATE = 48000\nN_MELS = 128\nN_FFT = 2048\nHOP_LENGTH = 512\nFMIN = 500\nFMAX = 8000\nSEGMENT_DURATION = 3.0\n\n\n# --- SpecAugment: masking op spectrogrammen ---\n\ndef spec_augment(mel_spec, num_freq_masks=NUM_FREQ_MASKS, freq_mask_param=FREQ_MASK_PARAM,\n                 num_time_masks=NUM_TIME_MASKS, time_mask_param=TIME_MASK_PARAM):\n    \"\"\"\n    SpecAugment: frequency en time masking op mel spectrogram.\n    Paper: Park et al. 2019 - \"SpecAugment: A Simple Data Augmentation Method\n    for Automatic Speech Recognition\"\n    \"\"\"\n    spec = mel_spec.copy()\n    n_mels, n_frames = spec.shape\n\n    # Frequency masking - maskeert horizontale banden\n    for _ in range(num_freq_masks):\n        f = np.random.randint(0, freq_mask_param + 1)\n        f0 = np.random.randint(0, max(1, n_mels - f))\n        spec[f0:f0 + f, :] = 0.0\n\n    # Time masking - maskeert verticale banden\n    for _ in range(num_time_masks):\n        t = np.random.randint(0, time_mask_param + 1)\n        t0 = np.random.randint(0, max(1, n_frames - t))\n        spec[:, t0:t0 + t] = 0.0\n\n    return spec\n\n\n# --- Mixup augmentatie op spectrogrammen ---\n\ndef mixup_data(X, y, alpha=0.3):\n    \"\"\"\n    Mixup augmentatie: lineaire interpolatie tussen samples.\n    Paper: Zhang et al. 2018 - \"mixup: Beyond Empirical Risk Minimization\"\n\n    Genereert zachte labels: lambda * class_a + (1-lambda) * class_b\n    Dit verbetert generalisatie en vermindert overfitting significant.\n    \"\"\"\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.0\n\n    batch_size = len(X)\n    indices = np.random.permutation(batch_size)\n\n    mixed_X = lam * X + (1 - lam) * X[indices]\n    y_a, y_b = y, y[indices]\n\n    return mixed_X, y_a, y_b, lam\n\n\n# --- Audio augmentation functies ---\n\ndef augment_audio(audio, sr):\n    \"\"\"\n    Genereer geaugmenteerde versies van audio.\n    Pro+: meer variatie, extra augmentaties.\n    \"\"\"\n    augmented = []\n    target_len = len(audio)\n\n    # 1. Pitch shift (+/- 1-3 semitones, random)\n    try:\n        n_steps = np.random.choice([-3, -2, -1, 1, 2, 3])\n        shifted = librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n        augmented.append(shifted)\n    except Exception:\n        pass\n\n    # 2. Time stretch (random factor 0.85-1.15)\n    try:\n        rate = np.random.uniform(0.85, 1.15)\n        stretched = librosa.effects.time_stretch(audio, rate=rate)\n        if len(stretched) > target_len:\n            stretched = stretched[:target_len]\n        else:\n            stretched = np.pad(stretched, (0, target_len - len(stretched)))\n        augmented.append(stretched)\n    except Exception:\n        pass\n\n    # 3. Volume scaling (random -6dB tot +6dB)\n    gain_db = np.random.uniform(-6, 6)\n    gain_linear = 10 ** (gain_db / 20)\n    volume_scaled = np.clip(audio * gain_linear, -1.0, 1.0)\n    augmented.append(volume_scaled)\n\n    # 4. Pink noise (realistischer dan Gaussian voor buitenopnames)\n    pink = _generate_pink_noise(target_len)\n    snr_db = np.random.uniform(15, 25)  # Realistische SNR range\n    signal_power = np.mean(audio ** 2) + 1e-10\n    noise_power = signal_power / (10 ** (snr_db / 10))\n    noisy = audio + pink * np.sqrt(noise_power / (np.mean(pink ** 2) + 1e-10))\n    augmented.append(np.clip(noisy, -1.0, 1.0).astype(np.float32))\n\n    # 5. Combinatie: pitch + noise\n    if len(augmented) >= 2:\n        combo = augmented[0] + pink * np.sqrt(noise_power / (np.mean(pink ** 2) + 1e-10)) * 0.5\n        augmented.append(np.clip(combo, -1.0, 1.0).astype(np.float32))\n\n    # 6. Random frequency filter (high-pass of low-pass, simuleert afstand)\n    try:\n        if np.random.random() > 0.5:\n            # High-pass: verwijdert lage frequenties (alsof geluid van ver komt)\n            cutoff = np.random.randint(200, 800)\n            from scipy.signal import butter, sosfilt\n            sos = butter(4, cutoff, btype='high', fs=sr, output='sos')\n            filtered = sosfilt(sos, audio).astype(np.float32)\n            augmented.append(np.clip(filtered, -1.0, 1.0))\n    except Exception:\n        pass\n\n    return augmented\n\n\ndef _generate_pink_noise(n_samples):\n    \"\"\"Genereer pink noise (1/f) - realistischer dan wit/Gaussian.\"\"\"\n    white = np.random.randn(n_samples)\n    fft = np.fft.rfft(white)\n    freqs = np.fft.rfftfreq(n_samples)\n    freqs[0] = 1  # Voorkom deling door 0\n    fft = fft / np.sqrt(freqs)\n    pink = np.fft.irfft(fft, n=n_samples)\n    pink = pink / (np.max(np.abs(pink)) + 1e-10)\n    return pink.astype(np.float32)\n\n\n# --- Spectrogram conversie ---\n\ndef audio_to_spectrogram(audio, sr=SAMPLE_RATE, apply_spec_augment=False):\n    \"\"\"Converteer audio naar mel spectrogram, optioneel met SpecAugment.\"\"\"\n    mel_spec = librosa.feature.melspectrogram(\n        y=audio, sr=sr,\n        n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH,\n        fmin=FMIN, fmax=FMAX\n    )\n    mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n    mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-8)\n\n    # SpecAugment toepassen op training data\n    if apply_spec_augment:\n        mel_norm = spec_augment(mel_norm)\n\n    if mel_norm.shape != (128, 128):\n        from skimage.transform import resize\n        mel_norm = resize(mel_norm, (128, 128), anti_aliasing=True)\n\n    return mel_norm.astype(np.float32)\n\n\ndef process_single_audio(audio_path, max_segments=5, use_augmentation=True):\n    \"\"\"Verwerk audio naar spectrogrammen met augmentation + SpecAugment.\"\"\"\n    try:\n        audio, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE, mono=True)\n    except Exception:\n        return []\n\n    segment_samples = int(SEGMENT_DURATION * SAMPLE_RATE)\n    spectrograms = []\n    segments_processed = 0\n\n    for i in range(0, len(audio), segment_samples):\n        if segments_processed >= max_segments:\n            break\n\n        segment = audio[i:i + segment_samples]\n        if len(segment) < segment_samples // 2:\n            continue\n\n        if len(segment) < segment_samples:\n            segment = np.pad(segment, (0, segment_samples - len(segment)))\n\n        # Origineel (zonder SpecAugment)\n        spec = audio_to_spectrogram(segment, apply_spec_augment=False)\n        spectrograms.append(spec)\n\n        # Origineel met SpecAugment\n        spec_aug = audio_to_spectrogram(segment, apply_spec_augment=True)\n        spectrograms.append(spec_aug)\n\n        if use_augmentation:\n            # Audio augmentaties\n            aug_segments = augment_audio(segment, SAMPLE_RATE)\n            for aug_seg in aug_segments[:AUGMENTATION_FACTOR]:\n                # Geaugmenteerde audio + SpecAugment (50% kans)\n                apply_sa = np.random.random() > 0.5\n                aug_spec = audio_to_spectrogram(aug_seg, apply_spec_augment=apply_sa)\n                spectrograms.append(aug_spec)\n\n        segments_processed += 1\n\n    return spectrograms\n\n\ndef process_audio_files_parallel(audio_paths, max_segments=5, max_workers=None,\n                                  use_augmentation=True):\n    \"\"\"Parallel audio processing met automatisch worker count.\"\"\"\n    if max_workers is None:\n        max_workers = NUM_WORKERS\n\n    all_specs = []\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        func = partial(process_single_audio, max_segments=max_segments,\n                       use_augmentation=use_augmentation)\n        results = list(executor.map(func, audio_paths))\n    for specs in results:\n        all_specs.extend(specs)\n    return all_specs\n\n\nprint(\"\\u2705 Spectrogram + SpecAugment + Audio Augmentation + Mixup geladen\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cel 8: Deep Residual CNN Model + Focal Loss (Pro+ Optimized)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass ResidualBlock(nn.Module):\n    \"\"\"Residual block met skip connection.\"\"\"\n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.dropout = nn.Dropout2d(0.2)\n\n        # Skip connection met 1x1 conv als dimensies niet matchen\n        self.skip = nn.Identity()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        identity = self.skip(x)\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.dropout(out)\n        out = self.bn2(self.conv2(out))\n        out = F.relu(out + identity)  # Skip connection\n        return out\n\n\nclass VocalizationResNet(nn.Module):\n    \"\"\"\n    Deep Residual CNN voor vocalisatie classificatie (Pro+ versie).\n\n    Verbeteringen t.o.v. standaard v2:\n    - 4 residual blocks (was 3) - dieper model, A100 heeft de memory\n    - Bredere SE bottleneck (128 ipv 64)\n    - Grotere classifier (256->128 ipv 128 direct)\n    \"\"\"\n\n    def __init__(self, num_classes=3):\n        super().__init__()\n\n        # Stem: initieel conv blok\n        self.stem = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n\n        # Residual blocks: 32 -> 64 -> 128 -> 256 -> 512\n        self.layer1 = ResidualBlock(32, 64, stride=1)\n        self.layer2 = ResidualBlock(64, 128, stride=2)\n        self.layer3 = ResidualBlock(128, 256, stride=2)\n        self.layer4 = ResidualBlock(256, 512, stride=2)  # NIEUW: extra diepte\n\n        # Squeeze-and-Excitation (channel attention) - breder\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(512, 128),       # Was 256->64\n            nn.ReLU(),\n            nn.Linear(128, 512),       # Was 64->256\n            nn.Sigmoid()\n        )\n\n        # Global Average Pooling + Deeper Classifier\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(512, 256),       # Was 256->128\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 128),       # NIEUW: extra layer\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        # Channel attention\n        se_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n        x = x * se_weight\n\n        x = self.gap(x)\n        x = self.classifier(x)\n        return x\n\n\nclass FocalLoss(nn.Module):\n    \"\"\"\n    Focal Loss met label smoothing voor ongebalanceerde klassen.\n    Combineert twee technieken:\n    - Focal: meer gewicht aan moeilijke/zeldzame voorbeelden\n    - Label smoothing: voorkomt overconfident predictions\n\n    Papers:\n    - Lin et al. 2017 - \"Focal Loss for Dense Object Detection\"\n    - Szegedy et al. 2016 - \"Rethinking the Inception Architecture\"\n    \"\"\"\n\n    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.0):\n        super().__init__()\n        self.alpha = alpha  # Per-class weging\n        self.gamma = gamma\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(\n            inputs, targets,\n            weight=self.alpha,\n            reduction='none',\n            label_smoothing=self.label_smoothing\n        )\n        p_t = torch.exp(-ce_loss)\n        focal_loss = ((1 - p_t) ** self.gamma) * ce_loss\n        return focal_loss.mean()\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\u2705 Deep Residual CNN + Focal Loss klaar voor {device}\")\n\n# Test model\ntest_model = VocalizationResNet(num_classes=3).to(device)\ntest_input = torch.randn(4, 1, 128, 128).to(device)\ntest_output = test_model(test_input)\nparams = sum(p.numel() for p in test_model.parameters())\nprint(f\"   Parameters: {params:,} ({params/1e6:.1f}M)\")\nprint(f\"   Output shape: {test_output.shape}\")\nprint(f\"   Architecture: 4 ResBlocks + SE(512->128->512) + Classifier(512->256->128->N)\")\ndel test_model, test_input, test_output"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cel 9: Training Pipeline v2 Pro+ (torch.compile, mixup, AMP)\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom sklearn.metrics import confusion_matrix\n\n\ndef compute_class_weights(y, num_classes, device):\n    \"\"\"Bereken inverse frequency weights voor Focal Loss.\"\"\"\n    counts = np.bincount(y, minlength=num_classes).astype(np.float32)\n    counts = np.maximum(counts, 1)  # Voorkom deling door 0\n    weights = 1.0 / counts\n    weights = weights / weights.sum() * num_classes  # Normaliseer\n    return torch.FloatTensor(weights).to(device)\n\n\ndef calibrate_temperature(model, val_loader, device):\n    \"\"\"\n    Temperature scaling voor gekalibreerde confidence.\n    Zoekt optimale temperature T zodat softmax(logits/T) goed gekalibreerd is.\n    \"\"\"\n    model.eval()\n    logits_list, labels_list = [], []\n\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch = X_batch.to(device)\n            logits = model(X_batch)\n            logits_list.append(logits.cpu())\n            labels_list.append(y_batch)\n\n    logits_all = torch.cat(logits_list)\n    labels_all = torch.cat(labels_list)\n\n    # Grid search voor optimale temperature\n    best_t = 1.0\n    best_nll = float('inf')\n\n    for t in np.arange(0.5, 5.0, 0.1):\n        scaled = logits_all / t\n        nll = F.cross_entropy(scaled, labels_all).item()\n        if nll < best_nll:\n            best_nll = nll\n            best_t = t\n\n    return best_t\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    \"\"\"Focal Loss met mixup labels.\"\"\"\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n\ndef train_species_v2(dutch_name, scientific_name, dirname):\n    \"\"\"\n    V2 Pro+ training met:\n    - SpecAugment + Mixup augmentatie\n    - Deep Residual CNN (4 blocks)\n    - Focal Loss + Label Smoothing\n    - torch.compile() voor snelheid\n    - AMP (Automatic Mixed Precision) op A100/L4\n    - Persistent DataLoader workers\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"\\U0001f426 {dutch_name} ({scientific_name})\")\n    print(f\"{'='*60}\")\n\n    start_time = time.time()\n    audio_dir = Path(f'{DRIVE_BASE}/audio/{dirname}')\n\n    X_all, y_all = [], []\n    voc_types = [('song', 0), ('call', 1), ('alarm call', 2)]\n\n    # --- Stap 1: Download Xeno-canto data ---\n    for voc_type, label in voc_types:\n        print(f\"  \\U0001f4e5 {voc_type}...\", end=' ')\n        recordings = search_xeno_canto(scientific_name, voc_type,\n                                       max_results=MAX_RECORDINGS_PER_TYPE)\n\n        if not recordings:\n            print(\"0 gevonden\")\n            continue\n\n        type_dir = audio_dir / voc_type.replace(' ', '_')\n        audio_files = download_recordings_parallel(\n            recordings[:MAX_RECORDINGS_PER_TYPE],\n            type_dir,\n            max_workers=MAX_CONCURRENT_DOWNLOADS\n        )\n        print(f\"{len(audio_files)} files\", end=' ')\n\n        if audio_files:\n            specs = process_audio_files_parallel(\n                audio_files,\n                max_segments=MAX_SEGMENTS_PER_RECORDING,\n                max_workers=NUM_WORKERS,\n                use_augmentation=USE_AUGMENTATION\n            )\n            for spec in specs:\n                X_all.append(spec)\n                y_all.append(label)\n            print(f\"\\u2192 {len(specs)} specs\")\n        else:\n            print()\n\n    # --- Stap 2: Eigen data toevoegen ---\n    own_species_dir = Path(OWN_DATA_DIR) / dirname\n    if own_species_dir.exists():\n        own_count = 0\n        type_map = {'song': 0, 'call': 1, 'alarm': 2}\n        for voc_name, label in type_map.items():\n            own_type_dir = own_species_dir / voc_name\n            if own_type_dir.exists():\n                own_files = list(own_type_dir.glob('*.mp3'))\n                if own_files:\n                    specs = process_audio_files_parallel(\n                        own_files,\n                        max_segments=MAX_SEGMENTS_PER_RECORDING,\n                        max_workers=NUM_WORKERS,\n                        use_augmentation=True\n                    )\n                    for spec in specs:\n                        X_all.append(spec)\n                        y_all.append(label)\n                    own_count += len(specs)\n        if own_count > 0:\n            print(f\"  \\U0001f3af Eigen data: +{own_count} specs\")\n\n    if len(X_all) < 30:\n        print(f\"  \\u26a0\\ufe0f Te weinig data ({len(X_all)})\")\n        return None, 'insufficient_data', {}\n\n    X = np.array(X_all)\n    y = np.array(y_all)\n\n    # Label remapping\n    unique_labels = np.unique(y)\n    num_classes = len(unique_labels)\n\n    if num_classes < 2:\n        print(f\"  \\u26a0\\ufe0f Slechts 1 klasse\")\n        return None, 'single_class', {}\n\n    label_map = {old: new for new, old in enumerate(unique_labels)}\n    y_remapped = np.array([label_map[l] for l in y])\n\n    all_class_names = ['song', 'call', 'alarm']\n    class_names = [all_class_names[l] for l in unique_labels]\n\n    unique, counts = np.unique(y_remapped, return_counts=True)\n    class_dist = {class_names[i]: int(counts[i]) for i in range(len(counts))}\n    print(f\"  \\U0001f4ca {len(X)} specs: {class_dist}\")\n\n    # --- Stap 3: Train/Val/Test split (70/15/15) ---\n    X_trainval, X_test, y_trainval, y_test = train_test_split(\n        X, y_remapped, test_size=0.15, random_state=42, stratify=y_remapped\n    )\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_trainval, y_trainval, test_size=0.176,  # 0.176 * 0.85 ~= 0.15\n        random_state=42, stratify=y_trainval\n    )\n    print(f\"  Split: train={len(X_train)} val={len(X_val)} test={len(X_test)}\")\n\n    # DataLoaders met persistent workers (hergebruikt worker processen)\n    train_loader = DataLoader(\n        TensorDataset(torch.FloatTensor(X_train).unsqueeze(1),\n                      torch.LongTensor(y_train)),\n        batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS,\n        pin_memory=True, persistent_workers=True, prefetch_factor=4\n    )\n    val_loader = DataLoader(\n        TensorDataset(torch.FloatTensor(X_val).unsqueeze(1),\n                      torch.LongTensor(y_val)),\n        batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n        pin_memory=True, persistent_workers=True\n    )\n    test_loader = DataLoader(\n        TensorDataset(torch.FloatTensor(X_test).unsqueeze(1),\n                      torch.LongTensor(y_test)),\n        batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True\n    )\n\n    # --- Stap 4: Model + torch.compile() + AMP ---\n    model = VocalizationResNet(num_classes=num_classes).to(device)\n\n    # torch.compile() voor ~20-30% speedup op A100 (PyTorch 2.0+)\n    if USE_TORCH_COMPILE:\n        try:\n            model = torch.compile(model, mode='reduce-overhead')\n        except Exception:\n            pass  # Fallback naar eager mode\n\n    class_weights = compute_class_weights(y_train, num_classes, device)\n    criterion = FocalLoss(alpha=class_weights, gamma=FOCAL_GAMMA,\n                          label_smoothing=LABEL_SMOOTHING)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE,\n                                  weight_decay=WEIGHT_DECAY)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2,\n                                            eta_min=MIN_LR)\n\n    # AMP: automatic mixed precision (FP16 compute, FP32 accumulate)\n    # Veilig op A100/V100/L4, ~30-50% speedup bovenop TF32\n    use_amp = GPU_TYPE in ('A100', 'V100', 'L4')\n    scaler = torch.amp.GradScaler('cuda', enabled=use_amp)\n\n    # --- Stap 5: Training loop met Mixup + AMP ---\n    best_acc = 0\n    best_state = None\n    patience_counter = 0\n\n    try:\n        for epoch in range(EPOCHS):\n            model.train()\n            train_loss = 0\n\n            for X_batch, y_batch in train_loader:\n                X_batch = X_batch.to(device, non_blocking=True)\n                y_batch = y_batch.to(device, non_blocking=True)\n\n                # Mixup augmentatie (50% kans per batch)\n                use_mixup_batch = USE_MIXUP and np.random.random() > 0.5\n                if use_mixup_batch:\n                    lam = np.random.beta(MIXUP_ALPHA, MIXUP_ALPHA)\n                    indices = torch.randperm(X_batch.size(0), device=device)\n                    mixed_X = lam * X_batch + (1 - lam) * X_batch[indices]\n                    y_a, y_b = y_batch, y_batch[indices]\n                else:\n                    mixed_X = X_batch\n\n                optimizer.zero_grad(set_to_none=True)  # Sneller dan zero_grad()\n\n                # AMP forward pass\n                with torch.amp.autocast('cuda', enabled=use_amp):\n                    outputs = model(mixed_X)\n                    if use_mixup_batch:\n                        loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n                    else:\n                        loss = criterion(outputs, y_batch)\n\n                # AMP backward pass\n                scaler.scale(loss).backward()\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                scaler.step(optimizer)\n                scaler.update()\n\n                train_loss += loss.item()\n\n            scheduler.step(epoch)\n\n            # Validation (zonder mixup, zonder AMP voor accurate meting)\n            model.eval()\n            val_correct = 0\n            with torch.no_grad():\n                for X_batch, y_batch in val_loader:\n                    X_batch = X_batch.to(device, non_blocking=True)\n                    y_batch = y_batch.to(device, non_blocking=True)\n                    outputs = model(X_batch)\n                    val_correct += (outputs.argmax(1) == y_batch).sum().item()\n\n            val_acc = val_correct / len(y_val)\n\n            if val_acc > best_acc:\n                best_acc = val_acc\n                # Bij torch.compile: gebruik _orig_mod als beschikbaar\n                state_source = model._orig_mod if hasattr(model, '_orig_mod') else model\n                best_state = {k: v.cpu().clone() for k, v in state_source.state_dict().items()}\n                patience_counter = 0\n            else:\n                patience_counter += 1\n\n            if patience_counter >= PATIENCE:\n                print(f\"  \\u23f9\\ufe0f Early stop @ epoch {epoch+1}\")\n                break\n\n    except RuntimeError as e:\n        if 'CUDA' in str(e):\n            print(f\"  \\u26a0\\ufe0f CUDA error: {str(e)[:60]}\")\n            torch.cuda.empty_cache()\n            gc.collect()\n            if best_state is None:\n                return None, 'cuda_error', {}\n        else:\n            raise\n\n    if best_state is None:\n        return None, 'training_failed', {}\n\n    # --- Stap 6: Test evaluatie ---\n    # Maak clean model (zonder torch.compile) voor evaluatie en opslaan\n    eval_model = VocalizationResNet(num_classes=num_classes).to(device)\n    eval_model.load_state_dict(best_state)\n    eval_model.eval()\n\n    test_preds, test_labels = [], []\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            X_batch = X_batch.to(device)\n            outputs = eval_model(X_batch)\n            test_preds.extend(outputs.argmax(1).cpu().numpy())\n            test_labels.extend(y_batch.numpy())\n\n    test_acc = np.mean(np.array(test_preds) == np.array(test_labels))\n\n    # Confusion matrix\n    cm = confusion_matrix(test_labels, test_preds, labels=list(range(num_classes)))\n    cm_dict = {}\n    for i, true_name in enumerate(class_names):\n        for j, pred_name in enumerate(class_names):\n            if cm[i, j] > 0:\n                cm_dict[f\"{true_name}>{pred_name}\"] = int(cm[i, j])\n\n    # --- Stap 7: Temperature scaling ---\n    temperature = calibrate_temperature(eval_model, val_loader, device)\n\n    # --- Stap 8: Model opslaan ---\n    model_path = Path(f'{DRIVE_BASE}/models/{dirname}_cnn_{VERSION}.pt')\n    torch.save({\n        'model_state_dict': best_state,\n        'num_classes': num_classes,\n        'class_names': class_names,\n        'label_map': label_map,\n        'accuracy': best_acc,\n        'test_accuracy': float(test_acc),\n        'temperature': temperature,\n        'confusion_matrix': cm_dict,\n        'class_distribution': class_dist,\n        'species_name': dutch_name,\n        'scientific_name': scientific_name,\n        'version': VERSION,\n        'architecture': 'ResNet_SE',\n    }, model_path)\n\n    del model, eval_model, train_loader, val_loader, test_loader\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    elapsed = time.time() - start_time\n    print(f\"  \\u2705 {model_path.name} | Val: {best_acc:.1%} | Test: {test_acc:.1%} | T={temperature:.2f} | {elapsed:.0f}s\")\n\n    if cm_dict:\n        # Toon alleen verwarringen (true != pred)\n        confusions = {k: v for k, v in cm_dict.items() if k.split('>')[0] != k.split('>')[1]}\n        if confusions:\n            print(f\"  \\U0001f500 Verwarringen: {confusions}\")\n\n    return test_acc, 'success', cm_dict\n\n\nprint(\"\\u2705 V2 Pro+ Training pipeline geladen\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cel 10: Start Training (met auto-resume + auto-upload naar HiDrive)\nimport pandas as pd\nimport subprocess\n\n# --- Resume: check welke modellen al op HiDrive staan ---\nprint(\"Checking HiDrive voor bestaande modellen...\")\ntry:\n    result = subprocess.run(\n        ['rclone', 'ls', f'hidrive:{HIDRIVE_MODELS}'],\n        capture_output=True, text=True, timeout=30\n    )\n    completed_models = set()\n    for line in result.stdout.strip().split('\\n'):\n        if line.strip():\n            # Format: \"  12345 dirname_cnn_2025_v2.pt\"\n            filename = line.strip().split()[-1] if line.strip() else ''\n            if filename.endswith('.pt'):\n                # Extract dirname: \"aalscholver_cnn_2025_v2.pt\" -> \"aalscholver\"\n                dirname = filename.replace(f'_cnn_{VERSION}.pt', '')\n                completed_models.add(dirname)\n    print(f\"  Gevonden: {len(completed_models)} voltooide modellen op HiDrive\")\nexcept Exception:\n    completed_models = set()\n    print(\"  Kon HiDrive niet checken - start vanaf begin\")\n\n# Bepaal welke soorten nog moeten\nspecies_todo = []\nspecies_skip = []\nfor dutch, scientific, dirname in ALL_SPECIES:\n    if dirname in completed_models:\n        species_skip.append(dutch)\n    else:\n        species_todo.append((dutch, scientific, dirname))\n\nif species_skip:\n    print(f\"  Overslaan: {len(species_skip)} soorten (al klaar)\")\n    print(f\"  Nog te doen: {len(species_todo)} soorten\")\nelse:\n    print(f\"  Eerste run - alle {len(species_todo)} soorten\")\n\n# --- Training loop ---\nresults = []\nall_confusions = {}\nstart_all = time.time()\n\nprint(f\"\\n{'='*60}\")\nprint(f\"\\U0001f680 EMSN VOCALIZATION TRAINING v2\")\nprint(f\"{'='*60}\")\nprint(f\"Start: {datetime.now().strftime('%H:%M:%S')}\")\nprint(f\"Soorten: {len(species_todo)} te doen ({len(species_skip)} overgeslagen)\")\nprint(f\"GPU: {GPU_TYPE} | Architecture: Deep ResNet+SE (5.2M params)\")\nprint(f\"Augmentation: {AUGMENTATION_FACTOR}x + SpecAugment + Mixup\")\nprint(f\"Loss: Focal (gamma={FOCAL_GAMMA}) + Label smoothing ({LABEL_SMOOTHING})\")\nprint(f\"Opslag: HiDrive (auto-upload per model)\")\nprint(f\"{'='*60}\")\n\nsuccessful = len(species_skip)  # Tel eerder voltooide mee\nfailed = 0\n\nfor i, (dutch, scientific, dirname) in enumerate(species_todo):\n    try:\n        acc, status, cm = train_species_v2(dutch, scientific, dirname)\n        results.append({\n            'species': dutch,\n            'scientific': scientific,\n            'test_accuracy': acc,\n            'status': status\n        })\n        if cm:\n            all_confusions[dutch] = cm\n\n        if status == 'success':\n            successful += 1\n            # Direct uploaden naar HiDrive na succesvolle training\n            model_file = f'{DRIVE_BASE}/models/{dirname}_cnn_{VERSION}.pt'\n            upload_model_to_hidrive(model_file)\n        else:\n            failed += 1\n\n    except Exception as e:\n        print(f\"  \\u274c Error: {str(e)[:80]}\")\n        results.append({\n            'species': dutch,\n            'scientific': scientific,\n            'test_accuracy': None,\n            'status': 'error'\n        })\n        failed += 1\n\n    # Checkpoint elke 20 soorten: resultaten opslaan + uploaden\n    if (i + 1) % 20 == 0:\n        pd.DataFrame(results).to_csv(f'{DRIVE_BASE}/checkpoint_v2.csv', index=False)\n        with open(f'{DRIVE_BASE}/confusions_v2.json', 'w') as f:\n            json.dump(all_confusions, f, indent=2)\n        upload_results_to_hidrive()\n        elapsed = time.time() - start_all\n        eta = (elapsed / (i + 1)) * (len(species_todo) - i - 1)\n        total_done = len(species_skip) + i + 1\n        print(f\"\\n  \\U0001f4be [{total_done}/{len(ALL_SPECIES)}] \\u2705{successful} \\u274c{failed} | HiDrive synced | ETA: {eta/60:.0f}min\\n\")\n\n# Finale resultaten uploaden\nelapsed_all = time.time() - start_all\nprint(f\"\\n{'='*60}\")\nprint(f\"\\U0001f3c1 TRAINING VOLTOOID!\")\nprint(f\"{'='*60}\")\nprint(f\"Tijd deze sessie: {elapsed_all/60:.1f} minuten\")\nprint(f\"Totaal succesvol: {successful}/{len(ALL_SPECIES)}\")\nprint(f\"Overgeslagen (al klaar): {len(species_skip)}\")\nprint(f\"Nieuw getraind: {len(species_todo) - failed}\")\nprint(f\"Mislukt: {failed}\")\nprint(f\"\\nFinale upload naar HiDrive...\")\nupload_results_to_hidrive()\nprint(f\"\\u2705 Alle modellen staan op HiDrive!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cel 11: Resultaten & Analyse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f'{DRIVE_BASE}/results_v2.csv', index=False)\n",
    "\n",
    "# Confusion data opslaan\n",
    "with open(f'{DRIVE_BASE}/confusions_v2.json', 'w') as f:\n",
    "    json.dump(all_confusions, f, indent=2)\n",
    "\n",
    "successful_df = df[df['status'] == 'success']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"\\U0001f4ca RESULTATEN v2\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Getraind: {len(successful_df)}/{len(df)}\")\n",
    "\n",
    "if len(successful_df) > 0:\n",
    "    accs = successful_df['test_accuracy']\n",
    "    print(f\"\\nTest Accuracy:\")\n",
    "    print(f\"  Gemiddeld: {accs.mean():.1%}\")\n",
    "    print(f\"  Mediaan:   {accs.median():.1%}\")\n",
    "    print(f\"  Min:       {accs.min():.1%}\")\n",
    "    print(f\"  Max:       {accs.max():.1%}\")\n",
    "    print(f\"  >90%:      {(accs > 0.9).sum()} soorten\")\n",
    "    print(f\"  >80%:      {(accs > 0.8).sum()} soorten\")\n",
    "    print(f\"  <50%:      {(accs < 0.5).sum()} soorten\")\n",
    "\n",
    "    # Top 10 en Bottom 10\n",
    "    print(f\"\\n\\U0001f3c6 Top 10 (beste modellen):\")\n",
    "    for _, row in successful_df.nlargest(10, 'test_accuracy').iterrows():\n",
    "        print(f\"  {row['test_accuracy']:.1%} - {row['species']}\")\n",
    "\n",
    "    print(f\"\\n\\u26a0\\ufe0f Bottom 10 (meeste verbetering nodig):\")\n",
    "    for _, row in successful_df.nsmallest(10, 'test_accuracy').iterrows():\n",
    "        print(f\"  {row['test_accuracy']:.1%} - {row['species']}\")\n",
    "\n",
    "    # Meest verwarde soorten\n",
    "    print(f\"\\n\\U0001f500 Meest verwarde types:\")\n",
    "    confusion_scores = []\n",
    "    for species, cm in all_confusions.items():\n",
    "        total = sum(cm.values())\n",
    "        errors = sum(v for k, v in cm.items() if k.split('>')[0] != k.split('>')[1])\n",
    "        if total > 0:\n",
    "            confusion_scores.append((species, errors / total, errors, total))\n",
    "    confusion_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    for species, rate, errors, total in confusion_scores[:10]:\n",
    "        print(f\"  {rate:.0%} verward ({errors}/{total}) - {species}\")\n",
    "\n",
    "    # Histogram\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    axes[0].hist(accs, bins=20, edgecolor='black', color='steelblue')\n",
    "    axes[0].axvline(accs.mean(), color='red', linestyle='--', label=f'Gem: {accs.mean():.1%}')\n",
    "    axes[0].axvline(accs.median(), color='orange', linestyle='--', label=f'Med: {accs.median():.1%}')\n",
    "    axes[0].set_xlabel('Test Accuracy')\n",
    "    axes[0].set_ylabel('Aantal soorten')\n",
    "    axes[0].set_title('Accuracy Verdeling v2')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Confusion rate histogram\n",
    "    if confusion_scores:\n",
    "        rates = [s[1] for s in confusion_scores]\n",
    "        axes[1].hist(rates, bins=20, edgecolor='black', color='coral')\n",
    "        axes[1].set_xlabel('Verwarrings-percentage')\n",
    "        axes[1].set_ylabel('Aantal soorten')\n",
    "        axes[1].set_title('Type Verwarring per Soort')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{DRIVE_BASE}/results_v2.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "# Mislukte soorten\n",
    "failed_df = df[df['status'] != 'success']\n",
    "if len(failed_df) > 0:\n",
    "    print(f\"\\n\\u274c Mislukt ({len(failed_df)}):\")\n",
    "    for status, group in failed_df.groupby('status'):\n",
    "        print(f\"  {status}: {', '.join(group['species'].tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cel 12: HiDrive status & download naar Pi\n#\n# Modellen zijn al automatisch ge-upload tijdens training.\n# Deze cel toont wat er op HiDrive staat en hoe je ze naar de Pi haalt.\n#\n\nprint(f\"{'='*60}\")\nprint(f\"\\U0001f4c1 HIDRIVE MODEL STATUS\")\nprint(f\"{'='*60}\")\n\n# Toon modellen op HiDrive\nprint(f\"\\nModellen op HiDrive ({HIDRIVE_MODELS}):\")\n!rclone ls hidrive:{HIDRIVE_MODELS} 2>/dev/null | wc -l | xargs -I{} echo \"  Totaal: {} bestanden\"\n!rclone size hidrive:{HIDRIVE_MODELS} 2>/dev/null\n\nprint(f\"\\nResultaten op HiDrive ({HIDRIVE_RESULTS}):\")\n!rclone ls hidrive:{HIDRIVE_RESULTS} 2>/dev/null\n\nprint(f\"\\n{'='*60}\")\nprint(f\"DOWNLOAD NAAR PI\")\nprint(f\"{'='*60}\")\nprint(f\"\"\"\nDraai dit commando op je Pi (emsn2-zolder) om de v2 modellen op te halen:\n\n  # Maak map aan\n  mkdir -p /mnt/nas-docker/emsn-vocalization/data/models\n\n  # Download v2 modellen van HiDrive naar NAS\n  rclone copy hidrive:{HIDRIVE_MODELS}/ \\\\\n    /mnt/nas-docker/emsn-vocalization/data/models/ \\\\\n    --progress --sftp-key-file ~/.ssh/id_ed25519_hidrive\n\n  # Of configureer rclone eerst:\n  # rclone config (type=sftp, host=sftp.hidrive.strato.com,\n  #                user=ronnyclouddisk, key_file=~/.ssh/id_ed25519_hidrive)\n\n  # Herstart vocalization enricher om nieuwe modellen te laden\n  sudo systemctl restart vocalization-enricher\n\nKlaar! De v2 modellen worden automatisch gebruikt (hogere prioriteit).\n\"\"\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}