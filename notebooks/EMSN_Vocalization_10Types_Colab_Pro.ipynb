{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽµ EMSN Vocalisatie 10-Types Training v2 (Pro+)\n\n**Ecologisch Monitoring Systeem Nijverdal** - Vocalisatie classificatie voor 382 Europese vogelsoorten\n\n## Wat doet dit notebook?\n\nTraint **per soort** een CNN model dat 10 vocalisatie-types kan onderscheiden:\n`zang`, `roep`, `alarm`, `vluchtroep`, `subzang`, `bedelroep`, `contactroep`, `nachttrekroep`, `baltszang`, `roffel`\n\n### v2 Verbeteringen (vs v1)\n- **Focal Loss**: Focus op moeilijk te classificeren samples ipv makkelijke\n- **Mixup regularisatie**: Betere generalisatie door sample mixing\n- **Adaptive oversampling**: Kleine classes worden opgeschaald naar target niveau\n- **Balanced Accuracy**: Eerlijke metric die alle classes gelijk weegt\n- **SE-attention CNN**: Squeeze-and-Excitation blocks leren welke features belangrijk zijn\n- **Residual connections**: Betere gradient flow voor diepere training\n- **Adaptive augmentatie**: Weinig data? Meer augmentatie. Veel data? Minder.\n- **Auto-resume**: Bij crash/timeout hervat training waar het was\n\n### Soorten (382 uniek)\n1. **Nederlandse broedvogels** (97) - Alle standaard soorten\n2. **Schaarse/zeldzame broedvogels** (35) - Woudaap, Velduil, etc.\n3. **Scandinavisch/boreaal** (50) - Taiga soorten, FjÃ¤ll vogels\n4. **Zuid-Europees/Mediterraan** (55) - Gieren, Bijeneter, etc.\n5. **Oost-Europees** (35) - Steppe/bos soorten\n6. **Trekvogels/NocMig/Pelagisch** (110+) - Nachttrek, zeevogels\n\n### Vereisten\n- **Colab Pro+** met A100/H100 GPU\n- **Twee Colab Secrets** (ðŸ”‘ icoon links):\n  - `HIDRIVE_SSH_KEY` â†’ Inhoud van SSH private key voor HiDrive backup\n  - `XC_API_KEY` â†’ Xeno-Canto API key\n\n### Gebruik\n1. Stel runtime in: **A100 GPU** (Runtime > Runtimetype wijzigen)\n2. Controleer Colab Secrets (ðŸ”‘)\n3. **Ctrl+F9** (Alles uitvoeren) - duurt ~15-25 uur voor alle 382 soorten\n4. Bij timeout: heropen notebook en run opnieuw â†’ resume pikt op waar het was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. GPU Detection & Dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Install dependencies\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "                       \"librosa\", \"scikit-learn\", \"scikit-image\", \"matplotlib\",\n",
    "                       \"tqdm\", \"requests\", \"paramiko\", \"audiomentations\",\n",
    "                       \"torch-audiomentations\", \"seaborn\"])\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"\\nGEEN GPU! Ga naar Runtime > Change runtime type > GPU\")\n",
    "    raise SystemExit(\"GPU required\")\n",
    "\n",
    "GPU_NAME = torch.cuda.get_device_name(0)\n",
    "_props = torch.cuda.get_device_properties(0)\n",
    "GPU_MEM = getattr(_props, \"total_memory\", getattr(_props, \"total_mem\", 0)) / 1e9\n",
    "\n",
    "print(f\"\\nGPU: {GPU_NAME}\")\n",
    "print(f\"Memory: {GPU_MEM:.1f} GB\")\n",
    "\n",
    "import psutil\n",
    "ram_gb = psutil.virtual_memory().total / 1e9\n",
    "print(f\"RAM: {ram_gb:.1f} GB\")\n",
    "\n",
    "# Auto-configure based on GPU\n",
    "if \"H100\" in GPU_NAME:\n",
    "    BATCH_SIZE = 128\n",
    "    NUM_WORKERS = 8\n",
    "    USE_BF16 = True\n",
    "    GPU_TIER = \"H100\"\n",
    "elif \"A100\" in GPU_NAME:\n",
    "    BATCH_SIZE = 96\n",
    "    NUM_WORKERS = 6\n",
    "    USE_BF16 = True\n",
    "    GPU_TIER = \"A100\"\n",
    "elif \"V100\" in GPU_NAME or \"L4\" in GPU_NAME:\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 4\n",
    "    USE_BF16 = False\n",
    "    GPU_TIER = \"V100/L4\"\n",
    "else:  # T4, etc.\n",
    "    BATCH_SIZE = 48\n",
    "    NUM_WORKERS = 4\n",
    "    USE_BF16 = False\n",
    "    GPU_TIER = \"T4/Other\"\n",
    "\n",
    "# Stability + performance\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.bfloat16 if USE_BF16 else torch.float16\n",
    "\n",
    "print(f\"\\nConfig voor {GPU_TIER}:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Precision: {dtype}\")\n",
    "print(f\"  Workers: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. HiDrive Verbinding via SSH Key (Colab Secrets)\n",
    "import paramiko\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from google.colab import userdata\n",
    "\n",
    "HIDRIVE_HOST = \"sftp.hidrive.strato.com\"\n",
    "HIDRIVE_USER = \"ronnyclouddisk\"\n",
    "\n",
    "# Lees SSH key uit Colab Secrets\n",
    "try:\n",
    "    ssh_key_content = userdata.get(\"HIDRIVE_SSH_KEY\")\n",
    "    print(\"SSH key geladen uit Colab Secrets\")\n",
    "except userdata.SecretNotFoundError:\n",
    "    raise RuntimeError(\n",
    "        \"Secret 'HIDRIVE_SSH_KEY' niet gevonden!\\n\\n\"\n",
    "        \"Stel in via het sleutel-icoon links in Colab:\\n\"\n",
    "        \"  Naam: HIDRIVE_SSH_KEY\\n\"\n",
    "        \"  Waarde: inhoud van ~/.ssh/id_ed25519_hidrive\\n\"\n",
    "        \"  Notebook toegang: Aan\"\n",
    "    )\n",
    "\n",
    "# Schrijf key naar tijdelijk bestand\n",
    "_key_file = tempfile.NamedTemporaryFile(mode=\"w\", suffix=\"_hidrive\", delete=False)\n",
    "_key_file.write(ssh_key_content)\n",
    "if not ssh_key_content.endswith(\"\\n\"):\n",
    "    _key_file.write(\"\\n\")\n",
    "_key_file.close()\n",
    "os.chmod(_key_file.name, 0o600)\n",
    "\n",
    "# Detecteer key type\n",
    "try:\n",
    "    _pkey = paramiko.Ed25519Key.from_private_key_file(_key_file.name)\n",
    "    print(\"  Key type: Ed25519\")\n",
    "except Exception:\n",
    "    try:\n",
    "        _pkey = paramiko.RSAKey.from_private_key_file(_key_file.name)\n",
    "        print(\"  Key type: RSA\")\n",
    "    except Exception:\n",
    "        _pkey = paramiko.ECDSAKey.from_private_key_file(_key_file.name)\n",
    "        print(\"  Key type: ECDSA\")\n",
    "\n",
    "# HiDrive paden\n",
    "HIDRIVE_MODELS_DIR = \"/users/ronnyclouddisk/emsn-backups/vocalization-models-10types/\"\n",
    "HIDRIVE_RETRAINING_DIR = \"/users/ronnyclouddisk/emsn-backups/vocalization-retraining/\"\n",
    "HIDRIVE_CHECKPOINT_DIR = \"/users/ronnyclouddisk/emsn-backups/vocalization-checkpoints/\"\n",
    "\n",
    "# Lokale paden\n",
    "LOCAL_BASE = Path(\"/content/EMSN-Vocalization-10Types\")\n",
    "LOCAL_AUDIO = LOCAL_BASE / \"audio\"\n",
    "LOCAL_MODELS = LOCAL_BASE / \"models\"\n",
    "LOCAL_CHECKPOINT = LOCAL_BASE / \"checkpoints\"\n",
    "LOCAL_RETRAINING = LOCAL_BASE / \"retraining\"\n",
    "for d in [LOCAL_AUDIO, LOCAL_MODELS, LOCAL_CHECKPOINT, LOCAL_RETRAINING]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_sftp():\n",
    "    \"\"\"Maak SFTP verbinding naar HiDrive.\"\"\"\n",
    "    transport = paramiko.Transport((HIDRIVE_HOST, 22))\n",
    "    transport.connect(username=HIDRIVE_USER, pkey=_pkey)\n",
    "    return paramiko.SFTPClient.from_transport(transport), transport\n",
    "\n",
    "\n",
    "def sftp_mkdir_p(sftp, remote_path):\n",
    "    \"\"\"mkdir -p voor SFTP.\"\"\"\n",
    "    parts = remote_path.strip(\"/\").split(\"/\")\n",
    "    current = \"\"\n",
    "    for part in parts:\n",
    "        current += f\"/{part}\"\n",
    "        try:\n",
    "            sftp.stat(current)\n",
    "        except FileNotFoundError:\n",
    "            sftp.mkdir(current)\n",
    "\n",
    "\n",
    "def upload_to_hidrive(local_path, remote_dir, remote_name=None):\n",
    "    \"\"\"Upload bestand naar HiDrive.\"\"\"\n",
    "    sftp, transport = get_sftp()\n",
    "    try:\n",
    "        sftp_mkdir_p(sftp, remote_dir)\n",
    "        if remote_name is None:\n",
    "            remote_name = Path(local_path).name\n",
    "        remote_path = f\"{remote_dir}{remote_name}\"\n",
    "        sftp.put(str(local_path), remote_path)\n",
    "        size_mb = os.path.getsize(local_path) / (1024 * 1024)\n",
    "        print(f\"  Uploaded: {remote_name} ({size_mb:.1f} MB)\")\n",
    "    finally:\n",
    "        sftp.close()\n",
    "        transport.close()\n",
    "\n",
    "\n",
    "def download_from_hidrive(remote_path, local_path):\n",
    "    \"\"\"Download bestand van HiDrive.\"\"\"\n",
    "    sftp, transport = get_sftp()\n",
    "    try:\n",
    "        sftp.get(remote_path, str(local_path))\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        return False\n",
    "    finally:\n",
    "        sftp.close()\n",
    "        transport.close()\n",
    "\n",
    "\n",
    "def download_retraining_data():\n",
    "    \"\"\"Download eigen review-correcties van HiDrive (als beschikbaar).\"\"\"\n",
    "    sftp, transport = get_sftp()\n",
    "    total = 0\n",
    "    try:\n",
    "        try:\n",
    "            sftp.stat(HIDRIVE_RETRAINING_DIR)\n",
    "        except FileNotFoundError:\n",
    "            print(\"  Geen retraining data op HiDrive (dat is OK, we gebruiken Xeno-Canto)\")\n",
    "            return 0\n",
    "\n",
    "        for species_dir in sftp.listdir(HIDRIVE_RETRAINING_DIR):\n",
    "            remote_dir = f\"{HIDRIVE_RETRAINING_DIR}{species_dir}\"\n",
    "            try:\n",
    "                import stat as stat_mod\n",
    "                if not stat_mod.S_ISDIR(sftp.stat(remote_dir).st_mode):\n",
    "                    continue\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            local_dir = LOCAL_RETRAINING / species_dir\n",
    "            local_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            files = [f for f in sftp.listdir(remote_dir) if f.endswith(('.mp3', '.wav'))]\n",
    "            for fname in files:\n",
    "                local_file = local_dir / fname\n",
    "                if not local_file.exists():\n",
    "                    sftp.get(f\"{remote_dir}/{fname}\", str(local_file))\n",
    "                    total += 1\n",
    "\n",
    "        print(f\"  {total} retraining bestanden gedownload\")\n",
    "    finally:\n",
    "        sftp.close()\n",
    "        transport.close()\n",
    "    return total\n",
    "\n",
    "\n",
    "# Test verbinding\n",
    "print(\"\\nTest HiDrive verbinding...\")\n",
    "sftp, transport = get_sftp()\n",
    "print(f\"  Verbonden met {HIDRIVE_HOST}\")\n",
    "sftp.close()\n",
    "transport.close()\n",
    "\n",
    "# Download eigen review-data (indien beschikbaar)\n",
    "print(\"\\nRetraining data ophalen...\")\n",
    "download_retraining_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Configuratie\nimport time\nimport numpy as np\nfrom datetime import datetime\nfrom google.colab import userdata\n\nVERSION = '2026_10types'\n\n# === XENO-CANTO API KEY (via Colab Secret) ===\ntry:\n    XC_API_KEY = userdata.get(\"XC_API_KEY\")\n    print(f\"Xeno-Canto API key geladen uit Colab Secrets\")\nexcept userdata.SecretNotFoundError:\n    raise RuntimeError(\n        \"Secret 'XC_API_KEY' niet gevonden!\\n\\n\"\n        \"Stel in via het sleutel-icoon links in Colab:\\n\"\n        \"  Naam: XC_API_KEY\\n\"\n        \"  Waarde: je Xeno-Canto API key\\n\"\n        \"  Notebook toegang: Aan\\n\\n\"\n        \"Nog geen key? Registreer op https://xeno-canto.org/explore/api\"\n    )\n\n# === VOCALISATIE TYPES ===\nVOCALIZATION_TYPES = {\n    'zang':          {'xc_query': 'song',                  'label': 0},\n    'roep':          {'xc_query': 'call',                  'label': 1},\n    'alarm':         {'xc_query': 'alarm call',            'label': 2},\n    'vluchtroep':    {'xc_query': 'flight call',           'label': 3},\n    'subzang':       {'xc_query': 'subsong',               'label': 4},\n    'bedelroep':     {'xc_query': 'begging call',          'label': 5},\n    'contactroep':   {'xc_query': 'social call',           'label': 6},\n    'nachttrekroep': {'xc_query': 'nocturnal flight call', 'label': 7},\n    'baltszang':     {'xc_query': 'flight song',           'label': 8},\n    'roffel':        {'xc_query': 'drumming',              'label': 9},\n}\n\n# === TRAINING PARAMETERS - PRO+ GEOPTIMALISEERD ===\nEPOCHS = 100\nLEARNING_RATE = 0.0005          # Lager dan voorheen - stabieler\nMIN_LR = 1e-6\nPATIENCE = 20                    # Meer geduld\nWARMUP_EPOCHS = 5                # Langere warmup\nLABEL_SMOOTHING = 0.1            # Iets meer smoothing\nWEIGHT_DECAY = 0.02\nFOCAL_LOSS_GAMMA = 2.0           # Focus op moeilijke samples\nFOCAL_LOSS_ALPHA = None          # Auto-berekend uit class weights\nMIXUP_ALPHA = 0.3                # Mixup regularisatie\n\n# === DATA PARAMETERS ===\nMAX_RECORDINGS_PER_TYPE = 100    # Meer data ophalen\nMAX_SEGMENTS_PER_RECORDING = 4   # 4 segmenten per opname\nMIN_SAMPLES_PER_TYPE = 20        # Minimum 20 samples per type\nMIN_TYPES_FOR_TRAINING = 2       # Minimaal 2 types\nMAX_CONCURRENT_DOWNLOADS = 12\nTARGET_SAMPLES_PER_CLASS = 800   # Doel per class na oversampling\n\n# === AUDIO PARAMETERS ===\nSAMPLE_RATE = 48000\nN_MELS = 128\nN_FFT = 2048\nHOP_LENGTH = 512\nFMIN = 150                       # Lager: roofvogels, uilen\nFMAX = 15000                     # Hoger: vluchtroepen, contactroepen\nSEGMENT_DURATION = 3.0\n\n# === AUGMENTATIE ===\nAUG_PITCH_RANGE = 2              # Iets minder agressief\nAUG_STRETCH_RANGE = 0.12\nAUG_NOISE_LEVELS = [0.001, 0.003, 0.007]\nAUG_PINK_NOISE_LEVEL = 0.005\nAUG_SPEC_FREQ_MASK = 12\nAUG_SPEC_TIME_MASK = 15\n\nprint(f\"EMSN Vocalisatie 10-Types Training v2 (Pro+)\")\nprint(f\"{'='*60}\")\nprint(f\"GPU: {GPU_TIER} | Batch: {BATCH_SIZE} | Precision: {dtype}\")\nprint(f\"Epochs: {EPOCHS} | Patience: {PATIENCE} | LR: {LEARNING_RATE}\")\nprint(f\"Focal Loss gamma: {FOCAL_LOSS_GAMMA} | Mixup alpha: {MIXUP_ALPHA}\")\nprint(f\"Target samples/class: {TARGET_SAMPLES_PER_CLASS}\")\nprint(f\"Recordings per type: {MAX_RECORDINGS_PER_TYPE}\")\nprint(f\"Freq range: {FMIN}-{FMAX} Hz\")\nprint(f\"\\nTypes ({len(VOCALIZATION_TYPES)}):\")\nfor name, info in VOCALIZATION_TYPES.items():\n    print(f\"  [{info['label']}] {name} -> XC: {info['xc_query']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title 4. Soortenlijst (400+ Europese vogelsoorten)\n# Nederlandse broedvogels, trekvogels, Scandinavische, Zuid- en Oost-Europese soorten.\n# Elke tuple: (Nederlandse naam, wetenschappelijke naam, directory naam)\n\nALL_SPECIES = [\n    # ===== NEDERLANDSE BROEDVOGELS & VASTE GASTEN =====\n    (\"Aalscholver\", \"Phalacrocorax carbo\", \"aalscholver\"),\n    (\"Appelvink\", \"Coccothraustes coccothraustes\", \"appelvink\"),\n    (\"Baardman\", \"Panurus biarmicus\", \"baardman\"),\n    (\"Barmsijs\", \"Acanthis flammea\", \"barmsijs\"),\n    (\"Beflijster\", \"Turdus torquatus\", \"beflijster\"),\n    (\"Bergeend\", \"Tadorna tadorna\", \"bergeend\"),\n    (\"Bijeneter\", \"Merops apiaster\", \"bijeneter\"),\n    (\"Blauwborst\", \"Luscinia svecica\", \"blauwborst\"),\n    (\"Blauwe Kiekendief\", \"Circus cyaneus\", \"blauwe_kiekendief\"),\n    (\"Blauwe Reiger\", \"Ardea cinerea\", \"blauwe_reiger\"),\n    (\"Boerenzwaluw\", \"Hirundo rustica\", \"boerenzwaluw\"),\n    (\"Bokje\", \"Lymnocryptes minimus\", \"bokje\"),\n    (\"Bontbekplevier\", \"Charadrius hiaticula\", \"bontbekplevier\"),\n    (\"Bonte Kraai\", \"Corvus cornix\", \"bonte_kraai\"),\n    (\"Bonte Strandloper\", \"Calidris alpina\", \"bonte_strandloper\"),\n    (\"Bonte Vliegenvanger\", \"Ficedula hypoleuca\", \"bonte_vliegenvanger\"),\n    (\"Boomklever\", \"Sitta europaea\", \"boomklever\"),\n    (\"Boomkruiper\", \"Certhia brachydactyla\", \"boomkruiper\"),\n    (\"Boomleeuwerik\", \"Lullula arborea\", \"boomleeuwerik\"),\n    (\"Boompieper\", \"Anthus trivialis\", \"boompieper\"),\n    (\"Boomvalk\", \"Falco subbuteo\", \"boomvalk\"),\n    (\"Bosrietzanger\", \"Acrocephalus palustris\", \"bosrietzanger\"),\n    (\"Bosruiter\", \"Tringa glareola\", \"bosruiter\"),\n    (\"Bosuil\", \"Strix aluco\", \"bosuil\"),\n    (\"Braamsluiper\", \"Curruca curruca\", \"braamsluiper\"),\n    (\"Brandgans\", \"Branta leucopsis\", \"brandgans\"),\n    (\"Brilduiker\", \"Bucephala clangula\", \"brilduiker\"),\n    (\"Bruine Kiekendief\", \"Circus aeruginosus\", \"bruine_kiekendief\"),\n    (\"Buidelmees\", \"Remiz pendulinus\", \"buidelmees\"),\n    (\"Buizerd\", \"Buteo buteo\", \"buizerd\"),\n    (\"Canadese Gans\", \"Branta canadensis\", \"canadese_gans\"),\n    (\"Cetti's Zanger\", \"Cettia cetti\", \"cettis_zanger\"),\n    (\"Citroenkanarie\", \"Serinus citrinella\", \"citroenkanarie\"),\n    (\"Dodaars\", \"Tachybaptus ruficollis\", \"dodaars\"),\n    (\"Draaihals\", \"Jynx torquilla\", \"draaihals\"),\n    (\"Drieteenstrandloper\", \"Calidris alba\", \"drieteenstrandloper\"),\n    (\"Dwergstern\", \"Sternula albifrons\", \"dwergstern\"),\n    (\"Eider\", \"Somateria mollissima\", \"eider\"),\n    (\"Ekster\", \"Pica pica\", \"ekster\"),\n    (\"Europese Kanarie\", \"Serinus serinus\", \"europese_kanarie\"),\n    (\"Fazant\", \"Phasianus colchicus\", \"fazant\"),\n    (\"Fitis\", \"Phylloscopus trochilus\", \"fitis\"),\n    (\"Flamingo\", \"Phoenicopterus roseus\", \"flamingo\"),\n    (\"Fluiter\", \"Phylloscopus sibilatrix\", \"fluiter\"),\n    (\"Fuut\", \"Podiceps cristatus\", \"fuut\"),\n    (\"Gaai\", \"Garrulus glandarius\", \"gaai\"),\n    (\"Geelgors\", \"Emberiza citrinella\", \"geelgors\"),\n    (\"Geelpootmeeuw\", \"Larus michahellis\", \"geelpootmeeuw\"),\n    (\"Gekraagde Roodstaart\", \"Phoenicurus phoenicurus\", \"gekraagde_roodstaart\"),\n    (\"Gele Kwikstaart\", \"Motacilla flava\", \"gele_kwikstaart\"),\n    (\"Gierzwaluw\", \"Apus apus\", \"gierzwaluw\"),\n    (\"Glanskop\", \"Poecile palustris\", \"glanskop\"),\n    (\"Goudhaan\", \"Regulus regulus\", \"goudhaan\"),\n    (\"Goudplevier\", \"Pluvialis apricaria\", \"goudplevier\"),\n    (\"Goudvink\", \"Pyrrhula pyrrhula\", \"goudvink\"),\n    (\"Grasmus\", \"Curruca communis\", \"grasmus\"),\n    (\"Graspieper\", \"Anthus pratensis\", \"graspieper\"),\n    (\"Graszanger\", \"Cisticola juncidis\", \"graszanger\"),\n    (\"Grauwe Gans\", \"Anser anser\", \"grauwe_gans\"),\n    (\"Grauwe Gors\", \"Emberiza calandra\", \"grauwe_gors\"),\n    (\"Grauwe Kiekendief\", \"Circus pygargus\", \"grauwe_kiekendief\"),\n    (\"Grauwe Klauwier\", \"Lanius collurio\", \"grauwe_klauwier\"),\n    (\"Grauwe Vliegenvanger\", \"Muscicapa striata\", \"grauwe_vliegenvanger\"),\n    (\"Groene Specht\", \"Picus viridis\", \"groene_specht\"),\n    (\"Groenling\", \"Chloris chloris\", \"groenling\"),\n    (\"Groenpootruiter\", \"Tringa nebularia\", \"groenpootruiter\"),\n    (\"Grote Barmsijs\", \"Acanthis flammea\", \"grote_barmsijs\"),\n    (\"Grote Bonte Specht\", \"Dendrocopos major\", \"grote_bonte_specht\"),\n    (\"Grote Canadese Gans\", \"Branta canadensis\", \"grote_canadese_gans\"),\n    (\"Grote Gele Kwikstaart\", \"Motacilla cinerea\", \"grote_gele_kwikstaart\"),\n    (\"Grote Karekiet\", \"Acrocephalus arundinaceus\", \"grote_karekiet\"),\n    (\"Grote Lijster\", \"Turdus viscivorus\", \"grote_lijster\"),\n    (\"Grote Mantelmeeuw\", \"Larus marinus\", \"grote_mantelmeeuw\"),\n    (\"Grote Zaagbek\", \"Mergus merganser\", \"grote_zaagbek\"),\n    (\"Grote Zilverreiger\", \"Ardea alba\", \"grote_zilverreiger\"),\n    (\"Grutto\", \"Limosa limosa\", \"grutto\"),\n    (\"Haakbek\", \"Pinicola enucleator\", \"haakbek\"),\n    (\"Halsbandparkiet\", \"Psittacula krameri\", \"halsbandparkiet\"),\n    (\"Havik\", \"Accipiter gentilis\", \"havik\"),\n    (\"Heggenmus\", \"Prunella modularis\", \"heggenmus\"),\n    (\"Holenduif\", \"Columba oenas\", \"holenduif\"),\n    (\"Hop\", \"Upupa epops\", \"hop\"),\n    (\"Houtduif\", \"Columba palumbus\", \"houtduif\"),\n    (\"Houtsnip\", \"Scolopax rusticola\", \"houtsnip\"),\n    (\"Huismus\", \"Passer domesticus\", \"huismus\"),\n    (\"Huiszwaluw\", \"Delichon urbicum\", \"huiszwaluw\"),\n    (\"IJsvogel\", \"Alcedo atthis\", \"ijsvogel\"),\n    (\"Kanoetstrandloper\", \"Calidris canutus\", \"kanoetstrandloper\"),\n    (\"Kauw\", \"Coloeus monedula\", \"kauw\"),\n    (\"Keep\", \"Fringilla montifringilla\", \"keep\"),\n    (\"Kerkuil\", \"Tyto alba\", \"kerkuil\"),\n    (\"Kievit\", \"Vanellus vanellus\", \"kievit\"),\n    (\"Klapekster\", \"Lanius excubitor\", \"klapekster\"),\n    (\"Kleine Bonte Specht\", \"Dryobates minor\", \"kleine_bonte_specht\"),\n    (\"Kleine Karekiet\", \"Acrocephalus scirpaceus\", \"kleine_karekiet\"),\n    (\"Kleine Mantelmeeuw\", \"Larus fuscus\", \"kleine_mantelmeeuw\"),\n    (\"Kleine Rietgans\", \"Anser brachyrhynchus\", \"kleine_rietgans\"),\n    (\"Kleine Strandloper\", \"Calidris minuta\", \"kleine_strandloper\"),\n    (\"Kleine Zilverreiger\", \"Egretta garzetta\", \"kleine_zilverreiger\"),\n    (\"Kleine Zwaan\", \"Cygnus columbianus\", \"kleine_zwaan\"),\n    (\"Kluut\", \"Recurvirostra avosetta\", \"kluut\"),\n    (\"Kneu\", \"Linaria cannabina\", \"kneu\"),\n    (\"Knobbelzwaan\", \"Cygnus olor\", \"knobbelzwaan\"),\n    (\"Koekoek\", \"Cuculus canorus\", \"koekoek\"),\n    (\"Kokmeeuw\", \"Chroicocephalus ridibundus\", \"kokmeeuw\"),\n    (\"Kolgans\", \"Anser albifrons\", \"kolgans\"),\n    (\"Koolmees\", \"Parus major\", \"koolmees\"),\n    (\"Koperwiek\", \"Turdus iliacus\", \"koperwiek\"),\n    (\"Kraanvogel\", \"Grus grus\", \"kraanvogel\"),\n    (\"Krakeend\", \"Mareca strepera\", \"krakeend\"),\n    (\"Kramsvogel\", \"Turdus pilaris\", \"kramsvogel\"),\n    (\"Kruisbek\", \"Loxia curvirostra\", \"kruisbek\"),\n    (\"Kuifeend\", \"Aythya fuligula\", \"kuifeend\"),\n    (\"Kuifmees\", \"Lophophanes cristatus\", \"kuifmees\"),\n    (\"Kwak\", \"Nycticorax nycticorax\", \"kwak\"),\n    (\"Kwartel\", \"Coturnix coturnix\", \"kwartel\"),\n    (\"Kwartelkoning\", \"Crex crex\", \"kwartelkoning\"),\n    (\"Mandarijneend\", \"Aix galericulata\", \"mandarijneend\"),\n    (\"Matkop\", \"Poecile montanus\", \"matkop\"),\n    (\"Meerkoet\", \"Fulica atra\", \"meerkoet\"),\n    (\"Merel\", \"Turdus merula\", \"merel\"),\n    (\"Middelste Bonte Specht\", \"Dendrocoptes medius\", \"middelste_bonte_specht\"),\n    (\"Middelste Zaagbek\", \"Mergus serrator\", \"middelste_zaagbek\"),\n    (\"Nachtegaal\", \"Luscinia megarhynchos\", \"nachtegaal\"),\n    (\"Nachtzwaluw\", \"Caprimulgus europaeus\", \"nachtzwaluw\"),\n    (\"Nijlgans\", \"Alopochen aegyptiaca\", \"nijlgans\"),\n    (\"Nonnetje\", \"Mergellus albellus\", \"nonnetje\"),\n    (\"Oehoe\", \"Bubo bubo\", \"oehoe\"),\n    (\"Oeverloper\", \"Actitis hypoleucos\", \"oeverloper\"),\n    (\"Oeverzwaluw\", \"Riparia riparia\", \"oeverzwaluw\"),\n    (\"Ooievaar\", \"Ciconia ciconia\", \"ooievaar\"),\n    (\"Orpheusspotvogel\", \"Hippolais polyglotta\", \"orpheusspotvogel\"),\n    (\"Paapje\", \"Saxicola rubetra\", \"paapje\"),\n    (\"Patrijs\", \"Perdix perdix\", \"patrijs\"),\n    (\"Pestvogel\", \"Bombycilla garrulus\", \"pestvogel\"),\n    (\"Pijlstaart\", \"Anas acuta\", \"pijlstaart\"),\n    (\"Pimpelmees\", \"Cyanistes caeruleus\", \"pimpelmees\"),\n    (\"Porseleinhoen\", \"Porzana porzana\", \"porseleinhoen\"),\n    (\"Putter\", \"Carduelis carduelis\", \"putter\"),\n    (\"Raaf\", \"Corvus corax\", \"raaf\"),\n    (\"Ransuil\", \"Asio otus\", \"ransuil\"),\n    (\"Regenwulp\", \"Numenius phaeopus\", \"regenwulp\"),\n    (\"Rietgors\", \"Emberiza schoeniclus\", \"rietgors\"),\n    (\"Rietzanger\", \"Acrocephalus schoenobaenus\", \"rietzanger\"),\n    (\"Ringmus\", \"Passer montanus\", \"ringmus\"),\n    (\"Rode Wouw\", \"Milvus milvus\", \"rode_wouw\"),\n    (\"Roek\", \"Corvus frugilegus\", \"roek\"),\n    (\"Roerdomp\", \"Botaurus stellaris\", \"roerdomp\"),\n    (\"Roodborst\", \"Erithacus rubecula\", \"roodborst\"),\n    (\"Roodborsttapuit\", \"Saxicola rubicola\", \"roodborsttapuit\"),\n    (\"Roodhalsfuut\", \"Podiceps grisegena\", \"roodhalsfuut\"),\n    (\"Roodkeelduiker\", \"Gavia stellata\", \"roodkeelduiker\"),\n    (\"Roodkeelpieper\", \"Anthus cervinus\", \"roodkeelpieper\"),\n    (\"Rosse Grutto\", \"Limosa lapponica\", \"rosse_grutto\"),\n    (\"Rotsduif\", \"Columba livia\", \"rotsduif\"),\n    (\"Scharrelaar\", \"Coracias garrulus\", \"scharrelaar\"),\n    (\"Scholekster\", \"Haematopus ostralegus\", \"scholekster\"),\n    (\"Sijs\", \"Spinus spinus\", \"sijs\"),\n    (\"Slechtvalk\", \"Falco peregrinus\", \"slechtvalk\"),\n    (\"Slobeend\", \"Spatula clypeata\", \"slobeend\"),\n    (\"Smelleken\", \"Falco columbarius\", \"smelleken\"),\n    (\"Smient\", \"Mareca penelope\", \"smient\"),\n    (\"Sneeuwgors\", \"Plectrophenax nivalis\", \"sneeuwgors\"),\n    (\"Snor\", \"Locustella luscinioides\", \"snor\"),\n    (\"Sperwer\", \"Accipiter nisus\", \"sperwer\"),\n    (\"Spotvogel\", \"Hippolais icterina\", \"spotvogel\"),\n    (\"Spreeuw\", \"Sturnus vulgaris\", \"spreeuw\"),\n    (\"Sprinkhaanzanger\", \"Locustella naevia\", \"sprinkhaanzanger\"),\n    (\"Staartmees\", \"Aegithalos caudatus\", \"staartmees\"),\n    (\"Stadsduif\", \"Columba livia domestica\", \"stadsduif\"),\n    (\"Steenloper\", \"Arenaria interpres\", \"steenloper\"),\n    (\"Steenuil\", \"Athene noctua\", \"steenuil\"),\n    (\"Stormmeeuw\", \"Larus canus\", \"stormmeeuw\"),\n    (\"Tafeleend\", \"Aythya ferina\", \"tafeleend\"),\n    (\"Taigaboomkruiper\", \"Certhia familiaris\", \"taigaboomkruiper\"),\n    (\"Tapuit\", \"Oenanthe oenanthe\", \"tapuit\"),\n    (\"Tjiftjaf\", \"Phylloscopus collybita\", \"tjiftjaf\"),\n    (\"Toendrarietgans\", \"Anser serrirostris\", \"toendrarietgans\"),\n    (\"Torenvalk\", \"Falco tinnunculus\", \"torenvalk\"),\n    (\"Tuinfluiter\", \"Sylvia borin\", \"tuinfluiter\"),\n    (\"Tureluur\", \"Tringa totanus\", \"tureluur\"),\n    (\"Turkse Tortel\", \"Streptopelia decaocto\", \"turkse_tortel\"),\n    (\"Veldleeuwerik\", \"Alauda arvensis\", \"veldleeuwerik\"),\n    (\"Velduil\", \"Asio flammeus\", \"velduil\"),\n    (\"Vink\", \"Fringilla coelebs\", \"vink\"),\n    (\"Visdief\", \"Sterna hirundo\", \"visdief\"),\n    (\"Vuurgoudhaan\", \"Regulus ignicapilla\", \"vuurgoudhaan\"),\n    (\"Waterhoen\", \"Gallinula chloropus\", \"waterhoen\"),\n    (\"Waterral\", \"Rallus aquaticus\", \"waterral\"),\n    (\"Watersnip\", \"Gallinago gallinago\", \"watersnip\"),\n    (\"Wielewaal\", \"Oriolus oriolus\", \"wielewaal\"),\n    (\"Wilde Eend\", \"Anas platyrhynchos\", \"wilde_eend\"),\n    (\"Wilde Zwaan\", \"Cygnus cygnus\", \"wilde_zwaan\"),\n    (\"Winterkoning\", \"Troglodytes troglodytes\", \"winterkoning\"),\n    (\"Wintertaling\", \"Anas crecca\", \"wintertaling\"),\n    (\"Witgat\", \"Tringa ochropus\", \"witgat\"),\n    (\"Witte Kwikstaart\", \"Motacilla alba\", \"witte_kwikstaart\"),\n    (\"Wulp\", \"Numenius arquata\", \"wulp\"),\n    (\"Zanglijster\", \"Turdus philomelos\", \"zanglijster\"),\n    (\"Zilvermeeuw\", \"Larus argentatus\", \"zilvermeeuw\"),\n    (\"Zomertortel\", \"Streptopelia turtur\", \"zomertortel\"),\n    (\"Zwarte Kraai\", \"Corvus corone\", \"zwarte_kraai\"),\n    (\"Zwarte Mees\", \"Periparus ater\", \"zwarte_mees\"),\n    (\"Zwarte Roodstaart\", \"Phoenicurus ochruros\", \"zwarte_roodstaart\"),\n    (\"Zwarte Ruiter\", \"Tringa erythropus\", \"zwarte_ruiter\"),\n    (\"Zwarte Specht\", \"Dryocopus martius\", \"zwarte_specht\"),\n    (\"Zwartkop\", \"Sylvia atricapilla\", \"zwartkop\"),\n\n    # ===== SCANDINAVISCHE / BOREALE SOORTEN =====\n    (\"Auerhoen\", \"Tetrao urogallus\", \"auerhoen\"),\n    (\"Korhoen\", \"Lyrurus tetrix\", \"korhoen\"),\n    (\"Hazelhoen\", \"Tetrastes bonasia\", \"hazelhoen\"),\n    (\"Siberische Gaai\", \"Perisoreus infaustus\", \"siberische_gaai\"),\n    (\"Notenkraker\", \"Nucifraga caryocatactes\", \"notenkraker\"),\n    (\"Dwerguil\", \"Glaucidium passerinum\", \"dwerguil\"),\n    (\"Oeraluil\", \"Strix uralensis\", \"oeraluil\"),\n    (\"Ruigpootuil\", \"Aegolius funereus\", \"ruigpootuil\"),\n    (\"Sperweruil\", \"Surnia ulula\", \"sperweruil\"),\n    (\"Sneeuwuil\", \"Bubo scandiacus\", \"sneeuwuil\"),\n    (\"Witrugspecht\", \"Dendrocopos leucotos\", \"witrugspecht\"),\n    (\"Drieteenspecht\", \"Picoides tridactylus\", \"drieteenspecht\"),\n    (\"Grijskopspecht\", \"Picus canus\", \"grijskopspecht\"),\n    (\"Dennenkruisbek\", \"Loxia pytyopsittacus\", \"dennenkruisbek\"),\n    (\"Witbandkruisbek\", \"Loxia leucoptera\", \"witbandkruisbek\"),\n    (\"Noordse Nachtegaal\", \"Luscinia luscinia\", \"noordse_nachtegaal\"),\n    (\"Blauwstaart\", \"Tarsiger cyanurus\", \"blauwstaart\"),\n    (\"Arctische Warbler\", \"Phylloscopus borealis\", \"arctische_warbler\"),\n    (\"Bladkoninkje\", \"Phylloscopus proregulus\", \"bladkoninkje\"),\n    (\"Dwerggors\", \"Emberiza pusilla\", \"dwerggors\"),\n    (\"Bosgors\", \"Emberiza rustica\", \"bosgors\"),\n    (\"Dennengors\", \"Emberiza leucocephalos\", \"dennengors\"),\n    (\"IJsgors\", \"Calcarius lapponicus\", \"ijsgors\"),\n    (\"Siberische Heggenmus\", \"Prunella montanella\", \"siberische_heggenmus\"),\n    (\"Azuurmees\", \"Cyanistes cyanus\", \"azuurmees\"),\n    (\"Giervalk\", \"Falco rusticolus\", \"giervalk\"),\n    (\"Ruigpootbuizerd\", \"Buteo lagopus\", \"ruigpootbuizerd\"),\n    (\"Zeearend\", \"Haliaeetus albicilla\", \"zeearend\"),\n    (\"Steppekiekendief\", \"Circus macrourus\", \"steppekiekendief\"),\n    (\"Kleine Vliegenvanger\", \"Ficedula parva\", \"kleine_vliegenvanger\"),\n    (\"Withalsvliegenvanger\", \"Ficedula albicollis\", \"withalsvliegenvanger\"),\n    (\"Geelbrauwgors\", \"Emberiza chrysophrys\", \"geelbrauwgors\"),\n    (\"Siberische Pieper\", \"Anthus japonicus\", \"siberische_pieper\"),\n    (\"Siberische Boompieper\", \"Anthus hodgsoni\", \"siberische_boompieper\"),\n    (\"Pechorapieper\", \"Anthus gustavi\", \"pechorapieper\"),\n    (\"Siberische Lijster\", \"Geokichla sibirica\", \"siberische_lijster\"),\n    (\"Bruine Boszanger\", \"Phylloscopus fuscatus\", \"bruine_boszanger\"),\n    (\"Raddes Boszanger\", \"Phylloscopus schwarzi\", \"raddes_boszanger\"),\n\n    # ===== ZUID-EUROPESE / MEDITERRANE SOORTEN =====\n    (\"Orpheusgrasmug\", \"Curruca hortensis\", \"orpheusgrasmug\"),\n    (\"Sardijnse Grasmus\", \"Curruca melanocephala\", \"sardijnse_grasmus\"),\n    (\"Balearische Grasmus\", \"Curruca subalpina\", \"balearische_grasmus\"),\n    (\"Provencaalse Grasmus\", \"Curruca undata\", \"provencaalse_grasmus\"),\n    (\"Brilgrasmus\", \"Curruca conspicillata\", \"brilgrasmus\"),\n    (\"Sperwergrasmus\", \"Curruca nisoria\", \"sperwergrasmus\"),\n    (\"Roodkopklauwier\", \"Lanius senator\", \"roodkopklauwier\"),\n    (\"Kleine Klauwier\", \"Lanius minor\", \"kleine_klauwier\"),\n    (\"Maskerklauwier\", \"Lanius nubicus\", \"maskerklauwier\"),\n    (\"Kuifleeuwerik\", \"Galerida cristata\", \"kuifleeuwerik\"),\n    (\"Kortteenleeuwerik\", \"Calandrella brachydactyla\", \"kortteenleeuwerik\"),\n    (\"Kalanderleeuwerik\", \"Melanocorypha calandra\", \"kalanderleeuwerik\"),\n    (\"Kleine Trap\", \"Tetrax tetrax\", \"kleine_trap\"),\n    (\"Grote Trap\", \"Otis tarda\", \"grote_trap\"),\n    (\"Alpengierzwaluw\", \"Tachymarptis melba\", \"alpengierzwaluw\"),\n    (\"Vale Gierzwaluw\", \"Apus pallidus\", \"vale_gierzwaluw\"),\n    (\"Kleine Torenvalk\", \"Falco naumanni\", \"kleine_torenvalk\"),\n    (\"Eleonora's Valk\", \"Falco eleonorae\", \"eleonoras_valk\"),\n    (\"Slangenarend\", \"Circaetus gallicus\", \"slangenarend\"),\n    (\"Dwergarend\", \"Hieraaetus pennatus\", \"dwergarend\"),\n    (\"Steenarend\", \"Aquila chrysaetos\", \"steenarend\"),\n    (\"Lammergier\", \"Gypaetus barbatus\", \"lammergier\"),\n    (\"Vale Gier\", \"Gyps fulvus\", \"vale_gier\"),\n    (\"Griel\", \"Burhinus oedicnemus\", \"griel\"),\n    (\"Steltkluut\", \"Himantopus himantopus\", \"steltkluut\"),\n    (\"Vorkstaartplevier\", \"Glareola pratincola\", \"vorkstaartplevier\"),\n    (\"Dwergooruil\", \"Otus scops\", \"dwergooruil\"),\n    (\"Rotslijster\", \"Monticola saxatilis\", \"rotslijster\"),\n    (\"Blauwe Rotslijster\", \"Monticola solitarius\", \"blauwe_rotslijster\"),\n    (\"Isabeltapuit\", \"Oenanthe isabellina\", \"isabeltapuit\"),\n    (\"Blonde Tapuit\", \"Oenanthe hispanica\", \"blonde_tapuit\"),\n    (\"Rotszwaluw\", \"Ptyonoprogne rupestris\", \"rotszwaluw\"),\n    (\"Roodstuitzwaluw\", \"Cecropis daurica\", \"roodstuitzwaluw\"),\n    (\"Iberische Tjiftjaf\", \"Phylloscopus ibericus\", \"iberische_tjiftjaf\"),\n    (\"Spaanse Mus\", \"Passer hispaniolensis\", \"spaanse_mus\"),\n    (\"Rotsmus\", \"Petronia petronia\", \"rotsmus\"),\n    (\"Cirlgors\", \"Emberiza cirlus\", \"cirlgors\"),\n    (\"Rotsgors\", \"Emberiza cia\", \"rotsgors\"),\n    (\"Ortolaan\", \"Emberiza hortulana\", \"ortolaan\"),\n    (\"Purperreiger\", \"Ardea purpurea\", \"purperreiger\"),\n    (\"Ralreiger\", \"Ardeola ralloides\", \"ralreiger\"),\n    (\"Koereiger\", \"Bubulcus ibis\", \"koereiger\"),\n    (\"Woudaap\", \"Ixobrychus minutus\", \"woudaap\"),\n    (\"Zwarte Ooievaar\", \"Ciconia nigra\", \"zwarte_ooievaar\"),\n    (\"Lepelaar\", \"Platalea leucorodia\", \"lepelaar\"),\n    (\"Zwarte Ibis\", \"Plegadis falcinellus\", \"zwarte_ibis\"),\n    (\"Purperkoet\", \"Porphyrio porphyrio\", \"purperkoet\"),\n\n    # ===== OOST-EUROPESE SOORTEN =====\n    (\"Kleine Schreeuwarend\", \"Clanga pomarina\", \"kleine_schreeuwarend\"),\n    (\"Grote Schreeuwarend\", \"Clanga clanga\", \"grote_schreeuwarend\"),\n    (\"Keizerarend\", \"Aquila heliaca\", \"keizerarend\"),\n    (\"Sakervalk\", \"Falco cherrug\", \"sakervalk\"),\n    (\"Roodpootvalk\", \"Falco vespertinus\", \"roodpootvalk\"),\n    (\"Syrische Bonte Specht\", \"Dendrocopos syriacus\", \"syrische_bonte_specht\"),\n    (\"Krekelzanger\", \"Locustella fluviatilis\", \"krekelzanger\"),\n    (\"Struikrietzanger\", \"Acrocephalus dumetorum\", \"struikrietzanger\"),\n    (\"Veldrietzanger\", \"Acrocephalus agricola\", \"veldrietzanger\"),\n    (\"Waterrietzanger\", \"Acrocephalus paludicola\", \"waterrietzanger\"),\n    (\"Snorborstzanger\", \"Acrocephalus melanopogon\", \"snorborstzanger\"),\n    (\"Poelruiter\", \"Tringa stagnatilis\", \"poelruiter\"),\n    (\"Terekruiter\", \"Xenus cinereus\", \"terekruiter\"),\n    (\"Grote Snip\", \"Gallinago media\", \"grote_snip\"),\n    (\"Roze Spreeuw\", \"Pastor roseus\", \"roze_spreeuw\"),\n    (\"Izabelklauwier\", \"Lanius isabellinus\", \"izabelklauwier\"),\n    (\"Bruine Klauwier\", \"Lanius cristatus\", \"bruine_klauwier\"),\n    (\"Citroenkwikstaart\", \"Motacilla citreola\", \"citroenkwikstaart\"),\n    (\"Zwartkeellijster\", \"Turdus atrogularis\", \"zwartkeellijster\"),\n    (\"Bruine Lijster\", \"Turdus eunomus\", \"bruine_lijster\"),\n    (\"Vale Lijster\", \"Turdus obscurus\", \"vale_lijster\"),\n    (\"Groene Fitis\", \"Phylloscopus trochiloides\", \"groene_fitis\"),\n    (\"Geelbrauwfitis\", \"Phylloscopus inornatus\", \"geelbrauwfitis\"),\n    (\"Humes Bladfitis\", \"Phylloscopus humei\", \"humes_bladfitis\"),\n    (\"Bonelli's Fitis\", \"Phylloscopus bonelli\", \"bonellis_fitis\"),\n    (\"Roodmus\", \"Carpodacus erythrinus\", \"roodmus\"),\n    (\"Frater\", \"Linaria flavirostris\", \"frater\"),\n    (\"Siberische Roodborsttapuit\", \"Saxicola maurus\", \"siberische_roodborsttapuit\"),\n\n    # ===== TREKVOGELS / DOORTREKKERS / NOCMIG =====\n    (\"Kemphaan\", \"Calidris pugnax\", \"kemphaan\"),\n    (\"Krombekstrandloper\", \"Calidris ferruginea\", \"krombekstrandloper\"),\n    (\"Temmincks Strandloper\", \"Calidris temminckii\", \"temmincks_strandloper\"),\n    (\"Paarse Strandloper\", \"Calidris maritima\", \"paarse_strandloper\"),\n    (\"Morinelplevier\", \"Eudromias morinellus\", \"morinelplevier\"),\n    (\"Strandplevier\", \"Anarhynchus alexandrinus\", \"strandplevier\"),\n    (\"Kleine Plevier\", \"Charadrius dubius\", \"kleine_plevier\"),\n    (\"Zilverplevier\", \"Pluvialis squatarola\", \"zilverplevier\"),\n    (\"Zwarte Stern\", \"Chlidonias niger\", \"zwarte_stern\"),\n    (\"Witvleugelstern\", \"Chlidonias leucopterus\", \"witvleugelstern\"),\n    (\"Witwangstern\", \"Chlidonias hybrida\", \"witwangstern\"),\n    (\"Grote Stern\", \"Thalasseus sandvicensis\", \"grote_stern\"),\n    (\"Noordse Stern\", \"Sterna paradisaea\", \"noordse_stern\"),\n    (\"Reuzenstern\", \"Hydroprogne caspia\", \"reuzenstern\"),\n    (\"Lachstern\", \"Gelochelidon nilotica\", \"lachstern\"),\n    (\"Visarend\", \"Pandion haliaetus\", \"visarend\"),\n    (\"Zwarte Wouw\", \"Milvus migrans\", \"zwarte_wouw\"),\n    (\"Wespendief\", \"Pernis apivorus\", \"wespendief\"),\n    (\"Grauwe Franjepoot\", \"Phalaropus lobatus\", \"grauwe_franjepoot\"),\n    (\"Rosse Franjepoot\", \"Phalaropus fulicarius\", \"rosse_franjepoot\"),\n    (\"Duinpieper\", \"Anthus campestris\", \"duinpieper\"),\n    (\"Waterpieper\", \"Anthus spinoletta\", \"waterpieper\"),\n    (\"Oeverpieper\", \"Anthus petrosus\", \"oeverpieper\"),\n    (\"Grote Pieper\", \"Anthus richardi\", \"grote_pieper\"),\n    (\"Klein Waterhoen\", \"Zapornia parva\", \"klein_waterhoen\"),\n    (\"Kleinst Waterhoen\", \"Zapornia pusilla\", \"kleinst_waterhoen\"),\n    (\"Alpenheggenmus\", \"Prunella collaris\", \"alpenheggenmus\"),\n    (\"Waterspreeuw\", \"Cinclus cinclus\", \"waterspreeuw\"),\n    (\"Gekuifde Koekoek\", \"Clamator glandarius\", \"gekuifde_koekoek\"),\n\n    # ===== PELAGISCHE / NOORDZEE / KUST SOORTEN =====\n    (\"Noordse Stormvogel\", \"Fulmarus glacialis\", \"noordse_stormvogel\"),\n    (\"Stormvogeltje\", \"Hydrobates pelagicus\", \"stormvogeltje\"),\n    (\"Grauwe Pijlstormvogel\", \"Ardenna grisea\", \"grauwe_pijlstormvogel\"),\n    (\"Noordse Pijlstormvogel\", \"Puffinus puffinus\", \"noordse_pijlstormvogel\"),\n    (\"Jan-van-gent\", \"Morus bassanus\", \"jan_van_gent\"),\n    (\"Papegaaiduiker\", \"Fratercula arctica\", \"papegaaiduiker\"),\n    (\"Alk\", \"Alca torda\", \"alk\"),\n    (\"Kleine Alk\", \"Alle alle\", \"kleine_alk\"),\n    (\"Zeekoet\", \"Uria aalge\", \"zeekoet\"),\n    (\"Zwarte Zeekoet\", \"Cepphus grylle\", \"zwarte_zeekoet\"),\n    (\"Drieteenmeeuw\", \"Rissa tridactyla\", \"drieteenmeeuw\"),\n    (\"Kleine Meeuw\", \"Hydrocoloeus minutus\", \"kleine_meeuw\"),\n    (\"Zwartkopmeeuw\", \"Ichthyaetus melanocephalus\", \"zwartkopmeeuw\"),\n    (\"Pontische Meeuw\", \"Larus cachinnans\", \"pontische_meeuw\"),\n    (\"Grote Burgemeester\", \"Larus hyperboreus\", \"grote_burgemeester\"),\n    (\"Kleine Burgemeester\", \"Larus glaucoides\", \"kleine_burgemeester\"),\n    (\"Grote Jager\", \"Stercorarius skua\", \"grote_jager\"),\n    (\"Kleine Jager\", \"Stercorarius parasiticus\", \"kleine_jager\"),\n    (\"Kleinste Jager\", \"Stercorarius longicaudus\", \"kleinste_jager\"),\n    (\"Middelste Jager\", \"Stercorarius pomarinus\", \"middelste_jager\"),\n    (\"Zwarte Zee-eend\", \"Melanitta nigra\", \"zwarte_zee_eend\"),\n    (\"Grote Zee-eend\", \"Melanitta fusca\", \"grote_zee_eend\"),\n    (\"IJseend\", \"Clangula hyemalis\", \"ijseend\"),\n    (\"Toppereend\", \"Aythya marila\", \"toppereend\"),\n    (\"Krooneend\", \"Netta rufina\", \"krooneend\"),\n    (\"Witoogeend\", \"Aythya nyroca\", \"witoogeend\"),\n    (\"Parelduiker\", \"Gavia arctica\", \"parelduiker\"),\n    (\"IJsduiker\", \"Gavia immer\", \"ijsduiker\"),\n    (\"Kuifduiker\", \"Podiceps auritus\", \"kuifduiker\"),\n    (\"Geoorde Fuut\", \"Podiceps nigricollis\", \"geoorde_fuut\"),\n    (\"Rotgans\", \"Branta bernicla\", \"rotgans\"),\n    (\"Zomertaling\", \"Spatula querquedula\", \"zomertaling\"),\n    (\"Taigarietgans\", \"Anser fabalis\", \"taigarietgans\"),\n]\n\n# Deduplicatie op directory naam\n_seen = set()\n_deduped = []\nfor species in ALL_SPECIES:\n    key = species[2]  # directory naam\n    if key not in _seen:\n        _seen.add(key)\n        _deduped.append(species)\nALL_SPECIES = sorted(_deduped, key=lambda x: x[0])  # Sorteer op Nederlandse naam\n\nprint(f\"Te trainen: {len(ALL_SPECIES)} soorten x max {len(VOCALIZATION_TYPES)} types\")\nprint(f\"\\nCategorieÃ«n:\")\nprint(f\"  Nederlandse broedvogels & vaste gasten\")\nprint(f\"  Scandinavische / boreale soorten\")\nprint(f\"  Zuid-Europese / mediterrane soorten\")\nprint(f\"  Oost-Europese soorten\")\nprint(f\"  Trekvogels / doortrekkers / nocmig\")\nprint(f\"  Pelagische / Noordzee / kust soorten\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title 5. Xeno-Canto API v3 + Parallel Downloads\nimport requests\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom tqdm import tqdm\n\n\ndef search_xeno_canto(scientific_name: str, voc_type: str, max_results: int = 100) -> list:\n    \"\"\"Zoek opnames op Xeno-Canto API v3.\n\n    API v3 gebruikt uitsluitend tags - geen vrije tekst queries.\n    Kwaliteitsfilter via post-processing (q>:C syntax bestaat niet in v3).\n    \"\"\"\n    parts = scientific_name.split()\n    if len(parts) < 2:\n        return []\n\n    genus, species = parts[0].lower(), parts[1].lower()\n\n    # Multi-word types moeten URL-encoded quotes hebben\n    if ' ' in voc_type:\n        type_query = f'type:\"{voc_type}\"'\n    else:\n        type_query = f'type:{voc_type}'\n\n    # API v3: alleen tags, geen q>:C syntax\n    query = f'gen:{genus} sp:{species} {type_query}'\n    url = f'https://xeno-canto.org/api/3/recordings?query={query}&key={XC_API_KEY}'\n\n    # Retry met exponential backoff (geen recursie!)\n    for attempt in range(4):\n        try:\n            response = requests.get(url, timeout=30)\n            if response.status_code == 200:\n                data = response.json()\n                # Check voor API errors\n                if 'error' in data:\n                    print(f\"API error: {data.get('message', '')[:60]}\", end=' ')\n                    return []\n                recordings = data.get('recordings', [])\n                # Filter en sorteer op kwaliteit (A en B eerst, C+ weg)\n                quality_order = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n                recordings = [r for r in recordings if r.get('q', 'E') in ('A', 'B', 'C')]\n                recordings.sort(key=lambda r: quality_order.get(r.get('q', 'E'), 5))\n                return recordings[:max_results]\n            elif response.status_code == 429:  # Rate limit\n                wait = 5 * (attempt + 1)\n                print(f\"    Rate limit, wacht {wait}s...\", end=' ')\n                time.sleep(wait)\n                continue\n            else:\n                return []\n        except requests.exceptions.Timeout:\n            time.sleep(2)\n            continue\n        except Exception:\n            return []\n\n    return []  # Alle retries gefaald\n\n\ndef download_single(args):\n    \"\"\"Download een enkele opname.\"\"\"\n    recording, output_dir = args\n    xc_id = recording['id']\n    file_url = recording.get('file', '')\n\n    if not file_url:\n        return None\n\n    if file_url.startswith('//'):\n        file_url = 'https:' + file_url\n    elif not file_url.startswith('http'):\n        file_url = 'https://xeno-canto.org' + file_url\n\n    output_path = output_dir / f\"XC{xc_id}.mp3\"\n\n    if output_path.exists():\n        return output_path\n\n    try:\n        response = requests.get(file_url, timeout=60)\n        if response.status_code == 200 and len(response.content) > 1000:\n            with open(output_path, 'wb') as f:\n                f.write(response.content)\n            return output_path\n    except Exception:\n        pass\n    return None\n\n\ndef download_recordings_parallel(recordings, output_dir, max_workers=12):\n    \"\"\"Download opnames parallel.\"\"\"\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    downloaded = []\n    args_list = [(rec, output_dir) for rec in recordings]\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {executor.submit(download_single, args): args[0]['id'] for args in args_list}\n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                downloaded.append(result)\n\n    return downloaded\n\n\nprint(f\"Xeno-Canto API v3 klaar (key via Colab Secret)\")\nprint(f\"  Kwaliteitsfilter: A, B, C (post-processing)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Audio Processing + Adaptive Augmentatie\nimport librosa\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\n\n\ndef generate_pink_noise(length: int) -> np.ndarray:\n    \"\"\"Genereer pink noise (1/f) - realistischer dan white noise.\"\"\"\n    uneven = length % 2\n    X = np.random.randn(length // 2 + 1 + uneven) + 1j * np.random.randn(length // 2 + 1 + uneven)\n    S = np.sqrt(np.arange(len(X)) + 1.0)\n    y = (np.fft.irfft(X / S)).real[:length]\n    return y / (np.abs(y).max() + 1e-8)\n\n\ndef augment_audio(audio: np.ndarray, sr: int, level: str = 'normal') -> list:\n    \"\"\"Audio augmentatie met instelbaar niveau.\n\n    level='light': 3 versies (origineel + 2 augmented) - voor grote classes\n    level='normal': 5 versies - standaard\n    level='heavy': 8+ versies - voor kleine classes (oversampling)\n    \"\"\"\n    augmented = [audio.copy()]\n    target_len = len(audio)\n\n    def _fix_len(a):\n        if len(a) > target_len:\n            return a[:target_len]\n        elif len(a) < target_len:\n            return np.pad(a, (0, target_len - len(a)))\n        return a\n\n    # === Altijd: pitch shift (1x) ===\n    try:\n        steps = np.random.uniform(-AUG_PITCH_RANGE, AUG_PITCH_RANGE)\n        augmented.append(librosa.effects.pitch_shift(audio, sr=sr, n_steps=steps))\n    except Exception:\n        pass\n\n    # === Altijd: noise (1x) ===\n    noise_level = np.random.choice(AUG_NOISE_LEVELS)\n    augmented.append(audio + np.random.normal(0, noise_level, target_len))\n\n    if level in ('normal', 'heavy'):\n        # Time stretch\n        rate = np.random.choice([1.0 - AUG_STRETCH_RANGE, 1.0 + AUG_STRETCH_RANGE])\n        try:\n            augmented.append(_fix_len(librosa.effects.time_stretch(audio, rate=rate)))\n        except Exception:\n            pass\n\n        # Pink noise\n        pink = generate_pink_noise(target_len) * AUG_PINK_NOISE_LEVEL\n        augmented.append(audio + pink)\n\n    if level == 'heavy':\n        # Extra pitch shifts\n        for _ in range(2):\n            try:\n                steps = np.random.uniform(-AUG_PITCH_RANGE, AUG_PITCH_RANGE)\n                shifted = librosa.effects.pitch_shift(audio, sr=sr, n_steps=steps)\n                noise = np.random.normal(0, np.random.choice(AUG_NOISE_LEVELS), target_len)\n                augmented.append(shifted + noise)\n            except Exception:\n                pass\n\n        # Extra time stretch + noise combo\n        try:\n            rate = np.random.uniform(1.0 - AUG_STRETCH_RANGE, 1.0 + AUG_STRETCH_RANGE)\n            stretched = _fix_len(librosa.effects.time_stretch(audio, rate=rate))\n            pink = generate_pink_noise(target_len) * AUG_PINK_NOISE_LEVEL * 1.5\n            augmented.append(stretched + pink)\n        except Exception:\n            pass\n\n        # Gain variation\n        for gain in [0.7, 1.3]:\n            augmented.append(np.clip(audio * gain, -1.0, 1.0))\n\n    return augmented\n\n\ndef audio_to_spectrogram(audio: np.ndarray, sr: int = SAMPLE_RATE) -> np.ndarray:\n    \"\"\"Converteer audio naar mel-spectrogram.\"\"\"\n    mel_spec = librosa.feature.melspectrogram(\n        y=audio, sr=sr,\n        n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH,\n        fmin=FMIN, fmax=FMAX\n    )\n    mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n    mel_range = mel_db.max() - mel_db.min()\n    if mel_range > 0:\n        mel_norm = (mel_db - mel_db.min()) / mel_range\n    else:\n        mel_norm = np.zeros_like(mel_db)\n\n    # Resize naar 128x128\n    if mel_norm.shape != (128, 128):\n        from skimage.transform import resize\n        mel_norm = resize(mel_norm, (128, 128), anti_aliasing=True)\n\n    return mel_norm.astype(np.float32)\n\n\ndef apply_spec_augment(spec: np.ndarray) -> np.ndarray:\n    \"\"\"SpecAugment: mask random frequentie- en tijdbanden.\"\"\"\n    spec = spec.copy()\n    n_freq, n_time = spec.shape\n\n    for _ in range(np.random.randint(1, 3)):\n        f_width = np.random.randint(1, AUG_SPEC_FREQ_MASK)\n        f_start = np.random.randint(0, max(1, n_freq - f_width))\n        spec[f_start:f_start + f_width, :] = 0\n\n    for _ in range(np.random.randint(1, 3)):\n        t_width = np.random.randint(1, AUG_SPEC_TIME_MASK)\n        t_start = np.random.randint(0, max(1, n_time - t_width))\n        spec[:, t_start:t_start + t_width] = 0\n\n    return spec\n\n\ndef process_single_audio(audio_path, max_segments=4, aug_level='normal'):\n    \"\"\"Verwerk audio naar spectrogrammen met adaptive augmentatie.\"\"\"\n    try:\n        audio, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE, mono=True)\n    except Exception:\n        return []\n\n    segment_samples = int(SEGMENT_DURATION * SAMPLE_RATE)\n    spectrograms = []\n\n    segments = []\n    for i in range(0, len(audio), segment_samples):\n        segment = audio[i:i + segment_samples]\n        if len(segment) < segment_samples // 2:\n            continue\n        if len(segment) < segment_samples:\n            segment = np.pad(segment, (0, segment_samples - len(segment)))\n        segments.append(segment)\n        if len(segments) >= max_segments:\n            break\n\n    for segment in segments:\n        if aug_level == 'none':\n            spec = audio_to_spectrogram(segment)\n            spectrograms.append(spec)\n        else:\n            aug_versions = augment_audio(segment, SAMPLE_RATE, level=aug_level)\n            for aug in aug_versions:\n                spec = audio_to_spectrogram(aug)\n                if np.random.random() > 0.5:\n                    spec = apply_spec_augment(spec)\n                spectrograms.append(spec)\n\n    return spectrograms\n\n\ndef process_audio_files_parallel(audio_paths, max_segments=4, max_workers=4,\n                                  aug_level='normal'):\n    \"\"\"Verwerk meerdere audio bestanden parallel.\"\"\"\n    all_specs = []\n    func = partial(process_single_audio, max_segments=max_segments, aug_level=aug_level)\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        results = list(executor.map(func, audio_paths))\n\n    for specs in results:\n        all_specs.extend(specs)\n\n    return all_specs\n\n\nprint(f\"Audio processing klaar\")\nprint(f\"  Augmentatie niveaus: light (3x), normal (5x), heavy (10x)\")\nprint(f\"  Adaptive: kleine classes krijgen meer augmentatie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7. Ultimate CNN v2 - Squeeze-and-Excitation + Residual\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.amp import GradScaler, autocast\n\n\nclass SqueezeExcitation(nn.Module):\n    \"\"\"Squeeze-and-Excitation block: leert welke feature channels belangrijk zijn.\"\"\"\n    def __init__(self, channels, reduction=16):\n        super().__init__()\n        self.fc1 = nn.Linear(channels, channels // reduction)\n        self.fc2 = nn.Linear(channels // reduction, channels)\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        # Squeeze: global average pooling\n        y = x.view(b, c, -1).mean(dim=2)\n        # Excitation: learn channel importance\n        y = F.relu(self.fc1(y), inplace=True)\n        y = torch.sigmoid(self.fc2(y))\n        # Scale\n        return x * y.view(b, c, 1, 1)\n\n\nclass ResidualConvBlock(nn.Module):\n    \"\"\"Conv block met residual connection + SE attention.\"\"\"\n    def __init__(self, in_ch, out_ch, dropout=0.2):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_ch)\n        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_ch)\n        self.se = SqueezeExcitation(out_ch, reduction=max(4, out_ch // 16))\n        self.pool = nn.MaxPool2d(2)\n        self.dropout = nn.Dropout2d(dropout)\n\n        # Residual projection als channels veranderen\n        self.residual = nn.Conv2d(in_ch, out_ch, 1, bias=False) if in_ch != out_ch else nn.Identity()\n        self.residual_pool = nn.AvgPool2d(2)\n\n    def forward(self, x):\n        residual = self.residual_pool(self.residual(x))\n\n        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n        out = self.bn2(self.conv2(out))\n        out = self.se(out)\n        out = self.pool(out)\n\n        out = F.relu(out + residual, inplace=True)\n        out = self.dropout(out)\n        return out\n\n\nclass UltimateVocalizationCNN(nn.Module):\n    \"\"\"Ultimate CNN v2 met residual connections en SE-attention.\n\n    Compatibel met EMSN inference code (zelfde output format).\n    Significant betere feature extraction door:\n    - Residual connections (gradient flow, diepere training)\n    - SE-blocks (channel attention: focus op relevante features)\n    - Adaptive average pooling (robuuster dan fixed flatten)\n\n    Input: 1x128x128 mel spectrogram\n    \"\"\"\n\n    def __init__(self, input_shape=(128, 128), num_classes=10):\n        super().__init__()\n\n        self.features = nn.Sequential(\n            ResidualConvBlock(1, 32, dropout=0.15),      # 128->64\n            ResidualConvBlock(32, 64, dropout=0.15),     # 64->32\n            ResidualConvBlock(64, 128, dropout=0.2),     # 32->16\n            ResidualConvBlock(128, 256, dropout=0.25),   # 16->8\n        )\n\n        # Adaptive pooling: werkt ongeacht input grootte\n        self.pool = nn.AdaptiveAvgPool2d((4, 4))\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(256 * 4 * 4, 512),                # 4096 -> 512\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(512, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.4),\n            nn.Linear(256, num_classes),\n        )\n\n        # Betere initialisatie\n        self._init_weights()\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.pool(x)\n        x = self.classifier(x)\n        return x\n\n\n# === FOCAL LOSS ===\nclass FocalLoss(nn.Module):\n    \"\"\"Focal Loss: focust op moeilijk te classificeren samples.\n\n    Reduceert de loss voor makkelijke samples, zodat het model\n    meer leert van de moeilijke/zeldzame classes.\n\n    gamma=0: identiek aan CrossEntropyLoss\n    gamma=2: standaard, goede balans (wat wij gebruiken)\n    \"\"\"\n    def __init__(self, weight=None, gamma=2.0, label_smoothing=0.0):\n        super().__init__()\n        self.gamma = gamma\n        self.weight = weight\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(\n            inputs, targets,\n            weight=self.weight,\n            label_smoothing=self.label_smoothing,\n            reduction='none'\n        )\n        pt = torch.exp(-ce_loss)\n        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n        return focal_loss.mean()\n\n\nprint(f\"UltimateVocalizationCNN v2 klaar\")\nprint(f\"  Nieuw: Residual connections + SE-attention + Focal Loss\")\ntest_model = UltimateVocalizationCNN(num_classes=10).to(device)\nparams = sum(p.numel() for p in test_model.parameters())\ntrainable = sum(p.numel() for p in test_model.parameters() if p.requires_grad)\nprint(f\"  Parameters: {params:,} (all trainable)\")\n\n# Quick forward test\nwith torch.no_grad():\n    dummy = torch.randn(2, 1, 128, 128).to(device)\n    out = test_model(dummy)\n    print(f\"  Output shape: {out.shape} (verwacht: [2, 10])\")\ndel test_model, dummy, out\ntorch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 8. Training Pipeline per Soort (v2: Focal Loss + Oversampling + Mixup)\nfrom torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import balanced_accuracy_score, f1_score\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom collections import Counter\n\n\ndef balanced_accuracy(y_true, y_pred):\n    \"\"\"Balanced accuracy: gemiddelde recall per class.\n    Veel betere metric bij class imbalance dan overall accuracy.\"\"\"\n    return balanced_accuracy_score(y_true, y_pred)\n\n\ndef mixup_data(x, y, alpha=0.3):\n    \"\"\"Mixup augmentatie: mix random paren van samples.\n    Verbetert generalisatie significant bij kleine datasets.\"\"\"\n    if alpha <= 0:\n        return x, y, y, 1.0\n\n    lam = np.random.beta(alpha, alpha)\n    lam = max(lam, 1 - lam)  # Zorg dat lambda >= 0.5\n\n    batch_size = x.size(0)\n    index = torch.randperm(batch_size, device=x.device)\n\n    mixed_x = lam * x + (1 - lam) * x[index]\n    return mixed_x, y, y[index], lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    \"\"\"Loss functie voor mixup samples.\"\"\"\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n\ndef adaptive_augmentation_level(num_raw_specs: int) -> str:\n    \"\"\"Bepaal augmentatie niveau op basis van beschikbare data.\"\"\"\n    if num_raw_specs >= 400:\n        return 'light'     # Genoeg data, minimale augmentatie\n    elif num_raw_specs >= 100:\n        return 'normal'    # Standaard augmentatie\n    else:\n        return 'heavy'     # Agressieve augmentatie voor kleine classes\n\n\ndef oversample_to_target(X_list, y_list, target_per_class):\n    \"\"\"Oversample kleine classes naar target aantal.\n    Dupliceert random samples uit kleine classes.\"\"\"\n    X = np.array(X_list)\n    y = np.array(y_list)\n\n    unique_labels = np.unique(y)\n    X_balanced, y_balanced = [], []\n\n    for label in unique_labels:\n        mask = y == label\n        X_class = X[mask]\n        n = len(X_class)\n\n        X_balanced.append(X_class)\n        y_balanced.append(np.full(n, label))\n\n        # Oversample als nodig\n        if n < target_per_class:\n            extra_needed = target_per_class - n\n            indices = np.random.choice(n, size=extra_needed, replace=True)\n            X_balanced.append(X_class[indices])\n            y_balanced.append(np.full(extra_needed, label))\n\n    return np.concatenate(X_balanced), np.concatenate(y_balanced)\n\n\ndef integrate_retraining_data(dirname, X_all, y_all, available_types):\n    \"\"\"Integreer eigen review-data van HiDrive.\"\"\"\n    retraining_dir = LOCAL_RETRAINING / dirname\n    if not retraining_dir.exists():\n        return X_all, y_all, available_types\n\n    added = 0\n    for type_name, type_info in VOCALIZATION_TYPES.items():\n        type_dir = retraining_dir / type_name\n        if not type_dir.exists():\n            continue\n\n        label = type_info['label']\n        audio_files = list(type_dir.glob('*.mp3')) + list(type_dir.glob('*.wav'))\n        if not audio_files:\n            continue\n\n        specs = process_audio_files_parallel(\n            audio_files, max_segments=MAX_SEGMENTS_PER_RECORDING,\n            max_workers=NUM_WORKERS, aug_level='none',\n        )\n\n        for spec in specs:\n            X_all.append(spec)\n            y_all.append(label)\n            added += 1\n\n        if label not in available_types:\n            available_types[label] = type_name\n\n    if added > 0:\n        print(f\"  +{added} eigen review-specs geintegreerd\")\n\n    return X_all, y_all, available_types\n\n\ndef train_species(dutch_name, scientific_name, dirname):\n    \"\"\"Train een 10-type model voor een soort.\n\n    v2 verbeteringen:\n    - Adaptive augmentatie (meer voor kleine classes)\n    - Oversampling naar TARGET_SAMPLES_PER_CLASS\n    - Focal Loss (focus op moeilijke samples)\n    - Mixup regularisatie\n    - Balanced accuracy als metric (niet overall accuracy)\n    - Cosine annealing met warm restarts\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"  {dutch_name} ({scientific_name})\")\n    print(f\"{'='*60}\")\n\n    start_time = time.time()\n    audio_dir = LOCAL_AUDIO / dirname\n\n    # Fase 1: Download data per type en bepaal augmentatie niveau\n    raw_counts = {}  # type -> aantal raw recordings\n    X_all, y_all = [], []\n    available_types = {}\n\n    for type_name, type_info in VOCALIZATION_TYPES.items():\n        xc_query = type_info['xc_query']\n        label = type_info['label']\n\n        print(f\"  [{label}] {type_name} (XC: {xc_query})...\", end=' ')\n\n        recordings = search_xeno_canto(\n            scientific_name, xc_query, max_results=MAX_RECORDINGS_PER_TYPE\n        )\n\n        if not recordings:\n            print(\"0 gevonden\")\n            continue\n\n        type_dir = audio_dir / xc_query.replace(' ', '_')\n        audio_files = download_recordings_parallel(\n            recordings[:MAX_RECORDINGS_PER_TYPE],\n            type_dir,\n            max_workers=MAX_CONCURRENT_DOWNLOADS,\n        )\n\n        if not audio_files:\n            print(\"0 downloads\")\n            continue\n\n        raw_counts[label] = len(audio_files)\n\n        # Adaptive augmentatie: eerste pass zonder augmentatie om raw count te krijgen\n        raw_specs = process_audio_files_parallel(\n            audio_files,\n            max_segments=MAX_SEGMENTS_PER_RECORDING,\n            max_workers=NUM_WORKERS,\n            aug_level='none',\n        )\n\n        raw_spec_count = len(raw_specs)\n        aug_level = adaptive_augmentation_level(raw_spec_count)\n\n        # Tweede pass met juiste augmentatie niveau\n        if aug_level != 'none':\n            specs = process_audio_files_parallel(\n                audio_files,\n                max_segments=MAX_SEGMENTS_PER_RECORDING,\n                max_workers=NUM_WORKERS,\n                aug_level=aug_level,\n            )\n        else:\n            specs = raw_specs\n\n        if len(specs) >= MIN_SAMPLES_PER_TYPE:\n            for spec in specs:\n                X_all.append(spec)\n                y_all.append(label)\n            available_types[label] = type_name\n            print(f\"{len(audio_files)} files -> {raw_spec_count} raw -> {len(specs)} aug ({aug_level})\")\n        else:\n            print(f\"{len(specs)} specs (< {MIN_SAMPLES_PER_TYPE}, skip)\")\n\n    # Integreer eigen review-data\n    X_all, y_all, available_types = integrate_retraining_data(\n        dirname, X_all, y_all, available_types\n    )\n\n    if len(available_types) < MIN_TYPES_FOR_TRAINING:\n        print(f\"  Te weinig types ({len(available_types)} < {MIN_TYPES_FOR_TRAINING})\")\n        return None, 'insufficient_types'\n\n    # Fase 2: Remap labels en oversample\n    unique_labels = sorted(available_types.keys())\n    num_classes = len(unique_labels)\n    label_map = {old: new for new, old in enumerate(unique_labels)}\n    reverse_map = {new: old for old, new in label_map.items()}\n    class_names = [available_types[unique_labels[i]] for i in range(num_classes)]\n    y_remapped = np.array([label_map[l] for l in y_all])\n\n    # Toon verdeling VOOR oversampling\n    unique, counts = np.unique(y_remapped, return_counts=True)\n    print(f\"\\n  Types: {num_classes} | Totaal voor balancering: {len(X_all)} specs\")\n    for u, c in zip(unique, counts):\n        print(f\"    [{u}] {class_names[u]}: {c}\")\n\n    # Oversample naar gebalanceerde dataset\n    max_class_count = max(counts)\n    target = min(TARGET_SAMPLES_PER_CLASS, max_class_count)\n    X_balanced, y_balanced = oversample_to_target(X_all, y_remapped, target)\n\n    unique2, counts2 = np.unique(y_balanced, return_counts=True)\n    print(f\"  Na balancering: {len(X_balanced)} specs (target: {target}/class)\")\n    for u, c in zip(unique2, counts2):\n        print(f\"    [{u}] {class_names[u]}: {c}\")\n\n    # Fase 3: Train/val split (stratified)\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_balanced, y_balanced, test_size=0.15, random_state=42, stratify=y_balanced\n    )\n\n    # Class weights voor Focal Loss (inverse frequency)\n    class_counts = Counter(y_train)\n    total_train = len(y_train)\n    class_weights = torch.tensor(\n        [total_train / (num_classes * class_counts.get(i, 1)) for i in range(num_classes)],\n        dtype=torch.float32\n    ).to(device)\n    # Normaliseer weights zodat mean=1\n    class_weights = class_weights / class_weights.mean()\n\n    # DataLoaders\n    train_dataset = TensorDataset(\n        torch.FloatTensor(X_train).unsqueeze(1),\n        torch.LongTensor(y_train),\n    )\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE, shuffle=True,\n        num_workers=NUM_WORKERS, pin_memory=True,\n        drop_last=(len(train_dataset) > BATCH_SIZE),\n    )\n    val_dataset = TensorDataset(\n        torch.FloatTensor(X_val).unsqueeze(1),\n        torch.LongTensor(y_val),\n    )\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS, pin_memory=True,\n    )\n\n    # Model + Focal Loss + Optimizer\n    model = UltimateVocalizationCNN(num_classes=num_classes).to(device)\n    criterion = FocalLoss(\n        weight=class_weights,\n        gamma=FOCAL_LOSS_GAMMA,\n        label_smoothing=LABEL_SMOOTHING,\n    )\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n    )\n\n    # Cosine annealing met warm restarts (T0=20 epochs, elke restart 2x langer)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2, eta_min=MIN_LR)\n\n    # Warmup wrapper\n    warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n        optimizer, start_factor=0.1, total_iters=WARMUP_EPOCHS\n    )\n    combined_scheduler = torch.optim.lr_scheduler.SequentialLR(\n        optimizer, schedulers=[warmup_scheduler, scheduler], milestones=[WARMUP_EPOCHS]\n    )\n\n    scaler = GradScaler(\"cuda\")\n\n    # Training loop\n    best_bal_acc = 0\n    best_f1 = 0\n    best_state = None\n    patience_counter = 0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        train_loss = 0\n        n_batches = 0\n\n        for X_batch, y_batch in train_loader:\n            X_batch = X_batch.to(device, non_blocking=True)\n            y_batch = y_batch.to(device, non_blocking=True)\n\n            # Mixup\n            mixed_x, y_a, y_b, lam = mixup_data(X_batch, y_batch, MIXUP_ALPHA)\n\n            optimizer.zero_grad(set_to_none=True)\n\n            with autocast(\"cuda\", dtype=dtype):\n                outputs = model(mixed_x)\n                loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n\n            train_loss += loss.item()\n            n_batches += 1\n\n        combined_scheduler.step()\n\n        # Validation met balanced accuracy\n        model.eval()\n        all_preds, all_targets = [], []\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch = X_batch.to(device, non_blocking=True)\n                with autocast(\"cuda\", dtype=dtype):\n                    outputs = model(X_batch)\n                preds = outputs.argmax(1).cpu().numpy()\n                all_preds.extend(preds)\n                all_targets.extend(y_batch.numpy())\n\n        bal_acc = balanced_accuracy(all_targets, all_preds)\n        f1 = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n\n        # Track best model op balanced accuracy\n        if bal_acc > best_bal_acc:\n            best_bal_acc = bal_acc\n            best_f1 = f1\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n            patience_counter = 0\n        else:\n            patience_counter += 1\n\n        if patience_counter >= PATIENCE:\n            print(f\"  Early stop @ epoch {epoch+1}\")\n            break\n\n    if best_state is None:\n        del model, train_loader, val_loader\n        torch.cuda.empty_cache()\n        gc.collect()\n        return None, 'training_failed'\n\n    # Save model\n    model_path = LOCAL_MODELS / f\"{dirname}_cnn_{VERSION}.pt\"\n    torch.save({\n        'model_state_dict': best_state,\n        'num_classes': num_classes,\n        'class_names': class_names,\n        'label_map': label_map,\n        'reverse_map': reverse_map,\n        'accuracy': best_bal_acc,\n        'f1_score': best_f1,\n        'species_name': dutch_name,\n        'scientific_name': scientific_name,\n        'version': VERSION,\n        'architecture': 'UltimateVocalizationCNN_v2',\n        'vocalization_types': VOCALIZATION_TYPES,\n        'available_types': available_types,\n        'training_info': {\n            'focal_loss_gamma': FOCAL_LOSS_GAMMA,\n            'mixup_alpha': MIXUP_ALPHA,\n            'oversampling_target': target,\n            'epochs_trained': epoch + 1,\n            'train_samples': len(X_train),\n            'val_samples': len(X_val),\n        },\n    }, model_path)\n\n    del model, train_loader, val_loader\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    elapsed = time.time() - start_time\n    print(f\"\\n  {model_path.name} | {num_classes} types | BalAcc: {best_bal_acc:.1%} | F1: {best_f1:.1%} | {elapsed:.0f}s\")\n\n    return best_bal_acc, 'success'\n\n\nprint(\"Training pipeline v2 klaar\")\nprint(\"  Focal Loss + Mixup + Oversampling + Balanced Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 9. START TRAINING (alle soorten, met auto-resume + quality gate)\nimport pandas as pd\n\n# â”€â”€ Resume detectie â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nexisting_models = {f.stem.replace(f'_cnn_{VERSION}', '') for f in LOCAL_MODELS.glob('*.pt')}\n\nprogress_csv = LOCAL_CHECKPOINT / 'training_progress.csv'\nif progress_csv.exists():\n    prev_results = pd.read_csv(progress_csv).to_dict('records')\n    prev_dirnames = {r['dirname'] for r in prev_results}\n    print(f\"Vorige progress gevonden: {len(prev_results)} soorten\")\nelse:\n    prev_results = []\n    prev_dirnames = set()\n\n# Download eerder getrainde modellen van HiDrive\ntry:\n    sftp, transport = get_sftp()\n    try:\n        remote_models = sftp.listdir(HIDRIVE_MODELS_DIR)\n        remote_pt = [f for f in remote_models if f.endswith('.pt') and VERSION in f]\n        for fname in remote_pt:\n            local_file = LOCAL_MODELS / fname\n            if not local_file.exists():\n                sftp.get(f\"{HIDRIVE_MODELS_DIR}/{fname}\", str(local_file))\n        existing_models = {f.stem.replace(f'_cnn_{VERSION}', '') for f in LOCAL_MODELS.glob('*.pt')}\n        print(f\"HiDrive modellen gesynced: {len(existing_models)} totaal\")\n    except FileNotFoundError:\n        print(\"Geen eerdere modellen op HiDrive\")\n    try:\n        remote_csv = f\"{HIDRIVE_CHECKPOINT_DIR}training_progress.csv\"\n        local_tmp = LOCAL_CHECKPOINT / 'hidrive_progress.csv'\n        sftp.get(remote_csv, str(local_tmp))\n        hd_results = pd.read_csv(local_tmp).to_dict('records')\n        if len(hd_results) > len(prev_results):\n            prev_results = hd_results\n            prev_dirnames = {r['dirname'] for r in prev_results}\n            print(f\"HiDrive progress geladen: {len(prev_results)} soorten\")\n        local_tmp.unlink(missing_ok=True)\n    except Exception:\n        pass\n    sftp.close()\n    transport.close()\nexcept Exception as e:\n    print(f\"HiDrive check overgeslagen: {e}\")\n\n# â”€â”€ Start training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nresults = list(prev_results)\nstart_all = time.time()\n\nskipped = 0\nsuccessful = sum(1 for r in prev_results if r.get('status') == 'success')\nfailed = sum(1 for r in prev_results if r.get('status') in ('error', 'training_failed', 'insufficient_types'))\n\nprint(f\"\\n{'='*60}\")\nprint(f\"EMSN VOCALISATIE 10-TYPES TRAINING v2\")\nprint(f\"{'='*60}\")\nprint(f\"Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"Soorten: {len(ALL_SPECIES)} totaal\")\nif existing_models:\n    print(f\"Al getraind: {len(existing_models)} modellen (worden overgeslagen)\")\nprint(f\"GPU: {GPU_TIER} ({GPU_NAME})\")\nprint(f\"Methode: Focal Loss + Mixup + Oversampling + Balanced Accuracy\")\nprint(f\"{'='*60}\")\n\nQUALITY_GATE = 0.25  # Minimum balanced accuracy (25% = beter dan random bij 4 types)\n\nfor i, (dutch, scientific, dirname) in enumerate(ALL_SPECIES):\n    if dirname in existing_models:\n        skipped += 1\n        continue\n\n    if dirname in prev_dirnames:\n        skipped += 1\n        continue\n\n    try:\n        acc, status = train_species(dutch, scientific, dirname)\n        results.append({\n            'species': dutch,\n            'scientific': scientific,\n            'dirname': dirname,\n            'accuracy': acc,\n            'status': status,\n        })\n\n        # Quality gate: als accuracy echt te laag is, noteer maar ga door\n        if status == 'success' and acc is not None and acc < QUALITY_GATE:\n            print(f\"  âš  Lage accuracy ({acc:.1%}) - model opgeslagen maar markeer als low_quality\")\n            results[-1]['status'] = 'low_quality'\n\n        if status == 'success':\n            successful += 1\n        else:\n            failed += 1\n\n    except Exception as e:\n        print(f\"  Error: {str(e)[:80]}\")\n        results.append({\n            'species': dutch,\n            'scientific': scientific,\n            'dirname': dirname,\n            'accuracy': None,\n            'status': 'error',\n        })\n        failed += 1\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    # Checkpoint elke 10 soorten\n    new_count = successful + failed - sum(1 for r in prev_results if r.get('status') in ('success', 'error', 'training_failed', 'insufficient_types', 'low_quality'))\n    if new_count > 0 and new_count % 10 == 0:\n        df = pd.DataFrame(results)\n        csv_path = LOCAL_CHECKPOINT / 'training_progress.csv'\n        df.to_csv(csv_path, index=False)\n\n        elapsed = time.time() - start_all\n        remaining = len(ALL_SPECIES) - skipped - successful - failed\n        eta = (elapsed / max(new_count, 1)) * remaining\n        \n        ok_results = [r for r in results if r.get('status') == 'success' and r.get('accuracy')]\n        avg_acc = np.mean([r['accuracy'] for r in ok_results]) if ok_results else 0\n        \n        print(f\"\\n  [{successful + failed}/{len(ALL_SPECIES)}] {successful} OK / {failed} mislukt / {skipped} skip\")\n        print(f\"  Gem. balanced accuracy: {avg_acc:.1%} | ETA: {eta/60:.0f}min\")\n\n        try:\n            for model_file in LOCAL_MODELS.glob('*.pt'):\n                upload_to_hidrive(model_file, HIDRIVE_MODELS_DIR)\n            upload_to_hidrive(csv_path, HIDRIVE_CHECKPOINT_DIR)\n            print(f\"  HiDrive checkpoint uploaded\")\n        except Exception as e:\n            print(f\"  HiDrive fout (niet fataal): {e}\")\n\n# Finale checkpoint\ndf = pd.DataFrame(results)\ncsv_path = LOCAL_CHECKPOINT / 'training_progress.csv'\ndf.to_csv(csv_path, index=False)\n\nelapsed_all = time.time() - start_all\nok_results = [r for r in results if r.get('status') == 'success' and r.get('accuracy')]\navg_acc = np.mean([r['accuracy'] for r in ok_results]) if ok_results else 0\n\nprint(f\"\\n{'='*60}\")\nprint(f\"TRAINING VOLTOOID\")\nprint(f\"{'='*60}\")\nprint(f\"Tijd: {elapsed_all/3600:.1f} uur\")\nprint(f\"Succesvol: {successful}/{len(ALL_SPECIES)}\")\nprint(f\"Mislukt: {failed}/{len(ALL_SPECIES)}\")\nprint(f\"Overgeslagen: {skipped}\")\nprint(f\"Gem. balanced accuracy: {avg_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 10. Resultaten & Analyse\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame(results)\ncsv_path = LOCAL_CHECKPOINT / 'training_progress.csv'\ndf.to_csv(csv_path, index=False)\n\nok = df[df['status'].isin(['success', 'low_quality'])]\ngood = df[df['status'] == 'success']\nlow = df[df['status'] == 'low_quality']\nnok = df[~df['status'].isin(['success', 'low_quality'])]\n\nprint(f\"\\n{'='*60}\")\nprint(f\"RESULTATEN v2 (Balanced Accuracy)\")\nprint(f\"{'='*60}\")\nprint(f\"Totaal soorten: {len(df)}\")\nprint(f\"Succesvol: {len(good)} ({len(good)/len(df)*100:.0f}%)\")\nprint(f\"Lage kwaliteit: {len(low)} ({len(low)/len(df)*100:.0f}%)\")\nprint(f\"Mislukt/overgeslagen: {len(nok)} ({len(nok)/len(df)*100:.0f}%)\")\n\nif len(ok) > 0:\n    print(f\"\\nBalanced Accuracy (alle modellen):\")\n    print(f\"  Gemiddeld:  {ok['accuracy'].mean():.1%}\")\n    print(f\"  Mediaan:    {ok['accuracy'].median():.1%}\")\n    print(f\"  Std:        {ok['accuracy'].std():.1%}\")\n    print(f\"  Min:        {ok['accuracy'].min():.1%}\")\n    print(f\"  Max:        {ok['accuracy'].max():.1%}\")\n\n    # Kwaliteits breakdown\n    excellent = ok[ok['accuracy'] >= 0.7]\n    good_q = ok[(ok['accuracy'] >= 0.4) & (ok['accuracy'] < 0.7)]\n    fair_q = ok[(ok['accuracy'] >= 0.25) & (ok['accuracy'] < 0.4)]\n    poor_q = ok[ok['accuracy'] < 0.25]\n\n    print(f\"\\nKwaliteitsverdeling:\")\n    print(f\"  Excellent (>=70%): {len(excellent)} soorten\")\n    print(f\"  Goed (40-70%):     {len(good_q)} soorten\")\n    print(f\"  Matig (25-40%):    {len(fair_q)} soorten\")\n    print(f\"  Slecht (<25%):     {len(poor_q)} soorten\")\n\n    # Top 15\n    print(f\"\\nTop 15:\")\n    for _, row in ok.nlargest(15, 'accuracy').iterrows():\n        print(f\"  {row['accuracy']:.1%} - {row['species']} ({row['scientific']})\")\n\n    # Bottom 10\n    print(f\"\\nBottom 10:\")\n    for _, row in ok.nsmallest(10, 'accuracy').iterrows():\n        print(f\"  {row['accuracy']:.1%} - {row['species']} ({row['scientific']})\")\n\n    # Visualisatie\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n    # Histogram\n    ax = axes[0]\n    colors = ['#e74c3c' if a < 0.25 else '#f39c12' if a < 0.4 else '#27ae60' if a < 0.7 else '#2980b9'\n              for a in ok['accuracy']]\n    ax.hist(ok['accuracy'] * 100, bins=25, edgecolor='black', alpha=0.8, color='#7e57c2')\n    ax.axvline(ok['accuracy'].mean() * 100, color='red', linestyle='--',\n               label=f\"Gemiddeld: {ok['accuracy'].mean():.1%}\")\n    ax.axvline(ok['accuracy'].median() * 100, color='orange', linestyle='--',\n               label=f\"Mediaan: {ok['accuracy'].median():.1%}\")\n    ax.set_xlabel('Balanced Accuracy (%)')\n    ax.set_ylabel('Aantal soorten')\n    ax.set_title('Balanced Accuracy Verdeling')\n    ax.legend()\n\n    # Box plot per kwaliteitsgroep\n    ax = axes[1]\n    categories = []\n    if len(excellent) > 0: categories.append(('Excellent\\n>=70%', excellent['accuracy'].values * 100))\n    if len(good_q) > 0: categories.append(('Goed\\n40-70%', good_q['accuracy'].values * 100))\n    if len(fair_q) > 0: categories.append(('Matig\\n25-40%', fair_q['accuracy'].values * 100))\n    if len(poor_q) > 0: categories.append(('Slecht\\n<25%', poor_q['accuracy'].values * 100))\n\n    if categories:\n        ax.bar(range(len(categories)), [len(c[1]) for c in categories],\n               color=['#2980b9', '#27ae60', '#f39c12', '#e74c3c'][:len(categories)],\n               edgecolor='black', alpha=0.8)\n        ax.set_xticks(range(len(categories)))\n        ax.set_xticklabels([c[0] for c in categories])\n        ax.set_ylabel('Aantal soorten')\n        ax.set_title('Kwaliteitsverdeling')\n        for i, c in enumerate(categories):\n            ax.text(i, len(c[1]) + 0.5, str(len(c[1])), ha='center', fontweight='bold')\n\n    plt.suptitle(f'EMSN Vocalisatie 10-Types v2 - {len(ok)} soorten getraind', fontsize=14)\n    plt.tight_layout()\n    hist_path = LOCAL_CHECKPOINT / 'accuracy_analysis.png'\n    plt.savefig(hist_path, dpi=150, bbox_inches='tight')\n    plt.show()\n\n# Mislukte soorten\nif len(nok) > 0:\n    print(f\"\\nMislukt ({len(nok)}):\")\n    status_counts = nok['status'].value_counts()\n    for status, count in status_counts.items():\n        print(f\"  {status}: {count}\")\n        for _, row in nok[nok['status'] == status].head(5).iterrows():\n            print(f\"    - {row['species']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 11. Upload ALLE modellen naar HiDrive\n\nmodels = sorted(LOCAL_MODELS.glob('*.pt'))\n\nprint(f\"{'='*60}\")\nprint(f\"FINALE UPLOAD NAAR HIDRIVE\")\nprint(f\"{'='*60}\")\nprint(f\"Modellen: {len(models)}\")\n\nif models:\n    total_size = sum(m.stat().st_size for m in models) / 1e6\n    print(f\"Totale grootte: {total_size:.0f} MB\")\n\n    for model_file in tqdm(models, desc=\"Uploaden\"):\n        try:\n            upload_to_hidrive(model_file, HIDRIVE_MODELS_DIR)\n        except Exception as e:\n            print(f\"  Fout bij {model_file.name}: {e}\")\n\n    # Upload resultaten CSV\n    csv_path = LOCAL_CHECKPOINT / 'training_progress.csv'\n    if csv_path.exists():\n        upload_to_hidrive(csv_path, HIDRIVE_MODELS_DIR)\n\n    print(f\"\\nAlles uploaded naar HiDrive: {HIDRIVE_MODELS_DIR}\")\n\nprint(f\"\"\"\n{'='*60}\nINSTALLATIE OP PI\n{'='*60}\n\n1. Download modellen van HiDrive:\n\n   rclone sync hidrive:users/ronnyclouddisk/emsn-backups/vocalization-models-10types/ \\\\\n     /mnt/nas-docker/emsn-vocalization/data/models/ --progress\n\n2. Backup oude modellen:\n\n   cp -r /mnt/nas-docker/emsn-vocalization/data/models/ \\\\\n     /mnt/nas-birdnet-archive/getrainde_modellen_EMSN/backup_$(date +%Y%m%d)/\n\n3. Herstart services:\n\n   sudo systemctl restart vocalization-enricher.service\n   sudo systemctl restart emsn-reports-api.service\n\n{'='*60}\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samenvatting\n\n### Training v2 Architectuur\n\n| Component | v1 | v2 |\n|-----------|----|----|\n| **Loss** | CrossEntropy | **Focal Loss** (gamma=2.0) |\n| **Regularisatie** | Label smoothing | **Mixup** (alpha=0.3) + Label smoothing |\n| **Balancering** | Class weights | **Oversampling** + Class weights |\n| **Metric** | Overall accuracy | **Balanced accuracy** + F1 |\n| **Model** | 4-blok CNN | **SE-ResNet CNN** (residual + attention) |\n| **Augmentatie** | Uniform 8x | **Adaptive** (light/normal/heavy) |\n| **Scheduler** | Cosine decay | **Cosine warm restarts** |\n| **Resume** | Geen | **Auto-resume** via HiDrive |\n\n### Installatie op Pi\n\n```bash\n# 1. Download modellen van HiDrive\nsftp ronnyclouddisk@sftp.hidrive.strato.com <<< \"get -r /users/ronnyclouddisk/emsn-backups/vocalization-models-10types/ /tmp/models/\"\nsudo cp /tmp/models/*.pt /mnt/nas-docker/emsn-vocalization/data/models/\n\n# 2. Backup oude modellen\ncp -r /mnt/nas-docker/emsn-vocalization/data/models/ \\\n  /mnt/nas-birdnet-archive/getrainde_modellen_EMSN/backup_$(date +%Y%m%d)/\n\n# 3. Herstart services\nsudo systemctl restart vocalization-enricher.service\nsudo systemctl restart emsn-reports-api.service\n```\n\n### EMSN Project\n- **Repo:** https://github.com/RonnyCHL/emsn-vocalization\n- **Eigenaar:** Ronny Hullegie - Ecologisch Monitoring Systeem Nijverdal"
   ]
  }
 ]
}