{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# EMSN AtmosBird Cloud Classifier - Volledig Automatisch\n\n**One-Click Training:** Runtime → Run All → Wacht → Download Model\n\nDeze notebook:\n1. **Laadt automatisch** de training beelden uit Google Drive (`EMSN/cloud_classifier/atmosbird_training.zip`)\n2. **Labelt automatisch** op basis van brightness, contrast en kleur\n3. **Traint EfficientNet-B0** (~10-15 min op A100)\n4. **Exporteert ONNX** model voor Raspberry Pi\n\n---\n## Instructies\n1. **Runtime → Change runtime type → GPU (A100) + High RAM**\n2. **Runtime → Run all** (Ctrl+F9)\n3. Wacht tot training klaar is (~10-15 min)\n4. Download model uit Google Drive"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title 1. Installatie & Setup (duurt ~1 minuut)\nprint(\"Installeren van dependencies...\")\n!pip install -q torch torchvision timm pillow matplotlib scikit-learn tqdm\n!pip install -q onnx onnxruntime onnxscript\n\nimport os\nimport json\nimport random\nimport shutil\nimport zipfile\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import List, Dict, Tuple\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.cluster import KMeans\n\n# GPU Check\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\n{'='*50}\")\nprint(f\"Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nprint(f\"{'='*50}\\n\")\nprint(\"Setup compleet!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Google Drive Mount & Werkdirectory\n",
    "from google.colab import drive\n",
    "\n",
    "print(\"Google Drive mounten...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Werkdirectory in Google Drive (blijft bewaard)\n",
    "WORK_DIR = Path('/content/drive/MyDrive/EMSN/cloud_classifier')\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lokale temp directory (sneller)\n",
    "LOCAL_DIR = Path('/content/atmosbird_data')\n",
    "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nWerkdirectory: {WORK_DIR}\")\n",
    "print(f\"Lokale cache: {LOCAL_DIR}\")\n",
    "print(\"\\nDrive gemount!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title 3. Laad AtmosBird Beelden (automatisch uit Drive)\nimport zipfile\n\n# Pad naar de ZIP in Google Drive (geupload via rclone)\nZIP_PATH = WORK_DIR / 'atmosbird_training.zip'\n\n# Lokale images directory\nIMAGES_DIR = LOCAL_DIR / 'images'\nIMAGES_DIR.mkdir(exist_ok=True)\n\n# Check of ZIP bestaat\nif ZIP_PATH.exists():\n    print(f\"ZIP gevonden: {ZIP_PATH}\")\n    print(f\"Grootte: {ZIP_PATH.stat().st_size / 1024 / 1024:.1f} MB\")\n    print(\"\\nUitpakken...\")\n    \n    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n        # Extract alleen JPG files\n        jpg_files = [f for f in zip_ref.namelist() if f.lower().endswith('.jpg')]\n        print(f\"Gevonden: {len(jpg_files)} JPG bestanden\")\n        \n        for jpg in tqdm(jpg_files, desc=\"Uitpakken\"):\n            # Extract naar flat directory (zonder subdirs)\n            data = zip_ref.read(jpg)\n            dest = IMAGES_DIR / Path(jpg).name\n            with open(dest, 'wb') as f:\n                f.write(data)\n    \n    print(f\"\\nKlaar! {len(list(IMAGES_DIR.glob('*.jpg')))} beelden geladen.\")\n\nelif (WORK_DIR / 'images').exists() and len(list((WORK_DIR / 'images').glob('*.jpg'))) > 100:\n    # Gebruik bestaande images directory\n    existing_images = list((WORK_DIR / 'images').glob('*.jpg'))\n    print(f\"Gebruik bestaande beelden: {len(existing_images)} stuks\")\n    print(\"Kopieren naar lokale cache...\")\n    \n    for img in tqdm(existing_images[:500], desc=\"Kopieren\"):\n        shutil.copy(img, IMAGES_DIR / img.name)\n    \n    print(f\"\\nKlaar! {len(list(IMAGES_DIR.glob('*.jpg')))} beelden geladen.\")\n\nelse:\n    # Fallback: handmatige upload\n    from google.colab import files\n    print(\"=\"*50)\n    print(\"GEEN ZIP GEVONDEN IN GOOGLE DRIVE\")\n    print(\"=\"*50)\n    print(f\"\\nVerwacht pad: {ZIP_PATH}\")\n    print(\"\\nUpload je ZIP bestand handmatig...\")\n    print(\"=\"*50 + \"\\n\")\n    \n    uploaded = files.upload()\n    \n    for filename in uploaded.keys():\n        if filename.endswith('.zip'):\n            print(f\"\\nUitpakken: {filename}...\")\n            \n            with zipfile.ZipFile(filename, 'r') as zip_ref:\n                jpg_files = [f for f in zip_ref.namelist() if f.lower().endswith('.jpg')]\n                print(f\"Gevonden: {len(jpg_files)} JPG bestanden\")\n                \n                for jpg in tqdm(jpg_files, desc=\"Uitpakken\"):\n                    data = zip_ref.read(jpg)\n                    dest = IMAGES_DIR / Path(jpg).name\n                    with open(dest, 'wb') as f:\n                        f.write(data)\n            \n            # Kopieer ZIP naar Google Drive voor later\n            shutil.copy(filename, ZIP_PATH)\n            print(f\"\\nZIP ook opgeslagen in Google Drive: {ZIP_PATH}\")\n            print(f\"Klaar! {len(list(IMAGES_DIR.glob('*.jpg')))} beelden geladen.\")\n            break\n\nprint(f\"\\nBeelden directory: {IMAGES_DIR}\")\nprint(f\"Aantal beelden: {len(list(IMAGES_DIR.glob('*.jpg')))}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title 4. Automatische Labeling (K-Means Clustering)\nprint(\"Automatisch labelen van beelden met K-Means clustering...\\n\")\n\nfrom scipy import ndimage\n\ndef analyze_image(img_path: Path) -> Dict:\n    \"\"\"Analyseer beeld voor automatische labeling.\"\"\"\n    img = Image.open(img_path).convert('RGB')\n    img_array = np.array(img)\n    \n    # Bereken statistieken\n    gray = np.mean(img_array, axis=2)\n    brightness = np.mean(gray)\n    contrast = np.std(gray)\n    \n    # Kleur analyse (blauw vs grijs)\n    r, g, b = img_array[:,:,0], img_array[:,:,1], img_array[:,:,2]\n    blue_ratio = np.mean(b) / (np.mean(r) + np.mean(g) + np.mean(b) + 1e-6)\n    \n    # Textuur (Laplacian variance)\n    laplacian = ndimage.laplace(gray)\n    texture = np.var(laplacian)\n    \n    # Saturation (kleurrijkheid)\n    hsv_s = np.std([r, g, b], axis=0).mean()\n    \n    return {\n        'brightness': brightness,\n        'contrast': contrast,\n        'blue_ratio': blue_ratio,\n        'texture': texture,\n        'saturation': hsv_s\n    }\n\n# Analyseer alle beelden\nall_images = list(IMAGES_DIR.glob('*.jpg'))\nprint(f\"Analyseren van {len(all_images)} beelden...\\n\")\n\nfeatures_list = []\nvalid_images = []\n\nfor img_path in tqdm(all_images, desc=\"Analyseren\"):\n    try:\n        features = analyze_image(img_path)\n        features['name'] = img_path.name\n        features_list.append(features)\n        valid_images.append(img_path.name)\n    except Exception as e:\n        print(f\"Fout bij {img_path.name}: {e}\")\n\n# Maak feature matrix voor clustering\nfeature_matrix = np.array([\n    [f['brightness'], f['contrast'], f['blue_ratio'] * 100, f['texture'], f['saturation']]\n    for f in features_list\n])\n\n# Normaliseer features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nfeature_matrix_scaled = scaler.fit_transform(feature_matrix)\n\n# K-Means clustering met 3 clusters\nprint(\"\\nK-Means clustering voor 3 klassen...\")\nkmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\ncluster_labels = kmeans.fit_predict(feature_matrix_scaled)\n\n# Bepaal welke cluster welke klasse is op basis van brightness\ncluster_brightness = {}\nfor i in range(3):\n    mask = cluster_labels == i\n    cluster_brightness[i] = np.mean(feature_matrix[mask, 0])  # brightness\n\n# Sorteer clusters op brightness: laagste = bewolkt (grijs), hoogste = helder (blauw)\nsorted_clusters = sorted(cluster_brightness.items(), key=lambda x: x[1])\n\n# Map clusters naar klassen\n# Middelste brightness = gedeeltelijk, laagste = bewolkt, hoogste = helder\ncluster_to_class = {}\nfor rank, (cluster_id, brightness) in enumerate(sorted_clusters):\n    if rank == 0:\n        cluster_to_class[cluster_id] = 'bewolkt'  # Laagste brightness (grijs/donker)\n    elif rank == 1:\n        cluster_to_class[cluster_id] = 'gedeeltelijk'  # Midden\n    else:\n        cluster_to_class[cluster_id] = 'helder'  # Hoogste brightness (blauw)\n\n# Maak labels dictionary\nlabels = {}\nfor i, name in enumerate(valid_images):\n    cluster = cluster_labels[i]\n    labels[name] = cluster_to_class[cluster]\n\n# Statistieken\nprint(f\"\\n{'='*50}\")\nprint(\"AUTOMATISCHE LABELING RESULTAAT (K-Means)\")\nprint(f\"{'='*50}\")\nlabel_counts = {}\nfor label in labels.values():\n    label_counts[label] = label_counts.get(label, 0) + 1\n\nfor label in ['helder', 'gedeeltelijk', 'bewolkt']:\n    count = label_counts.get(label, 0)\n    pct = count / len(labels) * 100 if len(labels) > 0 else 0\n    print(f\"  {label}: {count} ({pct:.1f}%)\")\n\nprint(f\"\\nTotaal: {len(labels)} beelden gelabeld\")\n\n# Toon cluster centers info\nprint(f\"\\nCluster karakteristieken (brightness gemiddelde):\")\nfor cluster_id, brightness in sorted_clusters:\n    cls = cluster_to_class[cluster_id]\n    print(f\"  {cls}: brightness={brightness:.1f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Bekijk Voorbeelden per Klasse\n",
    "def show_examples(labels: Dict, images_dir: Path, n_examples: int = 6):\n",
    "    \"\"\"Toon voorbeelden per klasse.\"\"\"\n",
    "    classes = ['helder', 'gedeeltelijk', 'bewolkt']\n",
    "    \n",
    "    fig, axes = plt.subplots(3, n_examples, figsize=(20, 12))\n",
    "    \n",
    "    for row, cls in enumerate(classes):\n",
    "        # Vind beelden van deze klasse\n",
    "        cls_images = [k for k, v in labels.items() if v == cls]\n",
    "        samples = random.sample(cls_images, min(n_examples, len(cls_images)))\n",
    "        \n",
    "        for col, img_name in enumerate(samples):\n",
    "            img = Image.open(images_dir / img_name)\n",
    "            img.thumbnail((400, 300))\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].axis('off')\n",
    "            if col == 0:\n",
    "                axes[row, col].set_ylabel(cls.upper(), fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Automatisch Gelabelde Voorbeelden', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(WORK_DIR / 'label_examples.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "show_examples(labels, IMAGES_DIR)\n",
    "print(\"\\nControleer of de labels correct lijken.\")\n",
    "print(\"Als niet, kun je de thresholds in cel 4 aanpassen en opnieuw uitvoeren.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Dataset & Model Setup\n",
    "print(\"Dataset en model voorbereiden...\\n\")\n",
    "\n",
    "# Configuratie\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "CLASS_MAPPING = {'helder': 0, 'gedeeltelijk': 1, 'bewolkt': 2}\n",
    "CLASS_NAMES = ['helder', 'gedeeltelijk', 'bewolkt']\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE + 32, IMAGE_SIZE + 32)),\n",
    "    transforms.RandomCrop(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = [(self.image_dir / k, CLASS_MAPPING[v]) \n",
    "                        for k, v in labels.items() if v in CLASS_MAPPING]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Train/Val split\n",
    "items = list(labels.items())\n",
    "train_items, val_items = train_test_split(items, test_size=0.2, random_state=42)\n",
    "train_labels = dict(train_items)\n",
    "val_labels = dict(val_items)\n",
    "\n",
    "train_dataset = CloudDataset(IMAGES_DIR, train_labels, train_transform)\n",
    "val_dataset = CloudDataset(IMAGES_DIR, val_labels, val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training set: {len(train_dataset)} beelden\")\n",
    "print(f\"Validation set: {len(val_dataset)} beelden\")\n",
    "\n",
    "# Model\n",
    "class CloudClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.backbone.num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.backbone(x))\n",
    "\n",
    "model = CloudClassifier().to(device)\n",
    "print(f\"\\nModel geladen: EfficientNet-B0\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7. Training (duurt ~10-15 minuten)\n",
    "print(\"=\"*50)\n",
    "print(\"START TRAINING\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images, targets in pbar:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        train_correct += (outputs.argmax(1) == targets).sum().item()\n",
    "        train_total += targets.size(0)\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{train_correct/train_total:.2%}'})\n",
    "    \n",
    "    train_loss /= train_total\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            val_correct += (outputs.argmax(1) == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "    \n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  ★ Nieuw beste model! Val acc: {val_acc:.2%}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss={train_loss:.4f}, Acc={train_acc:.2%}, Val_Loss={val_loss:.4f}, Val_Acc={val_acc:.2%}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"TRAINING COMPLEET!\")\n",
    "print(f\"Beste validatie accuracy: {best_val_acc:.2%}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title 8. Resultaten & Evaluatie\n# Plot training history\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\nax1.plot(history['train_loss'], label='Train')\nax1.plot(history['val_loss'], label='Validation')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.set_title('Training Loss')\nax1.legend()\nax1.grid(True)\n\nax2.plot(history['train_acc'], label='Train')\nax2.plot(history['val_acc'], label='Validation')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Accuracy')\nax2.set_title('Training Accuracy')\nax2.legend()\nax2.grid(True)\n\nplt.tight_layout()\nplt.savefig(WORK_DIR / 'training_history.png', dpi=150)\nplt.show()\n\n# Confusion matrix\nmodel.load_state_dict(best_model_state)\nmodel.eval()\n\nall_preds, all_targets = [], []\nwith torch.no_grad():\n    for images, targets in val_loader:\n        outputs = model(images.to(device))\n        all_preds.extend(outputs.argmax(1).cpu().numpy())\n        all_targets.extend(targets.numpy())\n\n# Bepaal welke klassen daadwerkelijk voorkomen\nunique_classes = sorted(set(all_targets) | set(all_preds))\nactual_class_names = [CLASS_NAMES[i] for i in unique_classes]\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_targets, all_preds, \n                           labels=unique_classes,\n                           target_names=actual_class_names,\n                           zero_division=0))\n\n# Confusion matrix met alle 3 klassen\ncm = confusion_matrix(all_targets, all_preds, labels=[0, 1, 2])\nfig, ax = plt.subplots(figsize=(8, 6))\nim = ax.imshow(cm, cmap='Blues')\nax.set_xticks(range(3))\nax.set_yticks(range(3))\nax.set_xticklabels(CLASS_NAMES)\nax.set_yticklabels(CLASS_NAMES)\nax.set_xlabel('Voorspeld')\nax.set_ylabel('Werkelijk')\nax.set_title('Confusion Matrix')\nfor i in range(3):\n    for j in range(3):\n        ax.text(j, i, str(cm[i, j]), ha='center', va='center',\n                color='white' if cm[i, j] > cm.max()/2 else 'black')\nplt.colorbar(im)\nplt.tight_layout()\nplt.savefig(WORK_DIR / 'confusion_matrix.png', dpi=150)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 9. Export naar ONNX\n",
    "print(\"Exporteren naar ONNX formaat...\\n\")\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "model_cpu = model.cpu()\n",
    "\n",
    "# Paden\n",
    "ONNX_PATH = WORK_DIR / 'cloud_classifier.onnx'\n",
    "PT_PATH = WORK_DIR / 'cloud_classifier.pt'\n",
    "\n",
    "# PyTorch checkpoint\n",
    "torch.save({\n",
    "    'model_state_dict': best_model_state,\n",
    "    'class_names': CLASS_NAMES,\n",
    "    'image_size': IMAGE_SIZE,\n",
    "    'best_val_acc': best_val_acc,\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'labels': labels\n",
    "}, PT_PATH)\n",
    "print(f\"PyTorch checkpoint: {PT_PATH}\")\n",
    "\n",
    "# ONNX export\n",
    "dummy_input = torch.randn(1, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "torch.onnx.export(\n",
    "    model_cpu,\n",
    "    dummy_input,\n",
    "    ONNX_PATH,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}}\n",
    ")\n",
    "\n",
    "print(f\"ONNX model: {ONNX_PATH}\")\n",
    "print(f\"Model grootte: {ONNX_PATH.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Valideer ONNX\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnx_model = onnx.load(ONNX_PATH)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"\\nONNX model validatie: OK!\")\n",
    "\n",
    "# Test inference\n",
    "session = ort.InferenceSession(str(ONNX_PATH))\n",
    "test_input = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "output = session.run(None, {'input': test_input})[0]\n",
    "print(f\"ONNX inference test: OK! Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 10. Sla Labels op\n",
    "labels_path = WORK_DIR / 'labels.json'\n",
    "with open(labels_path, 'w') as f:\n",
    "    json.dump(labels, f, indent=2)\n",
    "print(f\"Labels opgeslagen: {labels_path}\")\n",
    "print(f\"Totaal: {len(labels)} gelabelde beelden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 11. Klaar! Download Instructies\n",
    "print(\"=\"*60)\n",
    "print(\"         TRAINING SUCCESVOL AFGEROND!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBeste validatie accuracy: {best_val_acc:.1%}\")\n",
    "print(f\"\\nBestanden staan in Google Drive:\")\n",
    "print(f\"  {WORK_DIR}/\")\n",
    "print(f\"    ├── cloud_classifier.onnx  ({ONNX_PATH.stat().st_size/1024/1024:.1f} MB)\")\n",
    "print(f\"    ├── cloud_classifier.pt\")\n",
    "print(f\"    ├── labels.json\")\n",
    "print(f\"    ├── training_history.png\")\n",
    "print(f\"    └── confusion_matrix.png\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEPLOYMENT OP PI BERGING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. Download cloud_classifier.onnx van Google Drive\n",
    "\n",
    "2. Kopieer naar Pi:\n",
    "   scp cloud_classifier.onnx ronny@192.168.1.87:/home/ronny/emsn2/scripts/atmosbird/\n",
    "\n",
    "3. Test op Pi:\n",
    "   cd /home/ronny/emsn2/scripts/atmosbird\n",
    "   python cloud_classifier_inference.py cloud_classifier.onnx \\\n",
    "       /mnt/usb/atmosbird/ruwe_foto/2025/12/30/sky_20251230_120000.jpg\n",
    "\n",
    "4. Het model is nu klaar voor gebruik in atmosbird_capture.py!\n",
    "\"\"\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}