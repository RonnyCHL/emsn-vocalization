{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMSN AtmosBird Cloud Classifier - Volledig Automatisch\n",
    "\n",
    "**One-Click Training:** Upload ZIP → Train → Download Model\n",
    "\n",
    "Deze notebook gebruikt semi-supervised learning:\n",
    "1. Pre-trained model voor initiële classificatie\n",
    "2. Brightness-based dag/nacht detectie\n",
    "3. Automatische labeling + handmatige correctie optie\n",
    "\n",
    "---\n",
    "## Instructies\n",
    "1. **Runtime → Change runtime type → GPU (A100) + High RAM**\n",
    "2. **Runtime → Run all** (Ctrl+F9)\n",
    "3. Upload je ZIP als gevraagd\n",
    "4. Wacht tot training klaar is (~10-15 min)\n",
    "5. Download model uit Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Installatie & Setup (duurt ~1 minuut)\n",
    "print(\"Installeren van dependencies...\")\n",
    "!pip install -q torch torchvision timm onnx onnxruntime pillow matplotlib scikit-learn tqdm\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# GPU Check\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "print(\"Setup compleet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Google Drive Mount & Werkdirectory\n",
    "from google.colab import drive\n",
    "\n",
    "print(\"Google Drive mounten...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Werkdirectory in Google Drive (blijft bewaard)\n",
    "WORK_DIR = Path('/content/drive/MyDrive/EMSN/cloud_classifier')\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lokale temp directory (sneller)\n",
    "LOCAL_DIR = Path('/content/atmosbird_data')\n",
    "LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nWerkdirectory: {WORK_DIR}\")\n",
    "print(f\"Lokale cache: {LOCAL_DIR}\")\n",
    "print(\"\\nDrive gemount!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Upload AtmosBird Beelden (ZIP)\n",
    "from google.colab import files\n",
    "\n",
    "# Check of er al beelden zijn\n",
    "existing_images = list((WORK_DIR / 'images').glob('*.jpg')) if (WORK_DIR / 'images').exists() else []\n",
    "\n",
    "if len(existing_images) > 100:\n",
    "    print(f\"Er zijn al {len(existing_images)} beelden in Google Drive.\")\n",
    "    USE_EXISTING = True\n",
    "else:\n",
    "    USE_EXISTING = False\n",
    "    print(\"=\"*50)\n",
    "    print(\"UPLOAD JE ATMOSBIRD BEELDEN\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nMaak op de Pi een ZIP met:\")\n",
    "    print(\"  cd /mnt/usb/atmosbird/ruwe_foto/2025/12\")\n",
    "    print(\"  zip -r atmosbird.zip 20 21 22 23 24 25 26 27 28 29 30\")\n",
    "    print(\"\\nOf selecteer specifieke beelden:\")\n",
    "    print(\"  find . -name '*.jpg' | shuf -n 500 | zip atmosbird.zip -@\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Upload nu je ZIP bestand...\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"\\nUitpakken: {filename}...\")\n",
    "            \n",
    "            # Uitpakken naar lokale directory\n",
    "            images_dir = LOCAL_DIR / 'images'\n",
    "            images_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                # Extract alleen JPG files\n",
    "                jpg_files = [f for f in zip_ref.namelist() if f.lower().endswith('.jpg')]\n",
    "                print(f\"Gevonden: {len(jpg_files)} JPG bestanden\")\n",
    "                \n",
    "                for jpg in tqdm(jpg_files, desc=\"Uitpakken\"):\n",
    "                    # Extract naar flat directory\n",
    "                    data = zip_ref.read(jpg)\n",
    "                    dest = images_dir / Path(jpg).name\n",
    "                    with open(dest, 'wb') as f:\n",
    "                        f.write(data)\n",
    "            \n",
    "            # Kopieer ook naar Google Drive voor later\n",
    "            gdrive_images = WORK_DIR / 'images'\n",
    "            gdrive_images.mkdir(exist_ok=True)\n",
    "            print(f\"\\nKopieren naar Google Drive...\")\n",
    "            for img in tqdm(list(images_dir.glob('*.jpg')), desc=\"Kopieren\"):\n",
    "                shutil.copy(img, gdrive_images / img.name)\n",
    "            \n",
    "            print(f\"\\nKlaar! {len(list(images_dir.glob('*.jpg')))} beelden geladen.\")\n",
    "            break\n",
    "\n",
    "# Set images directory\n",
    "if USE_EXISTING:\n",
    "    IMAGES_DIR = WORK_DIR / 'images'\n",
    "    # Kopieer naar lokaal voor snellere toegang\n",
    "    LOCAL_IMAGES = LOCAL_DIR / 'images'\n",
    "    LOCAL_IMAGES.mkdir(exist_ok=True)\n",
    "    print(f\"Kopieren van {len(existing_images)} beelden naar lokale cache...\")\n",
    "    for img in tqdm(existing_images[:500], desc=\"Kopieren\"):  # Max 500 voor snelheid\n",
    "        shutil.copy(img, LOCAL_IMAGES / img.name)\n",
    "    IMAGES_DIR = LOCAL_IMAGES\n",
    "else:\n",
    "    IMAGES_DIR = LOCAL_DIR / 'images'\n",
    "\n",
    "print(f\"\\nBeelden directory: {IMAGES_DIR}\")\n",
    "print(f\"Aantal beelden: {len(list(IMAGES_DIR.glob('*.jpg')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Automatische Labeling\n",
    "print(\"Automatisch labelen van beelden...\\n\")\n",
    "\n",
    "def analyze_image(img_path: Path) -> Dict:\n",
    "    \"\"\"Analyseer beeld voor automatische labeling.\"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Bereken statistieken\n",
    "    gray = np.mean(img_array, axis=2)\n",
    "    brightness = np.mean(gray)\n",
    "    contrast = np.std(gray)\n",
    "    \n",
    "    # Kleur analyse (blauw vs grijs)\n",
    "    r, g, b = img_array[:,:,0], img_array[:,:,1], img_array[:,:,2]\n",
    "    blue_ratio = np.mean(b) / (np.mean(r) + np.mean(g) + np.mean(b) + 1e-6)\n",
    "    \n",
    "    # Textuur (variatie = wolken, uniform = helder of bewolkt)\n",
    "    # Gebruik Laplacian variance als textuur maat\n",
    "    from scipy import ndimage\n",
    "    laplacian = ndimage.laplace(gray)\n",
    "    texture = np.var(laplacian)\n",
    "    \n",
    "    return {\n",
    "        'brightness': brightness,\n",
    "        'contrast': contrast,\n",
    "        'blue_ratio': blue_ratio,\n",
    "        'texture': texture\n",
    "    }\n",
    "\n",
    "def auto_label(features: Dict) -> str:\n",
    "    \"\"\"Bepaal label op basis van features.\"\"\"\n",
    "    brightness = features['brightness']\n",
    "    contrast = features['contrast']\n",
    "    blue_ratio = features['blue_ratio']\n",
    "    texture = features['texture']\n",
    "    \n",
    "    # Nacht detectie\n",
    "    if brightness < 30:\n",
    "        # Nacht: hoge textuur = sterren zichtbaar = helder\n",
    "        if texture > 50:\n",
    "            return 'helder'  # nacht_helder -> helder\n",
    "        else:\n",
    "            return 'bewolkt'  # nacht_bewolkt -> bewolkt\n",
    "    \n",
    "    # Dag detectie\n",
    "    # Hoge blue ratio + hoge textuur = deels bewolkt of helder\n",
    "    # Lage contrast + grijzig = bewolkt\n",
    "    \n",
    "    if contrast < 30 and blue_ratio < 0.35:\n",
    "        return 'bewolkt'\n",
    "    elif blue_ratio > 0.38 and contrast > 50:\n",
    "        return 'helder'\n",
    "    else:\n",
    "        return 'gedeeltelijk'\n",
    "\n",
    "# Analyseer alle beelden\n",
    "all_images = list(IMAGES_DIR.glob('*.jpg'))\n",
    "print(f\"Analyseren van {len(all_images)} beelden...\\n\")\n",
    "\n",
    "labels = {}\n",
    "features_list = []\n",
    "\n",
    "for img_path in tqdm(all_images, desc=\"Analyseren\"):\n",
    "    try:\n",
    "        features = analyze_image(img_path)\n",
    "        features['path'] = str(img_path)\n",
    "        features['name'] = img_path.name\n",
    "        features_list.append(features)\n",
    "        \n",
    "        # Auto label\n",
    "        label = auto_label(features)\n",
    "        labels[img_path.name] = label\n",
    "    except Exception as e:\n",
    "        print(f\"Fout bij {img_path.name}: {e}\")\n",
    "\n",
    "# Statistieken\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"AUTOMATISCHE LABELING RESULTAAT\")\n",
    "print(f\"{'='*50}\")\n",
    "label_counts = {}\n",
    "for label in labels.values():\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    pct = count / len(labels) * 100\n",
    "    print(f\"  {label}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotaal: {len(labels)} beelden gelabeld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Bekijk Voorbeelden per Klasse\n",
    "def show_examples(labels: Dict, images_dir: Path, n_examples: int = 6):\n",
    "    \"\"\"Toon voorbeelden per klasse.\"\"\"\n",
    "    classes = ['helder', 'gedeeltelijk', 'bewolkt']\n",
    "    \n",
    "    fig, axes = plt.subplots(3, n_examples, figsize=(20, 12))\n",
    "    \n",
    "    for row, cls in enumerate(classes):\n",
    "        # Vind beelden van deze klasse\n",
    "        cls_images = [k for k, v in labels.items() if v == cls]\n",
    "        samples = random.sample(cls_images, min(n_examples, len(cls_images)))\n",
    "        \n",
    "        for col, img_name in enumerate(samples):\n",
    "            img = Image.open(images_dir / img_name)\n",
    "            img.thumbnail((400, 300))\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].axis('off')\n",
    "            if col == 0:\n",
    "                axes[row, col].set_ylabel(cls.upper(), fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Automatisch Gelabelde Voorbeelden', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(WORK_DIR / 'label_examples.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "show_examples(labels, IMAGES_DIR)\n",
    "print(\"\\nControleer of de labels correct lijken.\")\n",
    "print(\"Als niet, kun je de thresholds in cel 4 aanpassen en opnieuw uitvoeren.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Dataset & Model Setup\n",
    "print(\"Dataset en model voorbereiden...\\n\")\n",
    "\n",
    "# Configuratie\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "CLASS_MAPPING = {'helder': 0, 'gedeeltelijk': 1, 'bewolkt': 2}\n",
    "CLASS_NAMES = ['helder', 'gedeeltelijk', 'bewolkt']\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE + 32, IMAGE_SIZE + 32)),\n",
    "    transforms.RandomCrop(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = [(self.image_dir / k, CLASS_MAPPING[v]) \n",
    "                        for k, v in labels.items() if v in CLASS_MAPPING]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Train/Val split\n",
    "items = list(labels.items())\n",
    "train_items, val_items = train_test_split(items, test_size=0.2, random_state=42)\n",
    "train_labels = dict(train_items)\n",
    "val_labels = dict(val_items)\n",
    "\n",
    "train_dataset = CloudDataset(IMAGES_DIR, train_labels, train_transform)\n",
    "val_dataset = CloudDataset(IMAGES_DIR, val_labels, val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training set: {len(train_dataset)} beelden\")\n",
    "print(f\"Validation set: {len(val_dataset)} beelden\")\n",
    "\n",
    "# Model\n",
    "class CloudClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.backbone.num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.backbone(x))\n",
    "\n",
    "model = CloudClassifier().to(device)\n",
    "print(f\"\\nModel geladen: EfficientNet-B0\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7. Training (duurt ~10-15 minuten)\n",
    "print(\"=\"*50)\n",
    "print(\"START TRAINING\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images, targets in pbar:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        train_correct += (outputs.argmax(1) == targets).sum().item()\n",
    "        train_total += targets.size(0)\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{train_correct/train_total:.2%}'})\n",
    "    \n",
    "    train_loss /= train_total\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            val_correct += (outputs.argmax(1) == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "    \n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  ★ Nieuw beste model! Val acc: {val_acc:.2%}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss={train_loss:.4f}, Acc={train_acc:.2%}, Val_Loss={val_loss:.4f}, Val_Acc={val_acc:.2%}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"TRAINING COMPLEET!\")\n",
    "print(f\"Beste validatie accuracy: {best_val_acc:.2%}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 8. Resultaten & Evaluatie\n",
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train')\n",
    "ax1.plot(history['val_loss'], label='Validation')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Train')\n",
    "ax2.plot(history['val_acc'], label='Validation')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(WORK_DIR / 'training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for images, targets in val_loader:\n",
    "        outputs = model(images.to(device))\n",
    "        all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        all_targets.extend(targets.numpy())\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=CLASS_NAMES))\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_xticks(range(3))\n",
    "ax.set_yticks(range(3))\n",
    "ax.set_xticklabels(CLASS_NAMES)\n",
    "ax.set_yticklabels(CLASS_NAMES)\n",
    "ax.set_xlabel('Voorspeld')\n",
    "ax.set_ylabel('Werkelijk')\n",
    "ax.set_title('Confusion Matrix')\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax.text(j, i, str(cm[i, j]), ha='center', va='center',\n",
    "                color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.savefig(WORK_DIR / 'confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 9. Export naar ONNX\n",
    "print(\"Exporteren naar ONNX formaat...\\n\")\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "model_cpu = model.cpu()\n",
    "\n",
    "# Paden\n",
    "ONNX_PATH = WORK_DIR / 'cloud_classifier.onnx'\n",
    "PT_PATH = WORK_DIR / 'cloud_classifier.pt'\n",
    "\n",
    "# PyTorch checkpoint\n",
    "torch.save({\n",
    "    'model_state_dict': best_model_state,\n",
    "    'class_names': CLASS_NAMES,\n",
    "    'image_size': IMAGE_SIZE,\n",
    "    'best_val_acc': best_val_acc,\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'labels': labels\n",
    "}, PT_PATH)\n",
    "print(f\"PyTorch checkpoint: {PT_PATH}\")\n",
    "\n",
    "# ONNX export\n",
    "dummy_input = torch.randn(1, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "torch.onnx.export(\n",
    "    model_cpu,\n",
    "    dummy_input,\n",
    "    ONNX_PATH,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}}\n",
    ")\n",
    "\n",
    "print(f\"ONNX model: {ONNX_PATH}\")\n",
    "print(f\"Model grootte: {ONNX_PATH.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Valideer ONNX\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnx_model = onnx.load(ONNX_PATH)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"\\nONNX model validatie: OK!\")\n",
    "\n",
    "# Test inference\n",
    "session = ort.InferenceSession(str(ONNX_PATH))\n",
    "test_input = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "output = session.run(None, {'input': test_input})[0]\n",
    "print(f\"ONNX inference test: OK! Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 10. Sla Labels op\n",
    "labels_path = WORK_DIR / 'labels.json'\n",
    "with open(labels_path, 'w') as f:\n",
    "    json.dump(labels, f, indent=2)\n",
    "print(f\"Labels opgeslagen: {labels_path}\")\n",
    "print(f\"Totaal: {len(labels)} gelabelde beelden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 11. Klaar! Download Instructies\n",
    "print(\"=\"*60)\n",
    "print(\"         TRAINING SUCCESVOL AFGEROND!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBeste validatie accuracy: {best_val_acc:.1%}\")\n",
    "print(f\"\\nBestanden staan in Google Drive:\")\n",
    "print(f\"  {WORK_DIR}/\")\n",
    "print(f\"    ├── cloud_classifier.onnx  ({ONNX_PATH.stat().st_size/1024/1024:.1f} MB)\")\n",
    "print(f\"    ├── cloud_classifier.pt\")\n",
    "print(f\"    ├── labels.json\")\n",
    "print(f\"    ├── training_history.png\")\n",
    "print(f\"    └── confusion_matrix.png\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEPLOYMENT OP PI BERGING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. Download cloud_classifier.onnx van Google Drive\n",
    "\n",
    "2. Kopieer naar Pi:\n",
    "   scp cloud_classifier.onnx ronny@192.168.1.87:/home/ronny/emsn2/scripts/atmosbird/\n",
    "\n",
    "3. Test op Pi:\n",
    "   cd /home/ronny/emsn2/scripts/atmosbird\n",
    "   python cloud_classifier_inference.py cloud_classifier.onnx \\\n",
    "       /mnt/usb/atmosbird/ruwe_foto/2025/12/30/sky_20251230_120000.jpg\n",
    "\n",
    "4. Het model is nu klaar voor gebruik in atmosbird_capture.py!\n",
    "\"\"\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
