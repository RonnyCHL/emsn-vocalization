{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMSN 2.0 - Nordic Species Training\n",
    "## 25 Scandinavische soorten voor birdnet-vocalization\n",
    "\n",
    "### Doelgroep:\n",
    "- Zweden, Noorwegen, Finland\n",
    "- Noord-Europese gebruikers\n",
    "\n",
    "### Vereisten:\n",
    "- **GPU:** A100 (40GB) aanbevolen\n",
    "- **RAM:** High RAM runtime (52GB)\n",
    "- **Tijd:** ~2-3 uur\n",
    "\n",
    "### Colab Pro instellingen:\n",
    "1. Runtime ‚Üí Change runtime type\n",
    "2. Hardware accelerator: **GPU**\n",
    "3. GPU type: **A100** (als beschikbaar)\n",
    "4. High-RAM: **‚úì Aan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU en RAM\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / 1e9\n",
    "print(f\"RAM: {ram_gb:.1f} GB\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_mem:.1f} GB\")\n",
    "    \n",
    "    torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    torch.backends.cudnn.allow_tf32 = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    if 'A100' in gpu_name:\n",
    "        GPU_TYPE = 'A100'\n",
    "        BATCH_SIZE = 64\n",
    "        print(f\"\\nüöÄ A100 gedetecteerd\")\n",
    "    elif 'V100' in gpu_name:\n",
    "        GPU_TYPE = 'V100'\n",
    "        BATCH_SIZE = 48\n",
    "    else:\n",
    "        GPU_TYPE = 'T4'\n",
    "        BATCH_SIZE = 32\n",
    "else:\n",
    "    GPU_TYPE = 'CPU'\n",
    "    BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install librosa scikit-learn scikit-image matplotlib tqdm requests -q\n",
    "print(\"‚úÖ Dependencies ge√Ønstalleerd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Mount Google Drive voor persistente opslag\nfrom google.colab import drive\nimport os\n\n# Mount Drive\ndrive.mount('/content/drive')\n\n# Opslag in Drive (blijft bewaard!)\nDRIVE_BASE = '/content/drive/MyDrive/EMSN-Nordic'\nMODELS_DIR = f'{DRIVE_BASE}/models'\nAUDIO_DIR = f'{DRIVE_BASE}/audio'\n\nos.makedirs(MODELS_DIR, exist_ok=True)\nos.makedirs(AUDIO_DIR, exist_ok=True)\n\nprint(f\"‚úÖ Google Drive gemount\")\nprint(f\"üìÅ Modellen worden opgeslagen in: {MODELS_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATIE ===\n",
    "VERSION = '2026_nordic'\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "MIN_LR = 0.00001\n",
    "PATIENCE = 10\n",
    "\n",
    "# Data parameters\n",
    "MAX_RECORDINGS_PER_TYPE = 50\n",
    "MAX_SEGMENTS_PER_RECORDING = 5\n",
    "NUM_WORKERS = 4\n",
    "MAX_CONCURRENT_DOWNLOADS = 10\n",
    "\n",
    "# Augmentation\n",
    "USE_AUGMENTATION = True\n",
    "AUGMENTATION_FACTOR = 2\n",
    "\n",
    "# Xeno-canto API key\n",
    "XC_API_KEY = '14258afd1c8a8e055387d012f2620e20f59ef3a2'\n",
    "\n",
    "print(f\"üìä NORDIC CONFIGURATIE:\")\n",
    "print(f\"   GPU: {GPU_TYPE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 25 SCANDINAVISCHE/ONTBREKENDE SOORTEN ===\n",
    "# Format: (NL naam, Scientific name, filename)\n",
    "\n",
    "NORDIC_SPECIES = [\n",
    "    # Svardsten53's ontbrekende soorten\n",
    "    (\"Ringmus\", \"Passer montanus\", \"Passer_montanus\"),\n",
    "    (\"Witbandkruisbek\", \"Loxia leucoptera\", \"Loxia_leucoptera\"),\n",
    "    \n",
    "    # Kruisbekken\n",
    "    (\"Grote Kruisbek\", \"Loxia pytyopsittacus\", \"Loxia_pytyopsittacus\"),\n",
    "    \n",
    "    # Mezen\n",
    "    (\"Bruinkopmees\", \"Poecile cinctus\", \"Poecile_cinctus\"),\n",
    "    \n",
    "    # Uilen\n",
    "    (\"Laplanduil\", \"Strix nebulosa\", \"Strix_nebulosa\"),\n",
    "    (\"Oeraluil\", \"Strix uralensis\", \"Strix_uralensis\"),\n",
    "    (\"Ruigpootuil\", \"Aegolius funereus\", \"Aegolius_funereus\"),\n",
    "    (\"Dwerguil\", \"Glaucidium passerinum\", \"Glaucidium_passerinum\"),\n",
    "    (\"Sneeuwuil\", \"Bubo scandiacus\", \"Bubo_scandiacus\"),\n",
    "    (\"Sperweruil\", \"Surnia ulula\", \"Surnia_ulula\"),\n",
    "    \n",
    "    # Spechten\n",
    "    (\"Witrugspecht\", \"Dendrocopos leucotos\", \"Dendrocopos_leucotos\"),\n",
    "    (\"Drieteenspecht\", \"Picoides tridactylus\", \"Picoides_tridactylus\"),\n",
    "    \n",
    "    # Kraaiachtigen\n",
    "    (\"Taigagaai\", \"Perisoreus infaustus\", \"Perisoreus_infaustus\"),\n",
    "    (\"Notenkraker\", \"Nucifraga caryocatactes\", \"Nucifraga_caryocatactes\"),\n",
    "    \n",
    "    # Hoenders\n",
    "    (\"Alpensneeuwhoen\", \"Lagopus muta\", \"Lagopus_muta\"),\n",
    "    (\"Moerassneeuwhoen\", \"Lagopus lagopus\", \"Lagopus_lagopus\"),\n",
    "    (\"Auerhoen\", \"Tetrao urogallus\", \"Tetrao_urogallus\"),\n",
    "    (\"Korhoen\", \"Lyrurus tetrix\", \"Lyrurus_tetrix\"),\n",
    "    (\"Hazelhoen\", \"Bonasa bonasia\", \"Bonasa_bonasia\"),\n",
    "    \n",
    "    # Gorzen\n",
    "    (\"IJsgors\", \"Calcarius lapponicus\", \"Calcarius_lapponicus\"),\n",
    "    (\"Bosgors\", \"Emberiza rustica\", \"Emberiza_rustica\"),\n",
    "    \n",
    "    # Overig\n",
    "    (\"Waterspreeuw\", \"Cinclus cinclus\", \"Cinclus_cinclus\"),\n",
    "    (\"Roodmus\", \"Carpodacus erythrinus\", \"Carpodacus_erythrinus\"),\n",
    "    (\"Kleine Vliegenvanger\", \"Ficedula parva\", \"Ficedula_parva\"),\n",
    "    (\"Roodkeelpieper\", \"Anthus cervinus\", \"Anthus_cervinus\"),\n",
    "]\n",
    "\n",
    "print(f\"Te trainen: {len(NORDIC_SPECIES)} Scandinavische soorten\")\n",
    "for nl, sci, _ in NORDIC_SPECIES:\n",
    "    print(f\"  ‚Ä¢ {nl} ({sci})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xeno-canto API\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def search_xeno_canto(scientific_name, voc_type='song', max_results=100):\n",
    "    parts = scientific_name.split()\n",
    "    if len(parts) < 2:\n",
    "        return []\n",
    "    \n",
    "    genus, species = parts[0].lower(), parts[1].lower()\n",
    "    \n",
    "    if ' ' in voc_type:\n",
    "        type_query = f'type:\"{voc_type}\"'\n",
    "    else:\n",
    "        type_query = f'type:{voc_type}'\n",
    "    \n",
    "    query = f'gen:{genus} sp:{species} {type_query} q:A'\n",
    "    url = f'https://xeno-canto.org/api/3/recordings?query={query}&key={XC_API_KEY}'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get('recordings', [])[:max_results]\n",
    "        return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def download_single(args):\n",
    "    recording, output_dir = args\n",
    "    xc_id = recording['id']\n",
    "    file_url = recording.get('file', '')\n",
    "    \n",
    "    if not file_url:\n",
    "        return None\n",
    "    \n",
    "    if file_url.startswith('//'):\n",
    "        file_url = 'https:' + file_url\n",
    "    elif not file_url.startswith('http'):\n",
    "        file_url = 'https://xeno-canto.org' + file_url\n",
    "    \n",
    "    output_path = output_dir / f\"XC{xc_id}.mp3\"\n",
    "    \n",
    "    if output_path.exists():\n",
    "        return output_path\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(file_url, timeout=60)\n",
    "        if response.status_code == 200:\n",
    "            with open(output_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return output_path\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def download_recordings_parallel(recordings, output_dir, max_workers=10):\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    downloaded = []\n",
    "    args_list = [(rec, output_dir) for rec in recordings]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(download_single, args): args[0]['id'] for args in args_list}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                downloaded.append(result)\n",
    "    \n",
    "    return downloaded\n",
    "\n",
    "print(\"‚úÖ Download functies geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram generatie met augmentation\n",
    "import librosa\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "SAMPLE_RATE = 48000\n",
    "N_MELS = 128\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "FMIN = 500\n",
    "FMAX = 8000\n",
    "SEGMENT_DURATION = 3.0\n",
    "\n",
    "def augment_audio(audio, sr):\n",
    "    augmented = [audio]\n",
    "    \n",
    "    try:\n",
    "        shifted_up = librosa.effects.pitch_shift(audio, sr=sr, n_steps=2)\n",
    "        shifted_down = librosa.effects.pitch_shift(audio, sr=sr, n_steps=-2)\n",
    "        augmented.extend([shifted_up, shifted_down])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        stretched_slow = librosa.effects.time_stretch(audio, rate=0.9)\n",
    "        stretched_fast = librosa.effects.time_stretch(audio, rate=1.1)\n",
    "        target_len = len(audio)\n",
    "        if len(stretched_slow) > target_len:\n",
    "            stretched_slow = stretched_slow[:target_len]\n",
    "        else:\n",
    "            stretched_slow = np.pad(stretched_slow, (0, target_len - len(stretched_slow)))\n",
    "        if len(stretched_fast) > target_len:\n",
    "            stretched_fast = stretched_fast[:target_len]\n",
    "        else:\n",
    "            stretched_fast = np.pad(stretched_fast, (0, target_len - len(stretched_fast)))\n",
    "        augmented.extend([stretched_slow, stretched_fast])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    noise = np.random.normal(0, 0.005, len(audio))\n",
    "    noisy = audio + noise\n",
    "    augmented.append(noisy)\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "def audio_to_spectrogram(audio, sr=SAMPLE_RATE):\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio, sr=sr,\n",
    "        n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "        fmin=FMIN, fmax=FMAX\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-8)\n",
    "    \n",
    "    if mel_norm.shape != (128, 128):\n",
    "        from skimage.transform import resize\n",
    "        mel_norm = resize(mel_norm, (128, 128), anti_aliasing=True)\n",
    "    \n",
    "    return mel_norm\n",
    "\n",
    "def process_single_audio(audio_path, max_segments=5, use_augmentation=True):\n",
    "    try:\n",
    "        audio, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE, mono=True)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    segment_samples = int(SEGMENT_DURATION * SAMPLE_RATE)\n",
    "    spectrograms = []\n",
    "    \n",
    "    for i in range(0, len(audio), segment_samples):\n",
    "        if len(spectrograms) >= max_segments * (6 if use_augmentation else 1):\n",
    "            break\n",
    "        \n",
    "        segment = audio[i:i + segment_samples]\n",
    "        if len(segment) < segment_samples // 2:\n",
    "            continue\n",
    "        \n",
    "        if len(segment) < segment_samples:\n",
    "            segment = np.pad(segment, (0, segment_samples - len(segment)))\n",
    "        \n",
    "        if use_augmentation:\n",
    "            augmented_segments = augment_audio(segment, SAMPLE_RATE)\n",
    "            for aug_segment in augmented_segments[:AUGMENTATION_FACTOR]:\n",
    "                spec = audio_to_spectrogram(aug_segment)\n",
    "                spectrograms.append(spec)\n",
    "        else:\n",
    "            spec = audio_to_spectrogram(segment)\n",
    "            spectrograms.append(spec)\n",
    "    \n",
    "    return spectrograms\n",
    "\n",
    "def process_audio_files_parallel(audio_paths, max_segments=5, max_workers=4, use_augmentation=True):\n",
    "    all_specs = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        func = partial(process_single_audio, max_segments=max_segments, use_augmentation=use_augmentation)\n",
    "        results = list(executor.map(func, audio_paths))\n",
    "    \n",
    "    for specs in results:\n",
    "        all_specs.extend(specs)\n",
    "    \n",
    "    return all_specs\n",
    "\n",
    "print(\"‚úÖ Spectrogram functies geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultimate CNN Model (4 conv blocks)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VocalizationCNN(nn.Module):\n",
    "    def __init__(self, input_shape=(128, 128), num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "        \n",
    "        h, w = input_shape[0] // 16, input_shape[1] // 16\n",
    "        flatten_size = 256 * h * w\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flatten_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ CNN model klaar voor {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Pipeline\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "\n",
    "def train_species(dutch_name, scientific_name, dirname):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üê¶ {dutch_name} ({scientific_name})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    audio_dir = Path(f'{DRIVE_BASE}/audio/{dirname}')\n",
    "    \n",
    "    X_all, y_all = [], []\n",
    "    voc_types = [('song', 0), ('call', 1), ('alarm call', 2)]\n",
    "    \n",
    "    for voc_type, label in voc_types:\n",
    "        print(f\"  üì• {voc_type}...\", end=' ')\n",
    "        recordings = search_xeno_canto(scientific_name, voc_type, max_results=MAX_RECORDINGS_PER_TYPE)\n",
    "        \n",
    "        if not recordings:\n",
    "            print(\"0 gevonden\")\n",
    "            continue\n",
    "        \n",
    "        type_dir = audio_dir / voc_type.replace(' ', '_')\n",
    "        audio_files = download_recordings_parallel(\n",
    "            recordings[:MAX_RECORDINGS_PER_TYPE], \n",
    "            type_dir, \n",
    "            max_workers=MAX_CONCURRENT_DOWNLOADS\n",
    "        )\n",
    "        print(f\"{len(audio_files)} files\", end=' ')\n",
    "        \n",
    "        if audio_files:\n",
    "            specs = process_audio_files_parallel(\n",
    "                audio_files, \n",
    "                max_segments=MAX_SEGMENTS_PER_RECORDING, \n",
    "                max_workers=NUM_WORKERS,\n",
    "                use_augmentation=USE_AUGMENTATION\n",
    "            )\n",
    "            if specs:\n",
    "                for spec in specs:\n",
    "                    X_all.append(spec)\n",
    "                    y_all.append(label)\n",
    "            print(f\"‚Üí {len(specs)} specs\")\n",
    "        else:\n",
    "            print()\n",
    "    \n",
    "    if len(X_all) < 30:\n",
    "        print(f\"  ‚ö†Ô∏è Te weinig data ({len(X_all)})\")\n",
    "        return None, 'insufficient_data'\n",
    "    \n",
    "    X = np.array(X_all)\n",
    "    y = np.array(y_all)\n",
    "    \n",
    "    unique_labels = np.unique(y)\n",
    "    num_classes = len(unique_labels)\n",
    "    \n",
    "    if num_classes < 2:\n",
    "        print(f\"  ‚ö†Ô∏è Slechts 1 klasse\")\n",
    "        return None, 'single_class'\n",
    "    \n",
    "    label_map = {old: new for new, old in enumerate(unique_labels)}\n",
    "    y_remapped = np.array([label_map[l] for l in y])\n",
    "    \n",
    "    all_class_names = ['song', 'call', 'alarm']\n",
    "    class_names = [all_class_names[l] for l in unique_labels]\n",
    "    \n",
    "    unique, counts = np.unique(y_remapped, return_counts=True)\n",
    "    class_dist = {class_names[i]: int(counts[i]) for i in range(len(counts))}\n",
    "    print(f\"  üìä {len(X)} specs: {class_dist}\")\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y_remapped, test_size=0.2, random_state=42, stratify=y_remapped\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(torch.FloatTensor(X_train).unsqueeze(1), torch.LongTensor(y_train)),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        TensorDataset(torch.FloatTensor(X_val).unsqueeze(1), torch.LongTensor(y_val)),\n",
    "        batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    model = VocalizationCNN(num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, min_lr=MIN_LR)\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch = X_batch.to(device, non_blocking=True)\n",
    "                y_batch = y_batch.to(device, non_blocking=True)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    X_batch = X_batch.to(device, non_blocking=True)\n",
    "                    y_batch = y_batch.to(device, non_blocking=True)\n",
    "                    outputs = model(X_batch)\n",
    "                    val_correct += (outputs.argmax(1) == y_batch).sum().item()\n",
    "            \n",
    "            val_acc = val_correct / len(y_val)\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"  ‚èπÔ∏è Early stop @ epoch {epoch+1}\")\n",
    "                break\n",
    "                \n",
    "    except RuntimeError as e:\n",
    "        if 'CUDA' in str(e):\n",
    "            print(f\"  ‚ö†Ô∏è CUDA error\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            if best_state is None:\n",
    "                return None, 'cuda_error'\n",
    "        else:\n",
    "            raise e\n",
    "    \n",
    "    if best_state is None:\n",
    "        return None, 'training_failed'\n",
    "    \n",
    "    # Save with scientific name as filename!\n",
    "    model_path = Path(f'{DRIVE_BASE}/models/{dirname}.pt')\n",
    "    torch.save({\n",
    "        'model_state_dict': best_state,\n",
    "        'num_classes': num_classes,\n",
    "        'class_names': class_names,\n",
    "        'label_map': label_map,\n",
    "        'accuracy': best_acc,\n",
    "        'species_name': dutch_name,\n",
    "        'scientific_name': scientific_name,\n",
    "        'version': VERSION,\n",
    "        'class_distribution': class_dist\n",
    "    }, model_path)\n",
    "    \n",
    "    del model, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  ‚úÖ {model_path.name} | Acc: {best_acc:.1%} | {elapsed:.0f}s\")\n",
    "    \n",
    "    return best_acc, 'success'\n",
    "\n",
    "print(\"‚úÖ Training pipeline geladen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ START NORDIC TRAINING\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "start_all = time.time()\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"üöÄ EMSN NORDIC VOCALIZATION TRAINING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Start: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"Soorten: {len(NORDIC_SPECIES)}\")\n",
    "print(f\"GPU: {GPU_TYPE}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "for i, (dutch, scientific, dirname) in enumerate(NORDIC_SPECIES):\n",
    "    try:\n",
    "        acc, status = train_species(dutch, scientific, dirname)\n",
    "        results.append({\n",
    "            'species': dutch,\n",
    "            'scientific': scientific,\n",
    "            'filename': dirname,\n",
    "            'accuracy': acc,\n",
    "            'status': status\n",
    "        })\n",
    "        \n",
    "        if status == 'success':\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error: {str(e)[:50]}\")\n",
    "        results.append({\n",
    "            'species': dutch,\n",
    "            'scientific': scientific,\n",
    "            'filename': dirname,\n",
    "            'accuracy': None,\n",
    "            'status': f'error'\n",
    "        })\n",
    "        failed += 1\n",
    "    \n",
    "    # Progress update\n",
    "    if (i + 1) % 5 == 0:\n",
    "        pd.DataFrame(results).to_csv(f'{DRIVE_BASE}/checkpoint.csv', index=False)\n",
    "        elapsed = time.time() - start_all\n",
    "        eta = (elapsed / (i + 1)) * (len(NORDIC_SPECIES) - i - 1)\n",
    "        print(f\"\\n  üíæ [{i+1}/{len(NORDIC_SPECIES)}] ‚úÖ{successful} ‚ùå{failed} | ETA: {eta/60:.0f}min\\n\")\n",
    "\n",
    "elapsed_all = time.time() - start_all\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üèÅ TRAINING VOLTOOID!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Tijd: {elapsed_all/60:.1f} minuten\")\n",
    "print(f\"Succesvol: {successful}/{len(NORDIC_SPECIES)}\")\n",
    "print(f\"Mislukt: {failed}/{len(NORDIC_SPECIES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Resultaten\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f'{DRIVE_BASE}/results_nordic.csv', index=False)\n",
    "\n",
    "successful_df = df[df['status'] == 'success']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üìä RESULTATEN\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Getraind: {len(successful_df)}/{len(df)}\")\n",
    "\n",
    "if len(successful_df) > 0:\n",
    "    print(f\"\\nAccuracy:\")\n",
    "    print(f\"  Gemiddeld: {successful_df['accuracy'].mean():.1%}\")\n",
    "    print(f\"  Min: {successful_df['accuracy'].min():.1%}\")\n",
    "    print(f\"  Max: {successful_df['accuracy'].max():.1%}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Resultaten:\")\n",
    "    for _, row in successful_df.iterrows():\n",
    "        print(f\"  {row['accuracy']:.1%} - {row['species']} ({row['scientific']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• DOWNLOAD MODELLEN\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "models_dir = Path(f'{DRIVE_BASE}/models')\n",
    "models = sorted(models_dir.glob('*.pt'))\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"üìÅ NORDIC MODELLEN\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Totaal: {len(models)} modellen\")\n",
    "\n",
    "if models:\n",
    "    total_size = sum(m.stat().st_size for m in models) / 1e6\n",
    "    print(f\"Grootte: {total_size:.1f} MB\")\n",
    "    \n",
    "    print(f\"\\nModellen (met scientific names):\")\n",
    "    for m in models:\n",
    "        print(f\"  ‚Ä¢ {m.name}\")\n",
    "    \n",
    "    print(f\"\\nüì¶ ZIP maken...\")\n",
    "    zip_path = '/content/emsn_models_nordic.zip'\n",
    "    shutil.make_archive('/content/emsn_models_nordic', 'zip', models_dir)\n",
    "    zip_size = Path(zip_path).stat().st_size / 1e6\n",
    "    print(f\"‚úÖ {zip_path} ({zip_size:.1f} MB)\")\n",
    "    \n",
    "    print(f\"\\nüì• Downloading...\")\n",
    "    files.download(zip_path)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Geen modellen\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}